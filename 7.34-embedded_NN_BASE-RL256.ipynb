{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418c282c-2b25-4f32-96cf-883b40b84c36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "  # Apply encoder to morphological profiles to get latent space representations :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da93a6-653f-4a55-9b3a-e72ab79a1121",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a104a277-3ad3-438a-b706-d4499f709f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T10:29:16.111588Z",
     "start_time": "2023-04-12T10:29:15.764305Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:39.248243Z",
     "iopub.status.busy": "2024-10-04T00:02:39.247952Z",
     "iopub.status.idle": "2024-10-04T00:02:39.265807Z",
     "shell.execute_reply": "2024-10-04T00:02:39.265273Z",
     "shell.execute_reply.started": "2024-10-04T00:02:39.248219Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2\n",
    "from IPython.display import display, HTML, Image\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7478f60a-2ea2-4407-bd91-f068349f222b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T10:29:16.111588Z",
     "start_time": "2023-04-12T10:29:15.764305Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:40.210194Z",
     "iopub.status.busy": "2024-10-04T00:02:40.209681Z",
     "iopub.status.idle": "2024-10-04T00:02:42.974343Z",
     "shell.execute_reply": "2024-10-04T00:02:42.973647Z",
     "shell.execute_reply.started": "2024-10-04T00:02:40.210149Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert ./src\n",
      "insert ../pt-snnl\n",
      "insert ../..\n",
      "['../..', '../pt-snnl', './src', '/home/kevin/WSL-shared/cellpainting/cj-datasets', '/home/kevin/miniforge3/envs/cp311/lib/python311.zip', '/home/kevin/miniforge3/envs/cp311/lib/python3.11', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/lib-dynload', '', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages/huggingface_hub-0.20.3-py3.8.egg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff82a7aead0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from types import SimpleNamespace\n",
    "from functools import partial\n",
    "import pprint\n",
    "import logging\n",
    "from datetime import datetime\n",
    "for p in ['./src','../pt-snnl','../..']:\n",
    "    if p not in sys.path:\n",
    "        print(f\"insert {p}\")\n",
    "        sys.path.insert(0, p)\n",
    "print(sys.path)\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as sps\n",
    "import sklearn.metrics as skm\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt  # for making figures\n",
    "from torchinfo import summary\n",
    "\n",
    "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=180, profile=None, sci_mode=None)\n",
    "torch.manual_seed(42);   # seed rng for reproducibility\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pd.options.display.width = 132\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"AE-MAIN-SNNL.ipynb\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "\n",
    "torch.set_num_threads(4)  ## <--- limit to ~ 2 CPUs\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b939a031-286c-430c-890d-946ea497d8e3",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:42.975960Z",
     "iopub.status.busy": "2024-10-04T00:02:42.975608Z",
     "iopub.status.idle": "2024-10-04T00:02:45.136456Z",
     "shell.execute_reply": "2024-10-04T00:02:45.135768Z",
     "shell.execute_reply.started": "2024-10-04T00:02:42.975937Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from KevinsRoutines.utils.utils_general import list_namespace, save_to_pickle, load_from_pickle, get_device\n",
    "import KevinsRoutines.utils as myutils\n",
    "# import snnl.utils as utils\n",
    "# from utils.utils_ptsnnl import display_cellpainting_batch, get_device\n",
    "from utils.utils_cellpainting import label_counts, balance_datasets,save_checkpoint, load_checkpoint\n",
    "from utils.dataloader import custom_collate_fn, dynamic_collate_fn, CellpaintingDataset, InfiniteDataLoader\n",
    "from utils.utils_notebooks import plot_cls_metrics, compute_classification_metrics, run_model_on_test_data,\\\n",
    "                                train, validation, accuracy_fn, fit, build_model, define_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12352c5-443c-414b-bb2b-6ea5ba801515",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:45.137835Z",
     "iopub.status.busy": "2024-10-04T00:02:45.137614Z",
     "iopub.status.idle": "2024-10-04T00:02:45.173684Z",
     "shell.execute_reply": "2024-10-04T00:02:45.173098Z",
     "shell.execute_reply.started": "2024-10-04T00:02:45.137814Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:02:45,167 - __main__ - INFO: -  Excution started : 2024_10_04_02:02:45 \n",
      "2024-10-04 02:02:45,168 - __main__ - INFO: -  Pytorch version  : 2.2.0\n",
      "2024-10-04 02:02:45,169 - __main__ - INFO: -  Scipy version    : 1.11.4  \t\t Numpy version : 1.26.2\n",
      "2024-10-04 02:02:45,169 - __main__ - INFO: -  Pandas version   : 2.2.0  \n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y_%m_%d_%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logLevel = os.environ.get('LOG_LEVEL', 'INFO').upper()\n",
    "FORMAT = '%(asctime)s - %(name)s - %(levelname)s: - %(message)s'\n",
    "logging.basicConfig(level=\"INFO\", format= FORMAT)\n",
    "logger.info(f\" Excution started : {timestamp} \")\n",
    "logger.info(f\" Pytorch version  : {torch.__version__}\")\n",
    "logger.info(f\" Scipy version    : {scipy.__version__}  \\t\\t Numpy version : {np.__version__}\")\n",
    "logger.info(f\" Pandas version   : {pd.__version__}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78dd68d4-cabf-4b8b-ba9f-82fbda15fc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:45:10.550334Z",
     "start_time": "2023-07-31T18:45:07.868769Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:45.339819Z",
     "iopub.status.busy": "2024-10-04T00:02:45.339546Z",
     "iopub.status.idle": "2024-10-04T00:02:45.379340Z",
     "shell.execute_reply": "2024-10-04T00:02:45.378398Z",
     "shell.execute_reply.started": "2024-10-04T00:02:45.339797Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48065ef-8765-4b2f-a448-3d0d0dbf3609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:45.820729Z",
     "iopub.status.busy": "2024-10-04T00:02:45.820439Z",
     "iopub.status.idle": "2024-10-04T00:02:46.595386Z",
     "shell.execute_reply": "2024-10-04T00:02:46.594554Z",
     "shell.execute_reply.started": "2024-10-04T00:02:45.820706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Switched to: \"cuda:1\"   Device Name: Quadro GV100                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Id   Device Name                    Total Memory                     InUse                            Free Memory \n",
      "   0     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 1,092,616,192 B / (1.02 GB)  \t 32,977,256,448 B / (30.71 GB)  \n",
      "   1     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 966,787,072 B / (0.90 GB)  \t 33,103,085,568 B / (30.83 GB)   *** CURRENT DEVICE *** \n",
      "   2     NVIDIA TITAN Xp                12,774,539,264 B/ (11.90 GB)  \t 545,390,592 B / (0.51 GB)  \t 12,229,148,672 B / (11.39 GB)  \n",
      "\n",
      " Current CUDA Device is:  \"cuda:1\"  Device Name: Quadro GV100\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "myutils.set_device(1)\n",
    "device  = myutils.get_device(verbose = True)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953c069-cf3f-46b9-94e5-741525cf4232",
   "metadata": {},
   "source": [
    "# Args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4219af-8769-45f3-8b9f-23cff8e5eb6c",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:47.615475Z",
     "iopub.status.busy": "2024-10-04T00:02:47.614921Z",
     "iopub.status.idle": "2024-10-04T00:02:47.662482Z",
     "shell.execute_reply": "2024-10-04T00:02:47.661833Z",
     "shell.execute_reply.started": "2024-10-04T00:02:47.615427Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM    = 150\n",
    "COMPOUNDS_PER_BATCH = 600\n",
    "TPSA_THRESHOLD = 100\n",
    "\n",
    "MODEL_TYPE = 'relu'\n",
    "n_input    = LATENT_DIM  # the embedding dimensionality \n",
    "\n",
    "n_hidden_1 = 256  # the number of neurons in the hidden layer of the MLP\n",
    "n_hidden_2 = 256  # the number of neurons in the hidden layer of the MLP\n",
    "n_hidden_3 = 128\n",
    "\n",
    "METADATA_COLS = ['Metadata_Source', 'Metadata_Batch', 'Metadata_Plate', 'Metadata_Well', 'Metadata_JCP2022', 'Metadata_Hash', 'Metadata_Bin', 'Metadata_TPSA', 'Metadata_lnTPSA', 'Metadata_log10TPSA', 'Metadata_Permiation']\n",
    "# METADATA_COLS += [f'Feature_{x:03d}' for x in range(LATENT_DIM)]\n",
    "input_cols = LATENT_DIM + len(METADATA_COLS)\n",
    "print(len(METADATA_COLS))\n",
    "print(input_cols)\n",
    "\n",
    "\n",
    "INPUT_PATH = f\"/home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/\"\n",
    "CKPT_PATH = \"./saved_models/embedding_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eda1f6ea-e344-4b74-966e-19afbe6f15e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:48.649776Z",
     "iopub.status.busy": "2024-10-04T00:02:48.649260Z",
     "iopub.status.idle": "2024-10-04T00:02:48.687620Z",
     "shell.execute_reply": "2024-10-04T00:02:48.686947Z",
     "shell.execute_reply.started": "2024-10-04T00:02:48.649725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241002_1940\n"
     ]
    }
   ],
   "source": [
    "# RUN_DATETIME = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# RUN_DATETIME = '20240926_1900'   ## Baseline CPB 600, Latent 150  - Single layer 256\n",
    "# RUN_DATETIME = '20240927_2300'   ## Baseline CPB 600, Latent 150  - Single layer 512\n",
    "# RUN_DATETIME = '20240929_2000'   ## Baseline CPB 600, Latent 150  - Batch Norm 256/256/128\n",
    "# RUN_DATETIME = '20240929_1900'   ## Baseline CPB 600, Latent 150  - Batch Norm 512/512/128\n",
    "\n",
    "# RUN_DATETIME = '20240930_2100'   ## Baseline CPB 600, Latent 250  - Balanced TPSA labels - Batch Norm 256/256/128\n",
    "# RUN_DATETIME = '20241001_2100'   ## Baseline CPB 600, Latent 250  - Balanced TPSA labels - Batch Norm 512/512/256\n",
    "\n",
    "# RUN_DATETIME = '20241002_1915'   ## Baseline CPB 600, Latent 150  - Single layer 256\n",
    "# RUN_DATETIME = '20241002_1930'   ## Baseline CPB 600, Latent 150  - Single layer 512\n",
    "# RUN_DATETIME = '20241002_1945'   ## Baseline CPB 600, Latent 150  - Batch Norm 256/256/128\n",
    "# RUN_DATETIME = '20241002_2000'   ## Baseline CPB 600, Latent 150  - Batch Norm 512/512/128\n",
    "\n",
    "RUN_DATETIME = '20241002_1940'   ## Baseline CPB 600, Latent 150  - Batch Norm 512/512/128\n",
    "\n",
    "print(RUN_DATETIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9f50920-9384-4d93-8ea4-40379f898aa8",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:49.750651Z",
     "iopub.status.busy": "2024-10-04T00:02:49.750120Z",
     "iopub.status.idle": "2024-10-04T00:02:49.787585Z",
     "shell.execute_reply": "2024-10-04T00:02:49.786765Z",
     "shell.execute_reply.started": "2024-10-04T00:02:49.750608Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SNNL AUTOENCODERS \n",
    "# AE_RUNMODE = \"snnl\"\n",
    "# AE_DATETIME = \"20240718_1956\"\n",
    "# AE_DATETIME = \"20240906_2201\"     # Autoencoder training - SNNL, CPB = 600, Latent 150, WD = 0.001, SNN Factor 3\n",
    "# AE_DATETIME = \"20240917_2004\"     # Autoencoder training - SNNL, CPB = 600, Latent 250, WD = 0.001, SNN Factor 3\n",
    "\n",
    "## BASELINE AUTOENCODERS \n",
    "AE_RUNMODE = 'base'\n",
    "AE_DATETIME = \"20240923_1943\"     # Autoencoder training - Baseline, CPB = 600, Latent 150, WD = 0.001 (SNN Factor 0)\n",
    "# AE_DATETIME = \"20240917_2017\"     # Autoencoder training - Baseline, CPB = 600, Latent 250, WD = 0.001 (SNN Factor 0)\n",
    "\n",
    "AE_CKPTTYPE = \"BEST\"\n",
    "# AE_CKPTTYPE = \"LAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a64a90-897f-4148-9618-d6f02fc40aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:51.843004Z",
     "iopub.status.busy": "2024-10-04T00:02:51.842258Z",
     "iopub.status.idle": "2024-10-04T00:02:51.879234Z",
     "shell.execute_reply": "2024-10-04T00:02:51.878537Z",
     "shell.execute_reply.started": "2024-10-04T00:02:51.842962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_{ep}\n"
     ]
    }
   ],
   "source": [
    "CKPT_FILE = f\"NN_{AE_RUNMODE.lower()}_embd600_{LATENT_DIM}Ltnt_512_{AE_DATETIME}_{AE_CKPTTYPE}_{RUN_DATETIME}_ep_{{ep}}\"\n",
    "print(CKPT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10caf953-60e3-4c04-b096-4ae6240b6a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:53.320372Z",
     "iopub.status.busy": "2024-10-04T00:02:53.319905Z",
     "iopub.status.idle": "2024-10-04T00:02:53.358407Z",
     "shell.execute_reply": "2024-10-04T00:02:53.357861Z",
     "shell.execute_reply.started": "2024-10-04T00:02:53.320330Z"
    }
   },
   "outputs": [],
   "source": [
    "## total rows = 346,542\n",
    "## Trn file sz: 312,000 \n",
    "## Train      : 277,200    (312_000 - (21,600 + 12,600 + 600) = 277,200\n",
    "## Validation :  21,600\n",
    "## Test       :  12,600\n",
    "## Leftover   :     600\n",
    "cellpainting_args = {'compounds_per_batch': COMPOUNDS_PER_BATCH,\n",
    "                     'train_start'        : 0,\n",
    "                     'train_end'          : 277_200,\n",
    "                     'val_start'          : 0,\n",
    "                     'val_end'            : 21_600,\n",
    "                     'test_start'         : 0,\n",
    "                     'test_end'           : 12_600,\n",
    "                     'tpsa_threshold'     : 100\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ef5adfe-2daa-4f35-a263-66bf0c97efa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:02:54.845383Z",
     "iopub.status.busy": "2024-10-04T00:02:54.844907Z",
     "iopub.status.idle": "2024-10-04T00:02:54.924283Z",
     "shell.execute_reply": "2024-10-04T00:02:54.923361Z",
     "shell.execute_reply.started": "2024-10-04T00:02:54.845341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:02:54,881 - utils.dataloader - INFO: -  Building CellPantingDataset for train\n",
      "2024-10-04 02:02:54,881 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train.csv\n",
      "2024-10-04 02:02:54,882 - utils.dataloader - INFO: -  type    :  train\n",
      "2024-10-04 02:02:54,883 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-04 02:02:54,884 - utils.dataloader - INFO: -  end     :  277200\n",
      "2024-10-04 02:02:54,884 - utils.dataloader - INFO: -  numrows :  277200\n",
      "2024-10-04 02:02:54,885 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-04 02:02:54,886 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-04 02:02:54,887 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-04 02:02:54,887 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-04 02:02:54,888 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-04 02:02:54,889 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-04 02:02:54,889 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-04 02:02:54,890 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 154\n",
      "2024-10-04 02:02:54,890 - utils.dataloader - INFO: -  Rows covered by 154 full size batches (1800 rows) per epoch:  277200\n",
      "2024-10-04 02:02:54,891 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-04 02:02:54,893 - utils.dataloader - INFO: -  \n",
      "2024-10-04 02:02:54,894 - utils.dataloader - INFO: -  Building CellPantingDataset for val\n",
      "2024-10-04 02:02:54,895 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train_sub_val.csv\n",
      "2024-10-04 02:02:54,895 - utils.dataloader - INFO: -  type    :  val\n",
      "2024-10-04 02:02:54,896 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-04 02:02:54,897 - utils.dataloader - INFO: -  end     :  21600\n",
      "2024-10-04 02:02:54,898 - utils.dataloader - INFO: -  numrows :  21600\n",
      "2024-10-04 02:02:54,898 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-04 02:02:54,899 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-04 02:02:54,899 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-04 02:02:54,900 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-04 02:02:54,900 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-04 02:02:54,901 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-04 02:02:54,902 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-04 02:02:54,902 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 12\n",
      "2024-10-04 02:02:54,903 - utils.dataloader - INFO: -  Rows covered by 12 full size batches (1800 rows) per epoch:  21600\n",
      "2024-10-04 02:02:54,903 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-04 02:02:54,904 - utils.dataloader - INFO: -  \n",
      "2024-10-04 02:02:54,905 - utils.dataloader - INFO: -  Building CellPantingDataset for test\n",
      "2024-10-04 02:02:54,905 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train_sub_test.csv\n",
      "2024-10-04 02:02:54,906 - utils.dataloader - INFO: -  type    :  test\n",
      "2024-10-04 02:02:54,907 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-04 02:02:54,910 - utils.dataloader - INFO: -  end     :  12600\n",
      "2024-10-04 02:02:54,911 - utils.dataloader - INFO: -  numrows :  12600\n",
      "2024-10-04 02:02:54,911 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-04 02:02:54,912 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-04 02:02:54,912 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-04 02:02:54,913 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-04 02:02:54,914 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-04 02:02:54,914 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-04 02:02:54,915 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-04 02:02:54,916 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 7\n",
      "2024-10-04 02:02:54,916 - utils.dataloader - INFO: -  Rows covered by 7 full size batches (1800 rows) per epoch:  12600\n",
      "2024-10-04 02:02:54,917 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-04 02:02:54,917 - utils.dataloader - INFO: -  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAIN_INPUT:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train.csv\n",
      " TEST_INPUT :  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train_sub_test.csv\n",
      " ALL_INPUT  :  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_base_20240923_1943_BEST_train_sub_val.csv\n",
      " load {}\n",
      " Dataset size: 277200   rows per batch: 1800  tpsa_threshold: 100\n",
      " Dataset size: 21600   rows per batch: 1800  tpsa_threshold: 100\n",
      " Dataset size: 12600   rows per batch: 1800  tpsa_threshold: 100\n"
     ]
    }
   ],
   "source": [
    "data_loader = define_datasets(cellpainting_args, AE_RUNMODE, AE_DATETIME, input_cols, AE_CKPTTYPE, INPUT_PATH, tpsa_threshold = TPSA_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1b152-c298-465b-9313-e1cc880f6149",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e03f3-163a-42d4-8055-7e39f9c3f8af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN_INPUT_FILE = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train.csv\"\n",
    "# TEST_INPUT_FILE  = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train_sub_test.csv\"\n",
    "# VAL_INPUT_FILE   = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train_sub_val.csv\"\n",
    "# # ALL_INPUT_FILE   = f\"3smpl_prfl_embedding_{num_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_sub_val.csv\"\n",
    "\n",
    "# print(TRAIN_INPUT_FILE)\n",
    "# print(TEST_INPUT_FILE)\n",
    "# print(VAL_INPUT_FILE)\n",
    "\n",
    "# TRAIN_INPUT = os.path.join(INPUT_PATH, TRAIN_INPUT_FILE)\n",
    "# TEST_INPUT  = os.path.join(INPUT_PATH, TEST_INPUT_FILE)\n",
    "# VAL_INPUT   = os.path.join(INPUT_PATH, VAL_INPUT_FILE)\n",
    "\n",
    "# print(f\" TRAIN_INPUT:  {TRAIN_INPUT}\")\n",
    "# print(f\" TEST_INPUT :  {TEST_INPUT }\")\n",
    "# print(f\" ALL_INPUT  :  {VAL_INPUT }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752eccf-171a-4851-ae70-22771fffa4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## total rows = 346,542\n",
    "## Trn file sz: 312,000 \n",
    "## Train      : 277,200    (312_000 - (21,600 + 12,600 + 600) = 277,200\n",
    "## Validation :  21,600\n",
    "## Test       :  12,600\n",
    "## Leftover   :     600\n",
    "# cellpainting_args = {'sample_size': 3,\n",
    "#                      'batch_size': 1,\n",
    "#                      'compounds_per_batch': 600,\n",
    "#                      'training_path'  : TRAIN_INPUT,\n",
    "#                      'validation_path': TRAIN_INPUT,\n",
    "#                      'test_path'      : TRAIN_INPUT,\n",
    "#                      'train_start'    : 0,\n",
    "#                      'train_end'      : 277_200,  # 277,200 samples\n",
    "#                      'val_start'      : 277_200,  # \n",
    "#                      'val_end'        : 298_800,  # 21_600 samples\n",
    "#                      'test_start'     : 298_800,  # \n",
    "#                      'test_end'       : 311_400,  # 12_600 samples\n",
    "#                     }\n",
    "\n",
    "# cellpainting_args = {'compounds_per_batch': COMPOUNDS_PER_BATCH,\n",
    "#                      'training_path'      : TRAIN_INPUT,\n",
    "#                      'validation_path'    :  VAL_INPUT,\n",
    "#                      'test_path'          : TEST_INPUT,\n",
    "#                      'train_start'        : 0,\n",
    "#                      'train_end'          : 277_200,\n",
    "#                      'val_start'          : 0,\n",
    "#                      'val_end'            : 21_600,\n",
    "#                      'test_start'         : 0,\n",
    "#                      'test_end'           : 12_600,\n",
    "#                      'tpsa_threshold'     : 100\n",
    "#                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80b685-550e-43a7-b48d-af4518aa718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cellpainting_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda57be-1cd6-4598-b05e-a1c8b68176df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Load CellPainting Dataset\n",
    "# data : keys to the dataset settings (and resulting keys in output dictionary)\n",
    "# dataset = dict()\n",
    "# data_loader = dict()\n",
    "\n",
    "# for datatype in ['train', 'val', 'test']:\n",
    "#     dataset[datatype] = CellpaintingDataset(type = datatype, **cellpainting_args)\n",
    "#     data_loader[datatype] = InfiniteDataLoader(dataset = dataset[datatype], batch_size=1, shuffle = False, num_workers = 0, \n",
    "#                                                collate_fn = partial(dynamic_collate_fn, tpsa_threshold = dataset[datatype].tpsa_threshold) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c6429-dd69-421c-8a5c-689558acc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_cellpainting_batch(batch_id, batch):\n",
    "#     # data, labels, plates, compounds, cmphash, other, labels_2\n",
    "#     features, label, well_ids, compound_id, cmphash, tpsa, label_2 = batch\n",
    "#     # label_2 = np.zeros_like(label)\n",
    "#     print(\"-\"*135)\n",
    "#     print(f\"  Batch Id: {batch_id}   {type(batch)}  Rows returned {len(batch[0])} features: {features.shape}  \")\n",
    "#     print(f\"+-----+------------------------------------------+----------------+--------------------------+------------------------------+-----+-----+--------------------------------------------------------+\")\n",
    "#     print(f\"| idx |   batch[2]                               |    batch[3]    |      batch[2]            |          batch[5]            | [1] | [1] |     batch[0]                                           | \") \n",
    "#     print(f\"|     | SRCE      BATCH     PLATE     WELL       |   COMPOUND_ID  |       CMPHASH / BIN      |  TPSA / Ln(TPSA) / Log(TPSA) | LBL |LBL2 |     FEATURES                                           | \")\n",
    "#     print(f\"+-----+------------------------------------------+----------------+--------------------------+------------------------------+-----+-----+--------------------------------------------------------+\")\n",
    "#          ###    0 | source_11 Batch2    EC000046  K04      | JCP2022_009278 |  7406361908543180200 -  8  |   0   |   62.78000    4.13964   1.79782 | [-0.4377299 -0.4474466  1.1898487  0.2051901]\n",
    "#          # \"  1 | source_10    | JCP2022_006020 | -9223347314827979542 |   10 |  0 | tensor([-0.6346, -0.6232, -1.6046])\"\n",
    "    \n",
    "#     for i in range(len(label)):\n",
    "#         print(f\"| {i:3d} | {well_ids[i,0][:9]:9s} {well_ids[i,1][:12]:12s}  {well_ids[i,2][:10]:10s}  {well_ids[i,3]:4s} |\"\\\n",
    "#               f\" {compound_id[i]:14s} | {cmphash[i,0]:20d}  {cmphash[i,1]:2d} |\"\\\n",
    "#               f\" {tpsa[i,0]:7.3f}  {tpsa[i,1]:8.5f}  {tpsa[i,2]:8.5f}  |\"\n",
    "#               f\" {int(label[i]):2d}  | {int(label_2[i]):2d}  |\"\\\n",
    "#               f\" {features[i,:4].detach().cpu().numpy()}\")\n",
    "#         # print(f\"| {i:3d} | {batch[2][i,0]:9s} {batch[2][i,1][:9]:9s} {str(batch[2][i,2])[:9]:9s} {batch[2][i,3]:>4s}       \"\\\n",
    "#         #       f\"|{batch[3][i]:12s} | {batch[4][i,0]:20d} - {batch[4][i,1]:2d}  \"\\\n",
    "#         #       f\"{batch[5][i,0]:11.5f}   {batch[5][i,1]:8.5f}  {batch[5][i,2]:8.5f} \"\\\n",
    "#         #       f\"|  {int(batch[1][i]):1d}  | {batch[0][i,:4].detach().cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465d0ad-2f89-45a5-9e48-a55da7c4fa47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # %%timeit\n",
    "# # for dataset in ['train', 'val', 'test']:\n",
    "# for dataset in ['test']:\n",
    "#     for idx, batch in enumerate(data_loader[dataset]):\n",
    "#         for b in batch :\n",
    "#             print(b.shape)\n",
    "#         display_cellpainting_batch(idx, batch)\n",
    "#         if idx == 0:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247a1cd-eda6-4231-9603-feab85fea20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------\n",
    "# #  Count pos/neg labels in each dataset\n",
    "# # -----------------------------------------\n",
    "# for datatype in ['train', 'val', 'test']:\n",
    "#     MINIBATCH_SIZE = data_loader[datatype].dataset.sample_size * data_loader[datatype].dataset.compounds_per_batch\n",
    "#     print(f\" {datatype.capitalize()} Minibatch size : {MINIBATCH_SIZE}\") \n",
    "# print()\n",
    "\n",
    "# for datatype in ['train', 'val', 'test']:\n",
    "#     minibatches = len(data_loader[datatype]) // MINIBATCH_SIZE\n",
    "#     ttl_rows, ttl_rows_2 = 0, 0\n",
    "#     ttl_pos_labels, ttl_pos_labels_2 = 0, 0\n",
    "#     with tqdm.tqdm(enumerate(data_loader[datatype]), initial=0, total = minibatches, position=0, file=sys.stdout,\n",
    "#                    leave= False, desc=f\" Count labels \") as t_warmup:\n",
    "#         for batch_count, (_, batch_labels, _, _, _, _, batch_labels_2) in t_warmup:\n",
    "#             ttl_rows += batch_labels.shape[0]\n",
    "#             ttl_rows_2 += batch_labels_2.shape[0]\n",
    "#             ttl_pos_labels += batch_labels.sum()\n",
    "#             ttl_pos_labels_2 += batch_labels_2.sum()\n",
    "#     ttl_neg_labels = ttl_rows - ttl_pos_labels\n",
    "#     ttl_neg_labels_2 = ttl_rows_2 - ttl_pos_labels_2\n",
    "#     ttl = f\"\\n Dataset: {datatype} -  len of {datatype} data loader: {len(data_loader[datatype])}   number of batches: {minibatches}\"\n",
    "#     print(ttl)\n",
    "#     print('-'*len(ttl))\n",
    "#     print(f\" total rows     : {ttl_rows:7d}\")\n",
    "#     print(f\" total pos rows : {ttl_pos_labels:7.0f} - {ttl_pos_labels*100.0/ttl_rows:5.2f}%         alternative pos rows : {ttl_pos_labels_2:7.0f} - {ttl_pos_labels_2*100.0/ttl_rows:5.2f}%      \")\n",
    "#     print(f\" total neg rows : {ttl_neg_labels:7.0f} - {ttl_neg_labels*100.0/ttl_rows:5.2f}%         alternative neg rows : {ttl_neg_labels_2:7.0f} - {ttl_neg_labels_2*100.0/ttl_rows:5.2f}%\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424ff70-bcba-4702-bbb1-9d1871a5489d",
   "metadata": {},
   "source": [
    "     Minibatch size : 1800 \n",
    "                                                                                                 \n",
    "     Dataset: train - len of train data loader: 277200   number of batches: 154  \n",
    "    ------------------------------\n",
    "     total rows     :  277200\n",
    "     total pos rows :   33129 - 11.95%\n",
    "     total neg rows :  244071 - 88.05%\n",
    "\n",
    "     Dataset: val - len of val data loader: 21600   number of batches: 12\n",
    "    ------------------------------\n",
    "     total rows     :   21600\n",
    "     total pos rows :    2532 - 11.72%\n",
    "     total neg rows :   19068 - 88.28%\n",
    "    \n",
    "     Dataset: test - len of test data loader: 12600   number of batches: 7\n",
    "    ------------------------------\n",
    "     total rows     :   12600\n",
    "     total pos rows :    1431 - 11.36%\n",
    "     total neg rows :   11169 - 88.64%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84c48960-0808-47d4-bf2e-b0e5c00cace3",
   "metadata": {},
   "source": [
    "# Define Neural Net Model \n",
    "\n",
    "- **4 layer model :**\n",
    "\n",
    "    Input --> Hidden1 --> (BN/NL) ---> Hidden2 ---> (BN/NL) ---> Hidden3 --->  (BN/NL) ---> 1\n",
    "   \n",
    "    -  **20240909_1800** : Run on 4 FC layers model (includes final layer), model configuration UNKNOWN\n",
    "    -  **20240909_1801** : Run on 4 FC layers model (includes final layer), Relu non linearities (NO Batch Norm)\n",
    "    -  **20240909_2100** : Run on 4 FC layers model (includes final layer), with BATCH NORM and tanh non linearities\n",
    "\n",
    "      \n",
    " - **Single Hidden Layer - 256**\n",
    "\n",
    "   Input --> Hidden1 --> (Tanh) --->  1\n",
    "    -  **20240916_1830** : Run on 1 FC layers model (includes final layer), Input --> 256 --> Tanh --> 1 ,  Read from 20240906_2201 (SNNL - CPB 600, LAT 150, SNN Factor 3)\n",
    "    -  **20240926_1900** : Run on 1 FC layers model (includes final layer), Input --> 256 --> Tanh --> 1 ,  Read from 20240917_2017 (BASELINE - CPB 600, LAT 250, SNN Factor 0)\n",
    "    -  **20240926_1930** : Run on 1 FC layers model (includes final layer), Input --> 256 --> Tanh --> 1 ,  Read from 20240917_2004 (SNNL - CPB 600, LAT 250, SNN Factor 3)\n",
    "    -  **20240926_2000** : Run on 1 FC layers model (includes final layer), Input --> 256 --> Tanh --> 1 ,  Read from 20240924_0146 (SNNL - CPB 600, LAT 250, SNN Factor 30)\n",
    "<br>\n",
    "\n",
    " - **Single Hidden Layer - 256**\n",
    "\n",
    "    -  **20240921_0700** : Run on 1 FC layers model (includes final layer), Input --> 512 --> Tanh --> 1 ,  Read from 20240906_2201 (SNNL - CPB 600, LAT 150, SNN Factor 3)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32c6590-d212-4f37-8ce1-4ee46fd4246a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:45:44.380055Z",
     "start_time": "2023-07-31T18:45:41.073911Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:03.736713Z",
     "iopub.status.busy": "2024-10-04T00:03:03.736236Z",
     "iopub.status.idle": "2024-10-04T00:03:03.892655Z",
     "shell.execute_reply": "2024-10-04T00:03:03.892055Z",
     "shell.execute_reply.started": "2024-10-04T00:03:03.736668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %                   Mult-Adds                 Trainable\n",
      "==============================================================================================================================================================================================\n",
      "Sequential                               [30, 150]                 [30, 1]                   --                             --                   --                        True\n",
      "├─Linear: 1-1                            [30, 150]                 [30, 256]                 38,656                     28.12%                   1,159,680                 True\n",
      "│    └─weight                                                                                ├─38,400\n",
      "│    └─bias                                                                                  └─256\n",
      "├─ReLU: 1-2                              [30, 256]                 [30, 256]                 --                             --                   --                        --\n",
      "├─Linear: 1-3                            [30, 256]                 [30, 256]                 65,792                     47.86%                   1,973,760                 True\n",
      "│    └─weight                                                                                ├─65,536\n",
      "│    └─bias                                                                                  └─256\n",
      "├─ReLU: 1-4                              [30, 256]                 [30, 256]                 --                             --                   --                        --\n",
      "├─Linear: 1-5                            [30, 256]                 [30, 128]                 32,896                     23.93%                   986,880                   True\n",
      "│    └─weight                                                                                ├─32,768\n",
      "│    └─bias                                                                                  └─128\n",
      "├─ReLU: 1-6                              [30, 128]                 [30, 128]                 --                             --                   --                        --\n",
      "├─Linear: 1-7                            [30, 128]                 [30, 1]                   129                         0.09%                   3,870                     True\n",
      "│    └─weight                                                                                ├─128\n",
      "│    └─bias                                                                                  └─1\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 137,473\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 4.12\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 0.55\n",
      "Estimated Total Size (MB): 0.72\n",
      "==============================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = build_model(MODEL_TYPE, input = n_input, hidden_1 = n_hidden_1, hidden_2 = n_hidden_2, hidden_3=n_hidden_3, device = device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "039939c2-5cbb-4f5f-a33e-614ae6acbbcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:48:09.459977Z",
     "start_time": "2023-07-31T18:48:09.429767Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:10.432668Z",
     "iopub.status.busy": "2024-10-04T00:03:10.432193Z",
     "iopub.status.idle": "2024-10-04T00:03:10.471488Z",
     "shell.execute_reply": "2024-10-04T00:03:10.470850Z",
     "shell.execute_reply.started": "2024-10-04T00:03:10.432626Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = { 'loss_trn' : [], 'acc_trn' : [], 'loss_val' : [], 'acc_val' : []}\n",
    "\n",
    "start_epoch, end_epoch = 0,0\n",
    "init_LR = 1.0e-3\n",
    "# curr_LR = init_LR\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_LR)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.3 , patience=20, cooldown=10,)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma=0.1, last_epoch =-1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.5, threshold=1.0e-06, patience=50, cooldown=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb012c-1066-4a40-ba6d-8bd792e06ffb",
   "metadata": {},
   "source": [
    "### Read checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d8cc5c1-a8b4-4488-ba18-c7b6180722ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:11.970833Z",
     "iopub.status.busy": "2024-10-04T00:03:11.970297Z",
     "iopub.status.idle": "2024-10-04T00:03:12.007308Z",
     "shell.execute_reply": "2024-10-04T00:03:12.006651Z",
     "shell.execute_reply.started": "2024-10-04T00:03:11.970790Z"
    }
   },
   "outputs": [],
   "source": [
    "# loaded_epoch\n",
    "# optimizer.state_dict()\n",
    "# scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d093781-edac-4acb-a6ed-8c9f322228e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:12.228802Z",
     "iopub.status.busy": "2024-10-04T00:03:12.228377Z",
     "iopub.status.idle": "2024-10-04T00:03:12.266477Z",
     "shell.execute_reply": "2024-10-04T00:03:12.265861Z",
     "shell.execute_reply.started": "2024-10-04T00:03:12.228765Z"
    }
   },
   "outputs": [],
   "source": [
    "# model, optimizer, scheudler, end_epoch = load_checkpoint(model, optimizer, scheduler, checkpoint_file.format(ep=100), ckpt_path = CKPT_PATH)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9599cdd1-7434-4360-aa21-d8130696ffc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:12.922493Z",
     "iopub.status.busy": "2024-10-04T00:03:12.922086Z",
     "iopub.status.idle": "2024-10-04T00:03:12.958041Z",
     "shell.execute_reply": "2024-10-04T00:03:12.957374Z",
     "shell.execute_reply.started": "2024-10-04T00:03:12.922458Z"
    }
   },
   "outputs": [],
   "source": [
    "# end_epoch\n",
    "# optimizer.state_dict()\n",
    "# scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53a7c8-de53-45ec-ac18-2519c89e3ce5",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31ec54be-10d4-4b6e-85c9-8175fab24f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:48:09.459977Z",
     "start_time": "2023-07-31T18:48:09.429767Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:15.798905Z",
     "iopub.status.busy": "2024-10-04T00:03:15.798274Z",
     "iopub.status.idle": "2024-10-04T00:03:15.837728Z",
     "shell.execute_reply": "2024-10-04T00:03:15.836996Z",
     "shell.execute_reply.started": "2024-10-04T00:03:15.798854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 600\n"
     ]
    }
   ],
   "source": [
    "# start_epoch = 0\n",
    "# start_epoch = loaded_epoch\n",
    "start_epoch = end_epoch\n",
    "end_epoch += 600\n",
    "# start_epoch, end_epoch = 0,100\n",
    "print(start_epoch, end_epoch)\n",
    "_ = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ae239-ec9d-4afc-aef9-387fa19d0ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T19:00:14.450630Z",
     "start_time": "2023-07-31T18:49:12.235999Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T00:03:17.065185Z",
     "iopub.status.busy": "2024-10-04T00:03:17.064745Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 02:03:32 | Ep:   1/ 600 | Trn loss:  0.381807 - Acc: 87.6317 | Val loss:  0.364279 - Acc: 88.2870 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 02:03:45 | Ep:   2/ 600 | Trn loss:  0.365917 - Acc: 88.0545 | Val loss:  0.358049 - Acc: 88.2824 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 02:03:59 | Ep:   3/ 600 | Trn loss:  0.362231 - Acc: 88.0577 | Val loss:  0.356640 - Acc: 88.2685 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 02:04:13 | Ep:   4/ 600 | Trn loss:  0.360207 - Acc: 88.0592 | Val loss:  0.357255 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 02:04:26 | Ep:   5/ 600 | Trn loss:  0.358952 - Acc: 88.0599 | Val loss:  0.359051 - Acc: 88.2778 | last_lr: 1.00000e-03  bad_ep: 2  cdwn: 0                              \n",
      " 02:04:40 | Ep:   6/ 600 | Trn loss:  0.358073 - Acc: 88.0595 | Val loss:  0.360766 - Acc: 88.2778 | last_lr: 1.00000e-03  bad_ep: 3  cdwn: 0                              \n",
      " 02:04:53 | Ep:   7/ 600 | Trn loss:  0.357162 - Acc: 88.0642 | Val loss:  0.361173 - Acc: 88.2824 | last_lr: 1.00000e-03  bad_ep: 4  cdwn: 0                              \n",
      " 02:05:07 | Ep:   8/ 600 | Trn loss:  0.356238 - Acc: 88.0689 | Val loss:  0.360468 - Acc: 88.2917 | last_lr: 1.00000e-03  bad_ep: 5  cdwn: 0                              \n",
      " 02:05:20 | Ep:   9/ 600 | Trn loss:  0.355257 - Acc: 88.0736 | Val loss:  0.359971 - Acc: 88.2963 | last_lr: 1.00000e-03  bad_ep: 6  cdwn: 0                              \n",
      " 02:05:34 | Ep:  10/ 600 | Trn loss:  0.354191 - Acc: 88.0783 | Val loss:  0.359756 - Acc: 88.2917 | last_lr: 1.00000e-03  bad_ep: 7  cdwn: 0                              \n",
      " 02:05:47 | Ep:  11/ 600 | Trn loss:  0.353144 - Acc: 88.0869 | Val loss:  0.359738 - Acc: 88.3056 | last_lr: 1.00000e-03  bad_ep: 8  cdwn: 0                              \n",
      " 02:06:01 | Ep:  12/ 600 | Trn loss:  0.351991 - Acc: 88.0905 | Val loss:  0.360901 - Acc: 88.2870 | last_lr: 1.00000e-03  bad_ep: 9  cdwn: 0                              \n",
      " 02:06:14 | Ep:  13/ 600 | Trn loss:  0.350789 - Acc: 88.1136 | Val loss:  0.360919 - Acc: 88.3009 | last_lr: 1.00000e-03  bad_ep: 10  cdwn: 0                             \n",
      " 02:06:28 | Ep:  14/ 600 | Trn loss:  0.349394 - Acc: 88.1302 | Val loss:  0.363259 - Acc: 88.2731 | last_lr: 1.00000e-03  bad_ep: 11  cdwn: 0                             \n",
      " 02:06:41 | Ep:  15/ 600 | Trn loss:  0.347939 - Acc: 88.1490 | Val loss:  0.364897 - Acc: 88.2176 | last_lr: 1.00000e-03  bad_ep: 12  cdwn: 0                             \n",
      " 02:06:55 | Ep:  16/ 600 | Trn loss:  0.346278 - Acc: 88.1656 | Val loss:  0.364662 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 13  cdwn: 0                             \n",
      " 02:07:08 | Ep:  17/ 600 | Trn loss:  0.343960 - Acc: 88.1973 | Val loss:  0.366859 - Acc: 88.2315 | last_lr: 1.00000e-03  bad_ep: 14  cdwn: 0                             \n",
      " 02:07:22 | Ep:  18/ 600 | Trn loss:  0.341967 - Acc: 88.2150 | Val loss:  0.368352 - Acc: 88.1806 | last_lr: 1.00000e-03  bad_ep: 15  cdwn: 0                             \n",
      " 02:07:35 | Ep:  19/ 600 | Trn loss:  0.339691 - Acc: 88.2569 | Val loss:  0.368538 - Acc: 88.1991 | last_lr: 1.00000e-03  bad_ep: 16  cdwn: 0                             \n",
      " 02:07:49 | Ep:  20/ 600 | Trn loss:  0.336805 - Acc: 88.2983 | Val loss:  0.369669 - Acc: 88.1620 | last_lr: 1.00000e-03  bad_ep: 17  cdwn: 0                             \n",
      " 02:08:03 | Ep:  21/ 600 | Trn loss:  0.334342 - Acc: 88.3362 | Val loss:  0.372529 - Acc: 88.1944 | last_lr: 1.00000e-03  bad_ep: 18  cdwn: 0                             \n",
      " 02:08:18 | Ep:  22/ 600 | Trn loss:  0.331742 - Acc: 88.3867 | Val loss:  0.376674 - Acc: 88.1250 | last_lr: 1.00000e-03  bad_ep: 19  cdwn: 0                             \n",
      " 02:08:32 | Ep:  23/ 600 | Trn loss:  0.328723 - Acc: 88.4134 | Val loss:  0.381567 - Acc: 88.1806 | last_lr: 1.00000e-03  bad_ep: 20  cdwn: 0                             \n",
      " 02:08:46 | Ep:  24/ 600 | Trn loss:  0.325946 - Acc: 88.4636 | Val loss:  0.385647 - Acc: 88.1019 | last_lr: 1.00000e-03  bad_ep: 21  cdwn: 0                             \n",
      " 02:09:00 | Ep:  25/ 600 | Trn loss:  0.323257 - Acc: 88.5198 | Val loss:  0.388732 - Acc: 88.0139 | last_lr: 1.00000e-03  bad_ep: 22  cdwn: 0                             \n",
      " 02:09:15 | Ep:  26/ 600 | Trn loss:  0.320542 - Acc: 88.5483 | Val loss:  0.392747 - Acc: 87.9954 | last_lr: 1.00000e-03  bad_ep: 23  cdwn: 0                             \n",
      " 02:09:29 | Ep:  27/ 600 | Trn loss:  0.317529 - Acc: 88.5942 | Val loss:  0.400155 - Acc: 87.8565 | last_lr: 1.00000e-03  bad_ep: 24  cdwn: 0                             \n",
      " 02:09:43 | Ep:  28/ 600 | Trn loss:  0.314733 - Acc: 88.6641 | Val loss:  0.404486 - Acc: 87.7176 | last_lr: 1.00000e-03  bad_ep: 25  cdwn: 0                             \n",
      " 02:09:57 | Ep:  29/ 600 | Trn loss:  0.311610 - Acc: 88.7305 | Val loss:  0.412580 - Acc: 87.6250 | last_lr: 1.00000e-03  bad_ep: 26  cdwn: 0                             \n",
      " 02:10:11 | Ep:  30/ 600 | Trn loss:  0.309088 - Acc: 88.7680 | Val loss:  0.411486 - Acc: 87.6713 | last_lr: 1.00000e-03  bad_ep: 27  cdwn: 0                             \n",
      " 02:10:25 | Ep:  31/ 600 | Trn loss:  0.305860 - Acc: 88.8517 | Val loss:  0.413830 - Acc: 87.6389 | last_lr: 1.00000e-03  bad_ep: 28  cdwn: 0                             \n",
      " 02:10:39 | Ep:  32/ 600 | Trn loss:  0.302496 - Acc: 88.9430 | Val loss:  0.424203 - Acc: 87.7546 | last_lr: 1.00000e-03  bad_ep: 29  cdwn: 0                             \n",
      " 02:10:53 | Ep:  33/ 600 | Trn loss:  0.299919 - Acc: 89.0195 | Val loss:  0.427413 - Acc: 87.6713 | last_lr: 1.00000e-03  bad_ep: 30  cdwn: 0                             \n",
      " 02:11:08 | Ep:  34/ 600 | Trn loss:  0.297578 - Acc: 89.0437 | Val loss:  0.428878 - Acc: 87.6481 | last_lr: 1.00000e-03  bad_ep: 31  cdwn: 0                             \n",
      " 02:11:22 | Ep:  35/ 600 | Trn loss:  0.295812 - Acc: 89.1190 | Val loss:  0.434963 - Acc: 87.5694 | last_lr: 1.00000e-03  bad_ep: 32  cdwn: 0                             \n",
      " 02:11:36 | Ep:  36/ 600 | Trn loss:  0.293801 - Acc: 89.1447 | Val loss:  0.444284 - Acc: 87.5880 | last_lr: 1.00000e-03  bad_ep: 33  cdwn: 0                             \n",
      " 02:11:50 | Ep:  37/ 600 | Trn loss:  0.291046 - Acc: 89.2215 | Val loss:  0.453685 - Acc: 87.4815 | last_lr: 1.00000e-03  bad_ep: 34  cdwn: 0                             \n",
      " 02:12:04 | Ep:  38/ 600 | Trn loss:  0.288395 - Acc: 89.3041 | Val loss:  0.457021 - Acc: 87.6667 | last_lr: 1.00000e-03  bad_ep: 35  cdwn: 0                             \n",
      " 02:12:18 | Ep:  39/ 600 | Trn loss:  0.286762 - Acc: 89.3568 | Val loss:  0.464744 - Acc: 87.5417 | last_lr: 1.00000e-03  bad_ep: 36  cdwn: 0                             \n",
      " 02:12:32 | Ep:  40/ 600 | Trn loss:  0.284260 - Acc: 89.4466 | Val loss:  0.465967 - Acc: 87.4861 | last_lr: 1.00000e-03  bad_ep: 37  cdwn: 0                             \n",
      " 02:12:46 | Ep:  41/ 600 | Trn loss:  0.283112 - Acc: 89.4239 | Val loss:  0.469189 - Acc: 87.3843 | last_lr: 1.00000e-03  bad_ep: 38  cdwn: 0                             \n",
      " 02:13:00 | Ep:  42/ 600 | Trn loss:  0.282092 - Acc: 89.4513 | Val loss:  0.474318 - Acc: 87.3472 | last_lr: 1.00000e-03  bad_ep: 39  cdwn: 0                             \n",
      " 02:13:14 | Ep:  43/ 600 | Trn loss:  0.279580 - Acc: 89.5133 | Val loss:  0.476521 - Acc: 87.3611 | last_lr: 1.00000e-03  bad_ep: 40  cdwn: 0                             \n",
      " 02:13:29 | Ep:  44/ 600 | Trn loss:  0.278030 - Acc: 89.5740 | Val loss:  0.479425 - Acc: 87.2315 | last_lr: 1.00000e-03  bad_ep: 41  cdwn: 0                             \n",
      " 02:13:43 | Ep:  45/ 600 | Trn loss:  0.276687 - Acc: 89.6046 | Val loss:  0.475811 - Acc: 87.4074 | last_lr: 1.00000e-03  bad_ep: 42  cdwn: 0                             \n",
      " 02:13:57 | Ep:  46/ 600 | Trn loss:  0.273707 - Acc: 89.6595 | Val loss:  0.480189 - Acc: 87.3009 | last_lr: 1.00000e-03  bad_ep: 43  cdwn: 0                             \n",
      " 02:14:11 | Ep:  47/ 600 | Trn loss:  0.273261 - Acc: 89.6966 | Val loss:  0.479015 - Acc: 87.2500 | last_lr: 1.00000e-03  bad_ep: 44  cdwn: 0                             \n",
      " 02:14:25 | Ep:  48/ 600 | Trn loss:  0.271902 - Acc: 89.7269 | Val loss:  0.479301 - Acc: 87.1204 | last_lr: 1.00000e-03  bad_ep: 45  cdwn: 0                             \n",
      " 02:14:39 | Ep:  49/ 600 | Trn loss:  0.269722 - Acc: 89.8038 | Val loss:  0.480433 - Acc: 87.1019 | last_lr: 1.00000e-03  bad_ep: 46  cdwn: 0                             \n",
      " 02:14:53 | Ep:  50/ 600 | Trn loss:  0.267305 - Acc: 89.8701 | Val loss:  0.491396 - Acc: 87.0278 | last_lr: 1.00000e-03  bad_ep: 47  cdwn: 0                             \n",
      " 02:15:07 | Ep:  51/ 600 | Trn loss:  0.264659 - Acc: 89.9408 | Val loss:  0.497248 - Acc: 86.9954 | last_lr: 1.00000e-03  bad_ep: 48  cdwn: 0                             \n",
      " 02:15:21 | Ep:  52/ 600 | Trn loss:  0.263130 - Acc: 90.0032 | Val loss:  0.493228 - Acc: 87.0833 | last_lr: 1.00000e-03  bad_ep: 49  cdwn: 0                             \n",
      " 02:15:35 | Ep:  53/ 600 | Trn loss:  0.262581 - Acc: 90.0011 | Val loss:  0.497065 - Acc: 87.1019 | last_lr: 1.00000e-03  bad_ep: 50  cdwn: 0                             \n",
      " 02:15:49 | Ep:  54/ 600 | Trn loss:  0.262335 - Acc: 90.0289 | Val loss:  0.504784 - Acc: 87.2361 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 02:16:03 | Ep:  55/ 600 | Trn loss:  0.279826 - Acc: 89.4473 | Val loss:  0.475548 - Acc: 86.0972 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 02:16:17 | Ep:  56/ 600 | Trn loss:  0.273735 - Acc: 89.6890 | Val loss:  0.483995 - Acc: 85.9074 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 02:16:31 | Ep:  57/ 600 | Trn loss:  0.266894 - Acc: 89.9134 | Val loss:  0.489123 - Acc: 85.8843 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 02:16:45 | Ep:  58/ 600 | Trn loss:  0.261610 - Acc: 90.1241 | Val loss:  0.494639 - Acc: 85.8148 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 02:16:59 | Ep:  59/ 600 | Trn loss:  0.256891 - Acc: 90.3222 | Val loss:  0.499736 - Acc: 85.8519 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 02:17:13 | Ep:  60/ 600 | Trn loss:  0.252620 - Acc: 90.4794 | Val loss:  0.505135 - Acc: 85.7824 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 02:17:28 | Ep:  61/ 600 | Trn loss:  0.248482 - Acc: 90.6425 | Val loss:  0.512875 - Acc: 85.6157 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 02:17:42 | Ep:  62/ 600 | Trn loss:  0.244560 - Acc: 90.7951 | Val loss:  0.519260 - Acc: 85.5880 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 2                              \n",
      " 02:17:56 | Ep:  63/ 600 | Trn loss:  0.240946 - Acc: 90.9120 | Val loss:  0.526838 - Acc: 85.4167 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 1                              \n",
      " 02:18:10 | Ep:  64/ 600 | Trn loss:  0.237677 - Acc: 91.0249 | Val loss:  0.532645 - Acc: 85.2593 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 02:18:24 | Ep:  65/ 600 | Trn loss:  0.234102 - Acc: 91.1450 | Val loss:  0.539188 - Acc: 85.2130 | last_lr: 5.00000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 02:18:38 | Ep:  66/ 600 | Trn loss:  0.230899 - Acc: 91.2825 | Val loss:  0.548518 - Acc: 85.1481 | last_lr: 5.00000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 02:18:52 | Ep:  67/ 600 | Trn loss:  0.227856 - Acc: 91.3889 | Val loss:  0.556648 - Acc: 84.9074 | last_lr: 5.00000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 02:19:06 | Ep:  68/ 600 | Trn loss:  0.225418 - Acc: 91.4877 | Val loss:  0.563675 - Acc: 85.0602 | last_lr: 5.00000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 02:19:20 | Ep:  69/ 600 | Trn loss:  0.223546 - Acc: 91.5285 | Val loss:  0.569327 - Acc: 84.8333 | last_lr: 5.00000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 02:19:33 | Ep:  70/ 600 | Trn loss:  0.220800 - Acc: 91.6032 | Val loss:  0.576247 - Acc: 84.7870 | last_lr: 5.00000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 02:19:48 | Ep:  71/ 600 | Trn loss:  0.218202 - Acc: 91.6930 | Val loss:  0.581592 - Acc: 84.6574 | last_lr: 5.00000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 02:20:02 | Ep:  72/ 600 | Trn loss:  0.214695 - Acc: 91.8427 | Val loss:  0.591198 - Acc: 84.6296 | last_lr: 5.00000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 02:20:15 | Ep:  73/ 600 | Trn loss:  0.211346 - Acc: 91.9690 | Val loss:  0.600667 - Acc: 84.5093 | last_lr: 5.00000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 02:20:29 | Ep:  74/ 600 | Trn loss:  0.208278 - Acc: 92.1068 | Val loss:  0.610352 - Acc: 84.3611 | last_lr: 5.00000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 02:20:43 | Ep:  75/ 600 | Trn loss:  0.205581 - Acc: 92.2132 | Val loss:  0.620413 - Acc: 84.1806 | last_lr: 5.00000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 02:20:57 | Ep:  76/ 600 | Trn loss:  0.203261 - Acc: 92.3265 | Val loss:  0.628941 - Acc: 84.1019 | last_lr: 5.00000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 02:21:11 | Ep:  77/ 600 | Trn loss:  0.201718 - Acc: 92.3683 | Val loss:  0.634358 - Acc: 83.9722 | last_lr: 5.00000e-04  bad_ep: 13  cdwn: 0                             \n",
      " 02:21:25 | Ep:  78/ 600 | Trn loss:  0.200355 - Acc: 92.4098 | Val loss:  0.638835 - Acc: 83.7130 | last_lr: 5.00000e-04  bad_ep: 14  cdwn: 0                             \n",
      " 02:21:38 | Ep:  79/ 600 | Trn loss:  0.198569 - Acc: 92.4740 | Val loss:  0.648270 - Acc: 83.7639 | last_lr: 5.00000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 02:21:51 | Ep:  80/ 600 | Trn loss:  0.196314 - Acc: 92.5689 | Val loss:  0.657817 - Acc: 83.6991 | last_lr: 5.00000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 02:22:05 | Ep:  81/ 600 | Trn loss:  0.195427 - Acc: 92.5786 | Val loss:  0.662575 - Acc: 83.7407 | last_lr: 5.00000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 02:22:18 | Ep:  82/ 600 | Trn loss:  0.193200 - Acc: 92.6807 | Val loss:  0.665927 - Acc: 83.8657 | last_lr: 5.00000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 02:22:32 | Ep:  83/ 600 | Trn loss:  0.193146 - Acc: 92.6696 | Val loss:  0.674025 - Acc: 83.3148 | last_lr: 5.00000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 02:22:46 | Ep:  84/ 600 | Trn loss:  0.188931 - Acc: 92.8272 | Val loss:  0.683417 - Acc: 83.3426 | last_lr: 5.00000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 02:22:59 | Ep:  85/ 600 | Trn loss:  0.185894 - Acc: 92.9639 | Val loss:  0.691596 - Acc: 83.3843 | last_lr: 5.00000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 02:23:13 | Ep:  86/ 600 | Trn loss:  0.183957 - Acc: 93.0675 | Val loss:  0.701352 - Acc: 83.4213 | last_lr: 5.00000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 02:23:26 | Ep:  87/ 600 | Trn loss:  0.183001 - Acc: 93.1006 | Val loss:  0.711455 - Acc: 83.3287 | last_lr: 5.00000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 02:23:40 | Ep:  88/ 600 | Trn loss:  0.180791 - Acc: 93.1742 | Val loss:  0.721459 - Acc: 83.1667 | last_lr: 5.00000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 02:23:54 | Ep:  89/ 600 | Trn loss:  0.180464 - Acc: 93.1815 | Val loss:  0.727153 - Acc: 83.1435 | last_lr: 5.00000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 02:24:07 | Ep:  90/ 600 | Trn loss:  0.180376 - Acc: 93.1645 | Val loss:  0.743011 - Acc: 83.1111 | last_lr: 5.00000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 02:24:21 | Ep:  91/ 600 | Trn loss:  0.179794 - Acc: 93.1656 | Val loss:  0.746004 - Acc: 83.0694 | last_lr: 5.00000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 02:24:34 | Ep:  92/ 600 | Trn loss:  0.177081 - Acc: 93.2561 | Val loss:  0.755888 - Acc: 82.9676 | last_lr: 5.00000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 02:24:48 | Ep:  93/ 600 | Trn loss:  0.174917 - Acc: 93.3608 | Val loss:  0.761291 - Acc: 82.8935 | last_lr: 5.00000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 02:25:02 | Ep:  94/ 600 | Trn loss:  0.173543 - Acc: 93.4224 | Val loss:  0.767960 - Acc: 82.8426 | last_lr: 5.00000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 02:25:15 | Ep:  95/ 600 | Trn loss:  0.172338 - Acc: 93.4740 | Val loss:  0.776526 - Acc: 83.0880 | last_lr: 5.00000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 02:25:29 | Ep:  96/ 600 | Trn loss:  0.173034 - Acc: 93.4419 | Val loss:  0.779987 - Acc: 82.7407 | last_lr: 5.00000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 02:25:43 | Ep:  97/ 600 | Trn loss:  0.172084 - Acc: 93.4423 | Val loss:  0.792096 - Acc: 82.2778 | last_lr: 5.00000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 02:25:57 | Ep:  98/ 600 | Trn loss:  0.169853 - Acc: 93.4978 | Val loss:  0.793009 - Acc: 82.3287 | last_lr: 5.00000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 02:26:11 | Ep:  99/ 600 | Trn loss:  0.166740 - Acc: 93.6793 | Val loss:  0.805185 - Acc: 82.1759 | last_lr: 5.00000e-04  bad_ep: 35  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:26:25,861 - utils.utils_cellpainting - INFO: -  Model exported to NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_100.pt - epoch: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 02:26:25 | Ep: 100/ 600 | Trn loss:  0.164572 - Acc: 93.7670 | Val loss:  0.819779 - Acc: 82.0741 | last_lr: 5.00000e-04  bad_ep: 36  cdwn: 0 \n",
      " 02:26:39 | Ep: 101/ 600 | Trn loss:  0.163367 - Acc: 93.8009 | Val loss:  0.823831 - Acc: 82.2778 | last_lr: 5.00000e-04  bad_ep: 37  cdwn: 0                             \n",
      " 02:26:52 | Ep: 102/ 600 | Trn loss:  0.162690 - Acc: 93.8232 | Val loss:  0.836492 - Acc: 82.3241 | last_lr: 5.00000e-04  bad_ep: 38  cdwn: 0                             \n",
      " 02:27:06 | Ep: 103/ 600 | Trn loss:  0.164784 - Acc: 93.7291 | Val loss:  0.844410 - Acc: 82.0741 | last_lr: 5.00000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 02:27:20 | Ep: 104/ 600 | Trn loss:  0.165327 - Acc: 93.6522 | Val loss:  0.859241 - Acc: 82.3056 | last_lr: 5.00000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 02:27:34 | Ep: 105/ 600 | Trn loss:  0.165222 - Acc: 93.6703 | Val loss:  0.856850 - Acc: 82.6250 | last_lr: 5.00000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 02:27:48 | Ep: 106/ 600 | Trn loss:  0.165460 - Acc: 93.5905 | Val loss:  0.869356 - Acc: 82.2546 | last_lr: 5.00000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 02:28:02 | Ep: 107/ 600 | Trn loss:  0.162794 - Acc: 93.7211 | Val loss:  0.870352 - Acc: 82.4306 | last_lr: 5.00000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 02:28:15 | Ep: 108/ 600 | Trn loss:  0.161494 - Acc: 93.7882 | Val loss:  0.873287 - Acc: 81.9444 | last_lr: 5.00000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 02:28:29 | Ep: 109/ 600 | Trn loss:  0.159115 - Acc: 93.9058 | Val loss:  0.887234 - Acc: 81.6713 | last_lr: 5.00000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 02:28:43 | Ep: 110/ 600 | Trn loss:  0.158274 - Acc: 93.9426 | Val loss:  0.892225 - Acc: 81.3241 | last_lr: 5.00000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 02:28:57 | Ep: 111/ 600 | Trn loss:  0.157727 - Acc: 93.9625 | Val loss:  0.899961 - Acc: 81.3380 | last_lr: 5.00000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 02:29:11 | Ep: 112/ 600 | Trn loss:  0.156086 - Acc: 94.0321 | Val loss:  0.906438 - Acc: 80.9676 | last_lr: 5.00000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 02:29:25 | Ep: 113/ 600 | Trn loss:  0.155804 - Acc: 94.0718 | Val loss:  0.913954 - Acc: 81.2639 | last_lr: 5.00000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 02:29:39 | Ep: 114/ 600 | Trn loss:  0.153651 - Acc: 94.1461 | Val loss:  0.918997 - Acc: 81.7870 | last_lr: 5.00000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 02:29:53 | Ep: 115/ 600 | Trn loss:  0.151861 - Acc: 94.2605 | Val loss:  0.932429 - Acc: 81.9954 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 02:30:07 | Ep: 116/ 600 | Trn loss:  0.176148 - Acc: 92.9307 | Val loss:  0.908914 - Acc: 82.8009 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 02:30:21 | Ep: 117/ 600 | Trn loss:  0.177101 - Acc: 92.8770 | Val loss:  0.913303 - Acc: 81.2731 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 02:30:35 | Ep: 118/ 600 | Trn loss:  0.175079 - Acc: 92.9834 | Val loss:  0.921338 - Acc: 80.9259 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 02:30:49 | Ep: 119/ 600 | Trn loss:  0.173703 - Acc: 93.0786 | Val loss:  0.920776 - Acc: 81.1713 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 02:31:03 | Ep: 120/ 600 | Trn loss:  0.172070 - Acc: 93.1872 | Val loss:  0.926447 - Acc: 81.2454 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 02:31:17 | Ep: 121/ 600 | Trn loss:  0.170089 - Acc: 93.3178 | Val loss:  0.928666 - Acc: 81.2593 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 02:31:31 | Ep: 122/ 600 | Trn loss:  0.168131 - Acc: 93.4253 | Val loss:  0.935892 - Acc: 81.1481 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 02:31:45 | Ep: 123/ 600 | Trn loss:  0.166214 - Acc: 93.5227 | Val loss:  0.941345 - Acc: 81.1019 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 2                              \n",
      " 02:31:59 | Ep: 124/ 600 | Trn loss:  0.164420 - Acc: 93.6162 | Val loss:  0.944433 - Acc: 81.0324 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 1                              \n",
      " 02:32:13 | Ep: 125/ 600 | Trn loss:  0.162327 - Acc: 93.7298 | Val loss:  0.947841 - Acc: 81.1019 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 02:32:26 | Ep: 126/ 600 | Trn loss:  0.160322 - Acc: 93.8398 | Val loss:  0.952202 - Acc: 81.0602 | last_lr: 2.50000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 02:32:40 | Ep: 127/ 600 | Trn loss:  0.158469 - Acc: 93.9315 | Val loss:  0.953192 - Acc: 81.1389 | last_lr: 2.50000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 02:32:54 | Ep: 128/ 600 | Trn loss:  0.156875 - Acc: 94.0202 | Val loss:  0.962814 - Acc: 81.1528 | last_lr: 2.50000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 02:33:08 | Ep: 129/ 600 | Trn loss:  0.155360 - Acc: 94.0927 | Val loss:  0.964887 - Acc: 81.2407 | last_lr: 2.50000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 02:33:22 | Ep: 130/ 600 | Trn loss:  0.154439 - Acc: 94.1465 | Val loss:  0.966705 - Acc: 81.2639 | last_lr: 2.50000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 02:33:35 | Ep: 131/ 600 | Trn loss:  0.152388 - Acc: 94.2060 | Val loss:  0.967198 - Acc: 81.3657 | last_lr: 2.50000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 02:33:49 | Ep: 132/ 600 | Trn loss:  0.151367 - Acc: 94.2799 | Val loss:  0.974893 - Acc: 81.2037 | last_lr: 2.50000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 02:34:03 | Ep: 133/ 600 | Trn loss:  0.149673 - Acc: 94.3557 | Val loss:  0.982653 - Acc: 81.2315 | last_lr: 2.50000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 02:34:17 | Ep: 134/ 600 | Trn loss:  0.147876 - Acc: 94.4657 | Val loss:  0.987688 - Acc: 81.2500 | last_lr: 2.50000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 02:34:31 | Ep: 135/ 600 | Trn loss:  0.146078 - Acc: 94.5400 | Val loss:  0.993109 - Acc: 81.1898 | last_lr: 2.50000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 02:34:44 | Ep: 136/ 600 | Trn loss:  0.144652 - Acc: 94.6053 | Val loss:  1.000656 - Acc: 81.3009 | last_lr: 2.50000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 02:34:58 | Ep: 137/ 600 | Trn loss:  0.142731 - Acc: 94.7013 | Val loss:  1.008412 - Acc: 81.2269 | last_lr: 2.50000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 02:35:12 | Ep: 138/ 600 | Trn loss:  0.140937 - Acc: 94.7832 | Val loss:  1.015839 - Acc: 81.2222 | last_lr: 2.50000e-04  bad_ep: 13  cdwn: 0                             \n",
      " 02:35:26 | Ep: 139/ 600 | Trn loss:  0.139316 - Acc: 94.8582 | Val loss:  1.023846 - Acc: 81.2454 | last_lr: 2.50000e-04  bad_ep: 14  cdwn: 0                             \n",
      " 02:35:40 | Ep: 140/ 600 | Trn loss:  0.137741 - Acc: 94.9459 | Val loss:  1.030690 - Acc: 81.1620 | last_lr: 2.50000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 02:35:54 | Ep: 141/ 600 | Trn loss:  0.136184 - Acc: 95.0184 | Val loss:  1.037348 - Acc: 81.1944 | last_lr: 2.50000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 02:36:08 | Ep: 142/ 600 | Trn loss:  0.135016 - Acc: 95.0736 | Val loss:  1.040747 - Acc: 81.2731 | last_lr: 2.50000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 02:36:21 | Ep: 143/ 600 | Trn loss:  0.135384 - Acc: 95.0393 | Val loss:  1.049736 - Acc: 81.1667 | last_lr: 2.50000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 02:36:35 | Ep: 144/ 600 | Trn loss:  0.135579 - Acc: 95.0184 | Val loss:  1.052497 - Acc: 81.1713 | last_lr: 2.50000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 02:36:49 | Ep: 145/ 600 | Trn loss:  0.134351 - Acc: 95.0588 | Val loss:  1.058945 - Acc: 81.1574 | last_lr: 2.50000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 02:37:03 | Ep: 146/ 600 | Trn loss:  0.132178 - Acc: 95.1475 | Val loss:  1.066179 - Acc: 81.0324 | last_lr: 2.50000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 02:37:17 | Ep: 147/ 600 | Trn loss:  0.130208 - Acc: 95.2341 | Val loss:  1.071840 - Acc: 81.1389 | last_lr: 2.50000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 02:37:30 | Ep: 148/ 600 | Trn loss:  0.128449 - Acc: 95.3240 | Val loss:  1.077968 - Acc: 81.0278 | last_lr: 2.50000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 02:37:44 | Ep: 149/ 600 | Trn loss:  0.126588 - Acc: 95.4069 | Val loss:  1.085685 - Acc: 81.0324 | last_lr: 2.50000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 02:37:58 | Ep: 150/ 600 | Trn loss:  0.125146 - Acc: 95.4921 | Val loss:  1.093314 - Acc: 81.0417 | last_lr: 2.50000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 02:38:12 | Ep: 151/ 600 | Trn loss:  0.123797 - Acc: 95.5491 | Val loss:  1.102625 - Acc: 81.0139 | last_lr: 2.50000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 02:38:26 | Ep: 152/ 600 | Trn loss:  0.122508 - Acc: 95.6133 | Val loss:  1.109873 - Acc: 81.0694 | last_lr: 2.50000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 02:38:40 | Ep: 153/ 600 | Trn loss:  0.121251 - Acc: 95.6605 | Val loss:  1.119112 - Acc: 81.0648 | last_lr: 2.50000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 02:38:53 | Ep: 154/ 600 | Trn loss:  0.120080 - Acc: 95.7305 | Val loss:  1.129182 - Acc: 81.0046 | last_lr: 2.50000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 02:39:07 | Ep: 155/ 600 | Trn loss:  0.118918 - Acc: 95.7648 | Val loss:  1.136473 - Acc: 81.0093 | last_lr: 2.50000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 02:39:21 | Ep: 156/ 600 | Trn loss:  0.117879 - Acc: 95.8276 | Val loss:  1.147159 - Acc: 81.0509 | last_lr: 2.50000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 02:39:35 | Ep: 157/ 600 | Trn loss:  0.118786 - Acc: 95.7670 | Val loss:  1.158534 - Acc: 81.0093 | last_lr: 2.50000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 02:39:49 | Ep: 158/ 600 | Trn loss:  0.123706 - Acc: 95.5090 | Val loss:  1.155429 - Acc: 81.3426 | last_lr: 2.50000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 02:40:03 | Ep: 159/ 600 | Trn loss:  0.124992 - Acc: 95.4177 | Val loss:  1.159098 - Acc: 81.1713 | last_lr: 2.50000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 02:40:17 | Ep: 160/ 600 | Trn loss:  0.120205 - Acc: 95.6317 | Val loss:  1.166175 - Acc: 80.9398 | last_lr: 2.50000e-04  bad_ep: 35  cdwn: 0                             \n",
      " 02:40:30 | Ep: 161/ 600 | Trn loss:  0.117171 - Acc: 95.8120 | Val loss:  1.170333 - Acc: 80.8426 | last_lr: 2.50000e-04  bad_ep: 36  cdwn: 0                             \n",
      " 02:40:44 | Ep: 162/ 600 | Trn loss:  0.115273 - Acc: 95.9044 | Val loss:  1.179408 - Acc: 80.9028 | last_lr: 2.50000e-04  bad_ep: 37  cdwn: 0                             \n",
      " 02:40:58 | Ep: 163/ 600 | Trn loss:  0.113463 - Acc: 95.9812 | Val loss:  1.187730 - Acc: 80.9583 | last_lr: 2.50000e-04  bad_ep: 38  cdwn: 0                             \n",
      " 02:41:12 | Ep: 164/ 600 | Trn loss:  0.111924 - Acc: 96.0750 | Val loss:  1.195957 - Acc: 80.8750 | last_lr: 2.50000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 02:41:26 | Ep: 165/ 600 | Trn loss:  0.110679 - Acc: 96.1270 | Val loss:  1.204294 - Acc: 80.8889 | last_lr: 2.50000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 02:41:39 | Ep: 166/ 600 | Trn loss:  0.109559 - Acc: 96.1861 | Val loss:  1.212847 - Acc: 80.9722 | last_lr: 2.50000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 02:41:53 | Ep: 167/ 600 | Trn loss:  0.108484 - Acc: 96.2417 | Val loss:  1.221502 - Acc: 80.9120 | last_lr: 2.50000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 02:42:06 | Ep: 168/ 600 | Trn loss:  0.107460 - Acc: 96.2944 | Val loss:  1.230152 - Acc: 80.9120 | last_lr: 2.50000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 02:42:20 | Ep: 169/ 600 | Trn loss:  0.106537 - Acc: 96.3240 | Val loss:  1.237979 - Acc: 80.9120 | last_lr: 2.50000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 02:42:33 | Ep: 170/ 600 | Trn loss:  0.105796 - Acc: 96.3683 | Val loss:  1.241846 - Acc: 81.0046 | last_lr: 2.50000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 02:42:47 | Ep: 171/ 600 | Trn loss:  0.106311 - Acc: 96.3402 | Val loss:  1.246666 - Acc: 80.8241 | last_lr: 2.50000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 02:43:01 | Ep: 172/ 600 | Trn loss:  0.107766 - Acc: 96.2706 | Val loss:  1.267838 - Acc: 80.7778 | last_lr: 2.50000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 02:43:14 | Ep: 173/ 600 | Trn loss:  0.108446 - Acc: 96.2146 | Val loss:  1.252353 - Acc: 81.1343 | last_lr: 2.50000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 02:43:28 | Ep: 174/ 600 | Trn loss:  0.107020 - Acc: 96.2781 | Val loss:  1.265435 - Acc: 80.7963 | last_lr: 2.50000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 02:43:41 | Ep: 175/ 600 | Trn loss:  0.105075 - Acc: 96.3434 | Val loss:  1.277612 - Acc: 80.5926 | last_lr: 2.50000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 02:43:55 | Ep: 176/ 600 | Trn loss:  0.103688 - Acc: 96.4289 | Val loss:  1.281265 - Acc: 80.4769 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 02:44:08 | Ep: 177/ 600 | Trn loss:  0.112372 - Acc: 95.8395 | Val loss:  1.286403 - Acc: 80.9769 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 02:44:22 | Ep: 178/ 600 | Trn loss:  0.113054 - Acc: 95.7965 | Val loss:  1.276938 - Acc: 81.3565 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 02:44:35 | Ep: 179/ 600 | Trn loss:  0.112924 - Acc: 95.7976 | Val loss:  1.280256 - Acc: 81.4213 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 02:44:49 | Ep: 180/ 600 | Trn loss:  0.112529 - Acc: 95.8333 | Val loss:  1.282339 - Acc: 81.4213 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 02:45:03 | Ep: 181/ 600 | Trn loss:  0.111937 - Acc: 95.8658 | Val loss:  1.286404 - Acc: 81.4954 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 02:45:16 | Ep: 182/ 600 | Trn loss:  0.111289 - Acc: 95.9022 | Val loss:  1.289405 - Acc: 81.4491 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 02:45:30 | Ep: 183/ 600 | Trn loss:  0.110486 - Acc: 95.9560 | Val loss:  1.292811 - Acc: 81.4769 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 02:45:43 | Ep: 184/ 600 | Trn loss:  0.109654 - Acc: 96.0076 | Val loss:  1.296967 - Acc: 81.4306 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 2                              \n",
      " 02:45:57 | Ep: 185/ 600 | Trn loss:  0.108762 - Acc: 96.0534 | Val loss:  1.300845 - Acc: 81.4676 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 1                              \n",
      " 02:46:10 | Ep: 186/ 600 | Trn loss:  0.107815 - Acc: 96.0981 | Val loss:  1.304132 - Acc: 81.4583 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 02:46:24 | Ep: 187/ 600 | Trn loss:  0.106841 - Acc: 96.1526 | Val loss:  1.308110 - Acc: 81.4815 | last_lr: 1.25000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 02:46:37 | Ep: 188/ 600 | Trn loss:  0.105902 - Acc: 96.2013 | Val loss:  1.311475 - Acc: 81.4769 | last_lr: 1.25000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 02:46:51 | Ep: 189/ 600 | Trn loss:  0.104924 - Acc: 96.2569 | Val loss:  1.316512 - Acc: 81.5370 | last_lr: 1.25000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 02:47:04 | Ep: 190/ 600 | Trn loss:  0.103963 - Acc: 96.3110 | Val loss:  1.321127 - Acc: 81.5093 | last_lr: 1.25000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 02:47:18 | Ep: 191/ 600 | Trn loss:  0.103032 - Acc: 96.3611 | Val loss:  1.326259 - Acc: 81.5787 | last_lr: 1.25000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 02:47:31 | Ep: 192/ 600 | Trn loss:  0.102088 - Acc: 96.4012 | Val loss:  1.329236 - Acc: 81.5833 | last_lr: 1.25000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 02:47:45 | Ep: 193/ 600 | Trn loss:  0.101202 - Acc: 96.4499 | Val loss:  1.334704 - Acc: 81.5648 | last_lr: 1.25000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 02:47:58 | Ep: 194/ 600 | Trn loss:  0.100282 - Acc: 96.4957 | Val loss:  1.339325 - Acc: 81.6111 | last_lr: 1.25000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 02:48:12 | Ep: 195/ 600 | Trn loss:  0.099424 - Acc: 96.5465 | Val loss:  1.344796 - Acc: 81.5880 | last_lr: 1.25000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 02:48:25 | Ep: 196/ 600 | Trn loss:  0.098543 - Acc: 96.5786 | Val loss:  1.349386 - Acc: 81.6296 | last_lr: 1.25000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 02:48:39 | Ep: 197/ 600 | Trn loss:  0.097664 - Acc: 96.6194 | Val loss:  1.354125 - Acc: 81.6065 | last_lr: 1.25000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 02:48:52 | Ep: 198/ 600 | Trn loss:  0.096866 - Acc: 96.6598 | Val loss:  1.358747 - Acc: 81.5509 | last_lr: 1.25000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 02:49:06 | Ep: 199/ 600 | Trn loss:  0.095995 - Acc: 96.7020 | Val loss:  1.363771 - Acc: 81.5741 | last_lr: 1.25000e-04  bad_ep: 13  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:49:19,703 - utils.utils_cellpainting - INFO: -  Model exported to NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_200.pt - epoch: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 02:49:19 | Ep: 200/ 600 | Trn loss:  0.095167 - Acc: 96.7482 | Val loss:  1.369937 - Acc: 81.5694 | last_lr: 1.25000e-04  bad_ep: 14  cdwn: 0 \n",
      " 02:49:33 | Ep: 201/ 600 | Trn loss:  0.094388 - Acc: 96.7828 | Val loss:  1.374837 - Acc: 81.5093 | last_lr: 1.25000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 02:49:46 | Ep: 202/ 600 | Trn loss:  0.093858 - Acc: 96.8146 | Val loss:  1.377847 - Acc: 81.6065 | last_lr: 1.25000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 02:50:00 | Ep: 203/ 600 | Trn loss:  0.095036 - Acc: 96.7731 | Val loss:  1.376468 - Acc: 81.6065 | last_lr: 1.25000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 02:50:13 | Ep: 204/ 600 | Trn loss:  0.095440 - Acc: 96.7597 | Val loss:  1.380544 - Acc: 81.5093 | last_lr: 1.25000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 02:50:27 | Ep: 205/ 600 | Trn loss:  0.093539 - Acc: 96.8070 | Val loss:  1.384448 - Acc: 81.5648 | last_lr: 1.25000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 02:50:40 | Ep: 206/ 600 | Trn loss:  0.092124 - Acc: 96.8810 | Val loss:  1.393335 - Acc: 81.6435 | last_lr: 1.25000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 02:50:54 | Ep: 207/ 600 | Trn loss:  0.091054 - Acc: 96.9246 | Val loss:  1.399149 - Acc: 81.6435 | last_lr: 1.25000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 02:51:07 | Ep: 208/ 600 | Trn loss:  0.090261 - Acc: 96.9683 | Val loss:  1.404552 - Acc: 81.6065 | last_lr: 1.25000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 02:51:20 | Ep: 209/ 600 | Trn loss:  0.089545 - Acc: 97.0018 | Val loss:  1.409624 - Acc: 81.6435 | last_lr: 1.25000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 02:51:34 | Ep: 210/ 600 | Trn loss:  0.088830 - Acc: 97.0390 | Val loss:  1.414742 - Acc: 81.6065 | last_lr: 1.25000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 02:51:47 | Ep: 211/ 600 | Trn loss:  0.088142 - Acc: 97.0750 | Val loss:  1.419621 - Acc: 81.5602 | last_lr: 1.25000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 02:52:01 | Ep: 212/ 600 | Trn loss:  0.087466 - Acc: 97.1108 | Val loss:  1.425318 - Acc: 81.5556 | last_lr: 1.25000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 02:52:14 | Ep: 213/ 600 | Trn loss:  0.086825 - Acc: 97.1425 | Val loss:  1.430640 - Acc: 81.5370 | last_lr: 1.25000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 02:52:28 | Ep: 214/ 600 | Trn loss:  0.086190 - Acc: 97.1652 | Val loss:  1.435249 - Acc: 81.5602 | last_lr: 1.25000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 02:52:41 | Ep: 215/ 600 | Trn loss:  0.085505 - Acc: 97.2006 | Val loss:  1.441426 - Acc: 81.5139 | last_lr: 1.25000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 02:52:55 | Ep: 216/ 600 | Trn loss:  0.084847 - Acc: 97.2287 | Val loss:  1.446899 - Acc: 81.5000 | last_lr: 1.25000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 02:53:08 | Ep: 217/ 600 | Trn loss:  0.084226 - Acc: 97.2569 | Val loss:  1.452158 - Acc: 81.4630 | last_lr: 1.25000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 02:53:22 | Ep: 218/ 600 | Trn loss:  0.083607 - Acc: 97.2854 | Val loss:  1.459162 - Acc: 81.4259 | last_lr: 1.25000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 02:53:35 | Ep: 219/ 600 | Trn loss:  0.082964 - Acc: 97.3153 | Val loss:  1.466215 - Acc: 81.4259 | last_lr: 1.25000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 02:53:49 | Ep: 220/ 600 | Trn loss:  0.082376 - Acc: 97.3456 | Val loss:  1.471970 - Acc: 81.3704 | last_lr: 1.25000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 02:54:02 | Ep: 221/ 600 | Trn loss:  0.082028 - Acc: 97.3582 | Val loss:  1.478118 - Acc: 81.3241 | last_lr: 1.25000e-04  bad_ep: 35  cdwn: 0                             \n",
      " 02:54:16 | Ep: 222/ 600 | Trn loss:  0.081653 - Acc: 97.3918 | Val loss:  1.477353 - Acc: 81.3102 | last_lr: 1.25000e-04  bad_ep: 36  cdwn: 0                             \n",
      " 02:54:29 | Ep: 223/ 600 | Trn loss:  0.081733 - Acc: 97.3791 | Val loss:  1.485541 - Acc: 81.3519 | last_lr: 1.25000e-04  bad_ep: 37  cdwn: 0                             \n",
      " 02:54:43 | Ep: 224/ 600 | Trn loss:  0.081943 - Acc: 97.3561 | Val loss:  1.489810 - Acc: 81.3611 | last_lr: 1.25000e-04  bad_ep: 38  cdwn: 0                             \n",
      " 02:54:56 | Ep: 225/ 600 | Trn loss:  0.081215 - Acc: 97.3882 | Val loss:  1.496486 - Acc: 81.3657 | last_lr: 1.25000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 02:55:10 | Ep: 226/ 600 | Trn loss:  0.080409 - Acc: 97.4347 | Val loss:  1.509254 - Acc: 81.3148 | last_lr: 1.25000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 02:55:25 | Ep: 227/ 600 | Trn loss:  0.080521 - Acc: 97.4343 | Val loss:  1.511321 - Acc: 81.3102 | last_lr: 1.25000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 02:55:39 | Ep: 228/ 600 | Trn loss:  0.079460 - Acc: 97.4556 | Val loss:  1.520414 - Acc: 81.3796 | last_lr: 1.25000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 02:55:53 | Ep: 229/ 600 | Trn loss:  0.078457 - Acc: 97.5018 | Val loss:  1.522273 - Acc: 81.4306 | last_lr: 1.25000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 02:56:07 | Ep: 230/ 600 | Trn loss:  0.077951 - Acc: 97.5231 | Val loss:  1.528836 - Acc: 81.3889 | last_lr: 1.25000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 02:56:22 | Ep: 231/ 600 | Trn loss:  0.077161 - Acc: 97.5541 | Val loss:  1.535362 - Acc: 81.3611 | last_lr: 1.25000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 02:56:36 | Ep: 232/ 600 | Trn loss:  0.076558 - Acc: 97.5833 | Val loss:  1.541497 - Acc: 81.3519 | last_lr: 1.25000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 02:56:50 | Ep: 233/ 600 | Trn loss:  0.076005 - Acc: 97.6039 | Val loss:  1.547103 - Acc: 81.3148 | last_lr: 1.25000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 02:57:04 | Ep: 234/ 600 | Trn loss:  0.075482 - Acc: 97.6252 | Val loss:  1.553972 - Acc: 81.3333 | last_lr: 1.25000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 02:57:18 | Ep: 235/ 600 | Trn loss:  0.074983 - Acc: 97.6490 | Val loss:  1.560804 - Acc: 81.2778 | last_lr: 1.25000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 02:57:32 | Ep: 236/ 600 | Trn loss:  0.074463 - Acc: 97.6677 | Val loss:  1.567334 - Acc: 81.2269 | last_lr: 1.25000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 02:57:46 | Ep: 237/ 600 | Trn loss:  0.073956 - Acc: 97.6843 | Val loss:  1.573973 - Acc: 81.1991 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 10                             \n",
      " 02:58:01 | Ep: 238/ 600 | Trn loss:  0.077517 - Acc: 97.5025 | Val loss:  1.577994 - Acc: 81.7222 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 9                              \n",
      " 02:58:15 | Ep: 239/ 600 | Trn loss:  0.078051 - Acc: 97.4791 | Val loss:  1.580533 - Acc: 81.8750 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 8                              \n",
      " 02:58:29 | Ep: 240/ 600 | Trn loss:  0.077923 - Acc: 97.4841 | Val loss:  1.583471 - Acc: 81.8750 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 7                              \n",
      " 02:58:43 | Ep: 241/ 600 | Trn loss:  0.077673 - Acc: 97.4816 | Val loss:  1.586838 - Acc: 81.9213 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 6                              \n",
      " 02:58:57 | Ep: 242/ 600 | Trn loss:  0.077340 - Acc: 97.4928 | Val loss:  1.590259 - Acc: 81.8981 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 5                              \n",
      " 02:59:11 | Ep: 243/ 600 | Trn loss:  0.076966 - Acc: 97.5105 | Val loss:  1.593282 - Acc: 81.8750 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 4                              \n",
      " 02:59:25 | Ep: 244/ 600 | Trn loss:  0.076560 - Acc: 97.5245 | Val loss:  1.596545 - Acc: 81.8426 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 3                              \n",
      " 02:59:39 | Ep: 245/ 600 | Trn loss:  0.076126 - Acc: 97.5390 | Val loss:  1.599451 - Acc: 81.8102 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 2                              \n",
      " 02:59:53 | Ep: 246/ 600 | Trn loss:  0.075674 - Acc: 97.5639 | Val loss:  1.601945 - Acc: 81.8056 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 1                              \n",
      " 03:00:07 | Ep: 247/ 600 | Trn loss:  0.075200 - Acc: 97.5765 | Val loss:  1.604997 - Acc: 81.7685 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 0                              \n",
      " 03:00:20 | Ep: 248/ 600 | Trn loss:  0.074743 - Acc: 97.6010 | Val loss:  1.608023 - Acc: 81.7130 | last_lr: 6.25000e-05  bad_ep: 1  cdwn: 0                              \n",
      " 03:00:34 | Ep: 249/ 600 | Trn loss:  0.074279 - Acc: 97.6295 | Val loss:  1.610996 - Acc: 81.6898 | last_lr: 6.25000e-05  bad_ep: 2  cdwn: 0                              \n",
      " 03:00:48 | Ep: 250/ 600 | Trn loss:  0.073829 - Acc: 97.6569 | Val loss:  1.614831 - Acc: 81.6065 | last_lr: 6.25000e-05  bad_ep: 3  cdwn: 0                              \n",
      " 03:01:01 | Ep: 251/ 600 | Trn loss:  0.073366 - Acc: 97.6768 | Val loss:  1.617787 - Acc: 81.6065 | last_lr: 6.25000e-05  bad_ep: 4  cdwn: 0                              \n",
      " 03:01:15 | Ep: 252/ 600 | Trn loss:  0.072927 - Acc: 97.7053 | Val loss:  1.620164 - Acc: 81.5972 | last_lr: 6.25000e-05  bad_ep: 5  cdwn: 0                              \n",
      " 03:01:29 | Ep: 253/ 600 | Trn loss:  0.072473 - Acc: 97.7222 | Val loss:  1.623610 - Acc: 81.5556 | last_lr: 6.25000e-05  bad_ep: 6  cdwn: 0                              \n",
      " 03:01:43 | Ep: 254/ 600 | Trn loss:  0.072045 - Acc: 97.7399 | Val loss:  1.627295 - Acc: 81.5509 | last_lr: 6.25000e-05  bad_ep: 7  cdwn: 0                              \n",
      " 03:01:56 | Ep: 255/ 600 | Trn loss:  0.071597 - Acc: 97.7619 | Val loss:  1.630523 - Acc: 81.5509 | last_lr: 6.25000e-05  bad_ep: 8  cdwn: 0                              \n",
      " 03:02:10 | Ep: 256/ 600 | Trn loss:  0.071173 - Acc: 97.7796 | Val loss:  1.634048 - Acc: 81.5370 | last_lr: 6.25000e-05  bad_ep: 9  cdwn: 0                              \n",
      " 03:02:23 | Ep: 257/ 600 | Trn loss:  0.070757 - Acc: 97.7994 | Val loss:  1.637493 - Acc: 81.5093 | last_lr: 6.25000e-05  bad_ep: 10  cdwn: 0                             \n",
      " 03:02:37 | Ep: 258/ 600 | Trn loss:  0.070352 - Acc: 97.8167 | Val loss:  1.640350 - Acc: 81.5046 | last_lr: 6.25000e-05  bad_ep: 11  cdwn: 0                             \n",
      " 03:02:51 | Ep: 259/ 600 | Trn loss:  0.069942 - Acc: 97.8319 | Val loss:  1.643661 - Acc: 81.5278 | last_lr: 6.25000e-05  bad_ep: 12  cdwn: 0                             \n",
      " 03:03:05 | Ep: 260/ 600 | Trn loss:  0.069540 - Acc: 97.8478 | Val loss:  1.646829 - Acc: 81.4722 | last_lr: 6.25000e-05  bad_ep: 13  cdwn: 0                             \n",
      " 03:03:18 | Ep: 261/ 600 | Trn loss:  0.069146 - Acc: 97.8593 | Val loss:  1.650427 - Acc: 81.4722 | last_lr: 6.25000e-05  bad_ep: 14  cdwn: 0                             \n",
      " 03:03:32 | Ep: 262/ 600 | Trn loss:  0.068768 - Acc: 97.8820 | Val loss:  1.653784 - Acc: 81.4444 | last_lr: 6.25000e-05  bad_ep: 15  cdwn: 0                             \n",
      " 03:03:46 | Ep: 263/ 600 | Trn loss:  0.068397 - Acc: 97.8979 | Val loss:  1.656970 - Acc: 81.4028 | last_lr: 6.25000e-05  bad_ep: 16  cdwn: 0                             \n",
      " 03:03:59 | Ep: 264/ 600 | Trn loss:  0.068020 - Acc: 97.9141 | Val loss:  1.660793 - Acc: 81.3935 | last_lr: 6.25000e-05  bad_ep: 17  cdwn: 0                             \n",
      " 03:04:13 | Ep: 265/ 600 | Trn loss:  0.067663 - Acc: 97.9239 | Val loss:  1.664445 - Acc: 81.3565 | last_lr: 6.25000e-05  bad_ep: 18  cdwn: 0                             \n",
      " 03:04:27 | Ep: 266/ 600 | Trn loss:  0.067390 - Acc: 97.9405 | Val loss:  1.667136 - Acc: 81.3009 | last_lr: 6.25000e-05  bad_ep: 19  cdwn: 0                             \n",
      " 03:04:41 | Ep: 267/ 600 | Trn loss:  0.066937 - Acc: 97.9560 | Val loss:  1.671636 - Acc: 81.2685 | last_lr: 6.25000e-05  bad_ep: 20  cdwn: 0                             \n",
      " 03:04:55 | Ep: 268/ 600 | Trn loss:  0.066598 - Acc: 97.9722 | Val loss:  1.675656 - Acc: 81.2824 | last_lr: 6.25000e-05  bad_ep: 21  cdwn: 0                             \n",
      " 03:05:09 | Ep: 269/ 600 | Trn loss:  0.066248 - Acc: 97.9859 | Val loss:  1.679840 - Acc: 81.2407 | last_lr: 6.25000e-05  bad_ep: 22  cdwn: 0                             \n",
      " 03:05:23 | Ep: 270/ 600 | Trn loss:  0.065911 - Acc: 98.0014 | Val loss:  1.683481 - Acc: 81.2407 | last_lr: 6.25000e-05  bad_ep: 23  cdwn: 0                             \n",
      " 03:05:36 | Ep: 271/ 600 | Trn loss:  0.065577 - Acc: 98.0173 | Val loss:  1.687298 - Acc: 81.2454 | last_lr: 6.25000e-05  bad_ep: 24  cdwn: 0                             \n",
      " 03:05:50 | Ep: 272/ 600 | Trn loss:  0.065220 - Acc: 98.0325 | Val loss:  1.691602 - Acc: 81.1852 | last_lr: 6.25000e-05  bad_ep: 25  cdwn: 0                             \n",
      " 03:06:04 | Ep: 273/ 600 | Trn loss:  0.064901 - Acc: 98.0494 | Val loss:  1.695744 - Acc: 81.1852 | last_lr: 6.25000e-05  bad_ep: 26  cdwn: 0                             \n",
      " 03:06:18 | Ep: 274/ 600 | Trn loss:  0.064570 - Acc: 98.0592 | Val loss:  1.699628 - Acc: 81.1574 | last_lr: 6.25000e-05  bad_ep: 27  cdwn: 0                             \n",
      " 03:06:32 | Ep: 275/ 600 | Trn loss:  0.064235 - Acc: 98.0743 | Val loss:  1.704155 - Acc: 81.1389 | last_lr: 6.25000e-05  bad_ep: 28  cdwn: 0                             \n",
      " 03:06:46 | Ep: 276/ 600 | Trn loss:  0.063928 - Acc: 98.0855 | Val loss:  1.708252 - Acc: 81.1111 | last_lr: 6.25000e-05  bad_ep: 29  cdwn: 0                             \n",
      " 03:06:59 | Ep: 277/ 600 | Trn loss:  0.063602 - Acc: 98.0978 | Val loss:  1.712468 - Acc: 81.1157 | last_lr: 6.25000e-05  bad_ep: 30  cdwn: 0                             \n",
      " 03:07:13 | Ep: 278/ 600 | Trn loss:  0.063282 - Acc: 98.1100 | Val loss:  1.716890 - Acc: 81.1157 | last_lr: 6.25000e-05  bad_ep: 31  cdwn: 0                             \n",
      " 03:07:27 | Ep: 279/ 600 | Trn loss:  0.062969 - Acc: 98.1248 | Val loss:  1.721143 - Acc: 81.1157 | last_lr: 6.25000e-05  bad_ep: 32  cdwn: 0                             \n",
      " 03:07:41 | Ep: 280/ 600 | Trn loss:  0.062652 - Acc: 98.1400 | Val loss:  1.725731 - Acc: 81.1157 | last_lr: 6.25000e-05  bad_ep: 33  cdwn: 0                             \n",
      " 03:07:54 | Ep: 281/ 600 | Trn loss:  0.062346 - Acc: 98.1526 | Val loss:  1.730096 - Acc: 81.1157 | last_lr: 6.25000e-05  bad_ep: 34  cdwn: 0                             \n",
      " 03:08:08 | Ep: 282/ 600 | Trn loss:  0.062037 - Acc: 98.1631 | Val loss:  1.733936 - Acc: 81.1111 | last_lr: 6.25000e-05  bad_ep: 35  cdwn: 0                             \n",
      " 03:08:22 | Ep: 283/ 600 | Trn loss:  0.061740 - Acc: 98.1760 | Val loss:  1.738570 - Acc: 81.0694 | last_lr: 6.25000e-05  bad_ep: 36  cdwn: 0                             \n",
      " 03:08:36 | Ep: 284/ 600 | Trn loss:  0.061436 - Acc: 98.1865 | Val loss:  1.742315 - Acc: 81.0926 | last_lr: 6.25000e-05  bad_ep: 37  cdwn: 0                             \n",
      " 03:08:50 | Ep: 285/ 600 | Trn loss:  0.061146 - Acc: 98.1995 | Val loss:  1.746749 - Acc: 81.0648 | last_lr: 6.25000e-05  bad_ep: 38  cdwn: 0                             \n",
      " 03:09:04 | Ep: 286/ 600 | Trn loss:  0.060843 - Acc: 98.2092 | Val loss:  1.751193 - Acc: 81.0972 | last_lr: 6.25000e-05  bad_ep: 39  cdwn: 0                             \n",
      " 03:09:18 | Ep: 287/ 600 | Trn loss:  0.060551 - Acc: 98.2179 | Val loss:  1.755399 - Acc: 81.0787 | last_lr: 6.25000e-05  bad_ep: 40  cdwn: 0                             \n",
      " 03:09:32 | Ep: 288/ 600 | Trn loss:  0.060271 - Acc: 98.2330 | Val loss:  1.760120 - Acc: 81.0602 | last_lr: 6.25000e-05  bad_ep: 41  cdwn: 0                             \n",
      " 03:09:47 | Ep: 289/ 600 | Trn loss:  0.059982 - Acc: 98.2381 | Val loss:  1.764561 - Acc: 81.0370 | last_lr: 6.25000e-05  bad_ep: 42  cdwn: 0                             \n",
      " 03:10:01 | Ep: 290/ 600 | Trn loss:  0.059699 - Acc: 98.2511 | Val loss:  1.768571 - Acc: 81.0370 | last_lr: 6.25000e-05  bad_ep: 43  cdwn: 0                             \n",
      " 03:10:15 | Ep: 291/ 600 | Trn loss:  0.059410 - Acc: 98.2655 | Val loss:  1.772855 - Acc: 81.0139 | last_lr: 6.25000e-05  bad_ep: 44  cdwn: 0                             \n",
      " 03:10:29 | Ep: 292/ 600 | Trn loss:  0.059125 - Acc: 98.2789 | Val loss:  1.777431 - Acc: 80.9259 | last_lr: 6.25000e-05  bad_ep: 45  cdwn: 0                             \n",
      " 03:10:44 | Ep: 293/ 600 | Trn loss:  0.058855 - Acc: 98.2900 | Val loss:  1.782701 - Acc: 80.9537 | last_lr: 6.25000e-05  bad_ep: 46  cdwn: 0                             \n",
      " 03:10:58 | Ep: 294/ 600 | Trn loss:  0.058601 - Acc: 98.2991 | Val loss:  1.786894 - Acc: 80.9352 | last_lr: 6.25000e-05  bad_ep: 47  cdwn: 0                             \n",
      " 03:11:12 | Ep: 295/ 600 | Trn loss:  0.058375 - Acc: 98.3027 | Val loss:  1.790475 - Acc: 80.9491 | last_lr: 6.25000e-05  bad_ep: 48  cdwn: 0                             \n",
      " 03:11:27 | Ep: 296/ 600 | Trn loss:  0.058482 - Acc: 98.3084 | Val loss:  1.789926 - Acc: 80.9306 | last_lr: 6.25000e-05  bad_ep: 49  cdwn: 0                             \n",
      " 03:11:41 | Ep: 297/ 600 | Trn loss:  0.058592 - Acc: 98.3012 | Val loss:  1.798794 - Acc: 80.9491 | last_lr: 6.25000e-05  bad_ep: 50  cdwn: 0                             \n",
      " 03:11:55 | Ep: 298/ 600 | Trn loss:  0.059049 - Acc: 98.3019 | Val loss:  1.802204 - Acc: 80.9074 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 10                             \n",
      " 03:12:09 | Ep: 299/ 600 | Trn loss:  0.059696 - Acc: 98.2478 | Val loss:  1.801780 - Acc: 80.5880 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 9                              \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 03:12:24,179 - utils.utils_cellpainting - INFO: -  Model exported to NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_300.pt - epoch: 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 03:12:24 | Ep: 300/ 600 | Trn loss:  0.059152 - Acc: 98.2702 | Val loss:  1.806219 - Acc: 80.4722 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 8 \n",
      " 03:12:38 | Ep: 301/ 600 | Trn loss:  0.058791 - Acc: 98.2832 | Val loss:  1.808681 - Acc: 80.4213 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 7                              \n",
      " 03:12:52 | Ep: 302/ 600 | Trn loss:  0.058483 - Acc: 98.2926 | Val loss:  1.811404 - Acc: 80.4028 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 6                              \n",
      " 03:13:07 | Ep: 303/ 600 | Trn loss:  0.058213 - Acc: 98.3016 | Val loss:  1.813303 - Acc: 80.3750 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 5                              \n",
      " 03:13:21 | Ep: 304/ 600 | Trn loss:  0.057962 - Acc: 98.3095 | Val loss:  1.815868 - Acc: 80.3889 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 4                              \n",
      " 03:13:35 | Ep: 305/ 600 | Trn loss:  0.057726 - Acc: 98.3196 | Val loss:  1.817686 - Acc: 80.3657 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 3                              \n",
      " 03:13:50 | Ep: 306/ 600 | Trn loss:  0.057491 - Acc: 98.3272 | Val loss:  1.820004 - Acc: 80.3750 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 2                              \n",
      " 03:14:04 | Ep: 307/ 600 | Trn loss:  0.057259 - Acc: 98.3351 | Val loss:  1.822209 - Acc: 80.3611 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 1                              \n",
      " 03:14:18 | Ep: 308/ 600 | Trn loss:  0.057051 - Acc: 98.3409 | Val loss:  1.824247 - Acc: 80.3657 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 0                              \n",
      " 03:14:32 | Ep: 309/ 600 | Trn loss:  0.056832 - Acc: 98.3467 | Val loss:  1.826612 - Acc: 80.3796 | last_lr: 3.12500e-05  bad_ep: 1  cdwn: 0                              \n",
      " 03:14:47 | Ep: 310/ 600 | Trn loss:  0.056622 - Acc: 98.3528 | Val loss:  1.828561 - Acc: 80.3472 | last_lr: 3.12500e-05  bad_ep: 2  cdwn: 0                              \n",
      " 03:15:01 | Ep: 311/ 600 | Trn loss:  0.056421 - Acc: 98.3644 | Val loss:  1.831216 - Acc: 80.3565 | last_lr: 3.12500e-05  bad_ep: 3  cdwn: 0                              \n",
      " 03:15:15 | Ep: 312/ 600 | Trn loss:  0.056214 - Acc: 98.3777 | Val loss:  1.833021 - Acc: 80.3611 | last_lr: 3.12500e-05  bad_ep: 4  cdwn: 0                              \n",
      " 03:15:30 | Ep: 313/ 600 | Trn loss:  0.056016 - Acc: 98.3900 | Val loss:  1.835345 - Acc: 80.3519 | last_lr: 3.12500e-05  bad_ep: 5  cdwn: 0                              \n",
      " 03:15:44 | Ep: 314/ 600 | Trn loss:  0.055818 - Acc: 98.3939 | Val loss:  1.837298 - Acc: 80.3333 | last_lr: 3.12500e-05  bad_ep: 6  cdwn: 0                              \n",
      " 03:15:58 | Ep: 315/ 600 | Trn loss:  0.055629 - Acc: 98.4033 | Val loss:  1.839883 - Acc: 80.3333 | last_lr: 3.12500e-05  bad_ep: 7  cdwn: 0                              \n",
      " 03:16:12 | Ep: 316/ 600 | Trn loss:  0.055441 - Acc: 98.4080 | Val loss:  1.842373 - Acc: 80.3102 | last_lr: 3.12500e-05  bad_ep: 8  cdwn: 0                              \n",
      " 03:16:26 | Ep: 317/ 600 | Trn loss:  0.055263 - Acc: 98.4149 | Val loss:  1.844676 - Acc: 80.3148 | last_lr: 3.12500e-05  bad_ep: 9  cdwn: 0                              \n",
      " 03:16:40 | Ep: 318/ 600 | Trn loss:  0.055082 - Acc: 98.4235 | Val loss:  1.847025 - Acc: 80.3241 | last_lr: 3.12500e-05  bad_ep: 10  cdwn: 0                             \n",
      " 03:16:53 | Ep: 319/ 600 | Trn loss:  0.054901 - Acc: 98.4282 | Val loss:  1.849646 - Acc: 80.3194 | last_lr: 3.12500e-05  bad_ep: 11  cdwn: 0                             \n",
      " 03:17:07 | Ep: 320/ 600 | Trn loss:  0.054721 - Acc: 98.4318 | Val loss:  1.851661 - Acc: 80.3194 | last_lr: 3.12500e-05  bad_ep: 12  cdwn: 0                             \n",
      " 03:17:21 | Ep: 321/ 600 | Trn loss:  0.054552 - Acc: 98.4394 | Val loss:  1.854021 - Acc: 80.3194 | last_lr: 3.12500e-05  bad_ep: 13  cdwn: 0                             \n",
      " 03:17:34 | Ep: 322/ 600 | Trn loss:  0.054381 - Acc: 98.4452 | Val loss:  1.856215 - Acc: 80.3194 | last_lr: 3.12500e-05  bad_ep: 14  cdwn: 0                             \n",
      " 03:17:48 | Ep: 323/ 600 | Trn loss:  0.054210 - Acc: 98.4538 | Val loss:  1.858556 - Acc: 80.3102 | last_lr: 3.12500e-05  bad_ep: 15  cdwn: 0                             \n",
      " 03:18:02 | Ep: 324/ 600 | Trn loss:  0.054040 - Acc: 98.4582 | Val loss:  1.861480 - Acc: 80.2963 | last_lr: 3.12500e-05  bad_ep: 16  cdwn: 0                             \n",
      " 03:18:16 | Ep: 325/ 600 | Trn loss:  0.053877 - Acc: 98.4654 | Val loss:  1.864023 - Acc: 80.3241 | last_lr: 3.12500e-05  bad_ep: 17  cdwn: 0                             \n",
      " 03:18:30 | Ep: 326/ 600 | Trn loss:  0.053704 - Acc: 98.4715 | Val loss:  1.865955 - Acc: 80.3148 | last_lr: 3.12500e-05  bad_ep: 18  cdwn: 0                             \n",
      " 03:18:45 | Ep: 327/ 600 | Trn loss:  0.053545 - Acc: 98.4780 | Val loss:  1.868896 - Acc: 80.3102 | last_lr: 3.12500e-05  bad_ep: 19  cdwn: 0                             \n",
      " 03:18:59 | Ep: 328/ 600 | Trn loss:  0.053381 - Acc: 98.4820 | Val loss:  1.871418 - Acc: 80.2870 | last_lr: 3.12500e-05  bad_ep: 20  cdwn: 0                             \n",
      " 03:19:13 | Ep: 329/ 600 | Trn loss:  0.053233 - Acc: 98.4874 | Val loss:  1.873682 - Acc: 80.2963 | last_lr: 3.12500e-05  bad_ep: 21  cdwn: 0                             \n",
      " 03:19:28 | Ep: 330/ 600 | Trn loss:  0.053066 - Acc: 98.4928 | Val loss:  1.875943 - Acc: 80.3148 | last_lr: 3.12500e-05  bad_ep: 22  cdwn: 0                             \n",
      " 03:19:42 | Ep: 331/ 600 | Trn loss:  0.052904 - Acc: 98.4996 | Val loss:  1.878779 - Acc: 80.2870 | last_lr: 3.12500e-05  bad_ep: 23  cdwn: 0                             \n",
      " 03:19:56 | Ep: 332/ 600 | Trn loss:  0.052754 - Acc: 98.5061 | Val loss:  1.881142 - Acc: 80.2824 | last_lr: 3.12500e-05  bad_ep: 24  cdwn: 0                             \n",
      " 03:20:10 | Ep: 333/ 600 | Trn loss:  0.052598 - Acc: 98.5148 | Val loss:  1.883906 - Acc: 80.2731 | last_lr: 3.12500e-05  bad_ep: 25  cdwn: 0                             \n",
      " 03:20:23 | Ep: 334/ 600 | Trn loss:  0.052447 - Acc: 98.5166 | Val loss:  1.886437 - Acc: 80.2685 | last_lr: 3.12500e-05  bad_ep: 26  cdwn: 0                             \n",
      " 03:20:37 | Ep: 335/ 600 | Trn loss:  0.052287 - Acc: 98.5191 | Val loss:  1.888977 - Acc: 80.2685 | last_lr: 3.12500e-05  bad_ep: 27  cdwn: 0                             \n",
      " 03:20:51 | Ep: 336/ 600 | Trn loss:  0.052139 - Acc: 98.5310 | Val loss:  1.891724 - Acc: 80.2454 | last_lr: 3.12500e-05  bad_ep: 28  cdwn: 0                             \n",
      " 03:21:05 | Ep: 337/ 600 | Trn loss:  0.051993 - Acc: 98.5382 | Val loss:  1.894240 - Acc: 80.2407 | last_lr: 3.12500e-05  bad_ep: 29  cdwn: 0                             \n",
      " 03:21:19 | Ep: 338/ 600 | Trn loss:  0.051845 - Acc: 98.5451 | Val loss:  1.896818 - Acc: 80.2361 | last_lr: 3.12500e-05  bad_ep: 30  cdwn: 0                             \n",
      " 03:21:33 | Ep: 339/ 600 | Trn loss:  0.051694 - Acc: 98.5487 | Val loss:  1.899631 - Acc: 80.2315 | last_lr: 3.12500e-05  bad_ep: 31  cdwn: 0                             \n",
      " 03:21:48 | Ep: 340/ 600 | Trn loss:  0.051549 - Acc: 98.5548 | Val loss:  1.901953 - Acc: 80.2222 | last_lr: 3.12500e-05  bad_ep: 32  cdwn: 0                             \n",
      " 03:22:02 | Ep: 341/ 600 | Trn loss:  0.051408 - Acc: 98.5592 | Val loss:  1.904382 - Acc: 80.2083 | last_lr: 3.12500e-05  bad_ep: 33  cdwn: 0                             \n",
      " 03:22:16 | Ep: 342/ 600 | Trn loss:  0.051263 - Acc: 98.5628 | Val loss:  1.907020 - Acc: 80.2083 | last_lr: 3.12500e-05  bad_ep: 34  cdwn: 0                             \n",
      " 03:22:31 | Ep: 343/ 600 | Trn loss:  0.051117 - Acc: 98.5675 | Val loss:  1.909620 - Acc: 80.1991 | last_lr: 3.12500e-05  bad_ep: 35  cdwn: 0                             \n",
      " 03:22:45 | Ep: 344/ 600 | Trn loss:  0.050975 - Acc: 98.5718 | Val loss:  1.912153 - Acc: 80.2130 | last_lr: 3.12500e-05  bad_ep: 36  cdwn: 0                             \n",
      " 03:22:59 | Ep: 345/ 600 | Trn loss:  0.050834 - Acc: 98.5765 | Val loss:  1.914653 - Acc: 80.2083 | last_lr: 3.12500e-05  bad_ep: 37  cdwn: 0                             \n",
      " 03:23:14 | Ep: 346/ 600 | Trn loss:  0.050693 - Acc: 98.5801 | Val loss:  1.917422 - Acc: 80.1944 | last_lr: 3.12500e-05  bad_ep: 38  cdwn: 0                             \n",
      " 03:23:28 | Ep: 347/ 600 | Trn loss:  0.050552 - Acc: 98.5880 | Val loss:  1.919692 - Acc: 80.1991 | last_lr: 3.12500e-05  bad_ep: 39  cdwn: 0                             \n",
      " 03:23:43 | Ep: 348/ 600 | Trn loss:  0.050417 - Acc: 98.5970 | Val loss:  1.922136 - Acc: 80.2130 | last_lr: 3.12500e-05  bad_ep: 40  cdwn: 0                             \n",
      " 03:23:57 | Ep: 349/ 600 | Trn loss:  0.050278 - Acc: 98.6003 | Val loss:  1.924718 - Acc: 80.2083 | last_lr: 3.12500e-05  bad_ep: 41  cdwn: 0                             \n",
      " 03:24:11 | Ep: 350/ 600 | Trn loss:  0.050138 - Acc: 98.6061 | Val loss:  1.927302 - Acc: 80.2222 | last_lr: 3.12500e-05  bad_ep: 42  cdwn: 0                             \n",
      " 03:24:26 | Ep: 351/ 600 | Trn loss:  0.050001 - Acc: 98.6097 | Val loss:  1.929569 - Acc: 80.2130 | last_lr: 3.12500e-05  bad_ep: 43  cdwn: 0                             \n",
      " 03:24:40 | Ep: 352/ 600 | Trn loss:  0.049863 - Acc: 98.6176 | Val loss:  1.932495 - Acc: 80.1852 | last_lr: 3.12500e-05  bad_ep: 44  cdwn: 0                             \n",
      " 03:24:55 | Ep: 353/ 600 | Trn loss:  0.049730 - Acc: 98.6201 | Val loss:  1.934868 - Acc: 80.1759 | last_lr: 3.12500e-05  bad_ep: 45  cdwn: 0                             \n",
      " 03:25:09 | Ep: 354/ 600 | Trn loss:  0.049590 - Acc: 98.6241 | Val loss:  1.937517 - Acc: 80.1852 | last_lr: 3.12500e-05  bad_ep: 46  cdwn: 0                             \n",
      " 03:25:23 | Ep: 355/ 600 | Trn loss:  0.049456 - Acc: 98.6284 | Val loss:  1.939713 - Acc: 80.1852 | last_lr: 3.12500e-05  bad_ep: 47  cdwn: 0                             \n",
      " 03:25:36 | Ep: 356/ 600 | Trn loss:  0.049322 - Acc: 98.6353 | Val loss:  1.941847 - Acc: 80.1806 | last_lr: 3.12500e-05  bad_ep: 48  cdwn: 0                             \n",
      " 03:25:50 | Ep: 357/ 600 | Trn loss:  0.049192 - Acc: 98.6374 | Val loss:  1.944996 - Acc: 80.1667 | last_lr: 3.12500e-05  bad_ep: 49  cdwn: 0                             \n",
      " 03:26:04 | Ep: 358/ 600 | Trn loss:  0.049054 - Acc: 98.6407 | Val loss:  1.946874 - Acc: 80.1852 | last_lr: 3.12500e-05  bad_ep: 50  cdwn: 0                             \n",
      " 03:26:17 | Ep: 359/ 600 | Trn loss:  0.048919 - Acc: 98.6475 | Val loss:  1.949621 - Acc: 80.1852 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 10                             \n",
      " 03:26:31 | Ep: 360/ 600 | Trn loss:  0.049051 - Acc: 98.6367 | Val loss:  1.950387 - Acc: 80.1296 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 9                              \n",
      " 03:26:46 | Ep: 361/ 600 | Trn loss:  0.048910 - Acc: 98.6439 | Val loss:  1.951427 - Acc: 80.1343 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 8                              \n",
      " 03:27:00 | Ep: 362/ 600 | Trn loss:  0.048779 - Acc: 98.6465 | Val loss:  1.952500 - Acc: 80.1296 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 7                              \n",
      " 03:27:14 | Ep: 363/ 600 | Trn loss:  0.048670 - Acc: 98.6519 | Val loss:  1.953834 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 6                              \n",
      " 03:27:28 | Ep: 364/ 600 | Trn loss:  0.048559 - Acc: 98.6555 | Val loss:  1.954804 - Acc: 80.1528 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 5                              \n",
      " 03:27:42 | Ep: 365/ 600 | Trn loss:  0.048456 - Acc: 98.6591 | Val loss:  1.956111 - Acc: 80.1435 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 4                              \n",
      " 03:27:56 | Ep: 366/ 600 | Trn loss:  0.048357 - Acc: 98.6641 | Val loss:  1.957149 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 3                              \n",
      " 03:28:11 | Ep: 367/ 600 | Trn loss:  0.048261 - Acc: 98.6667 | Val loss:  1.958259 - Acc: 80.1528 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 2                              \n",
      " 03:28:25 | Ep: 368/ 600 | Trn loss:  0.048165 - Acc: 98.6714 | Val loss:  1.959252 - Acc: 80.1528 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 1                              \n",
      " 03:28:39 | Ep: 369/ 600 | Trn loss:  0.048076 - Acc: 98.6728 | Val loss:  1.960382 - Acc: 80.1435 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 0                              \n",
      " 03:28:53 | Ep: 370/ 600 | Trn loss:  0.047986 - Acc: 98.6764 | Val loss:  1.961724 - Acc: 80.1435 | last_lr: 1.56250e-05  bad_ep: 1  cdwn: 0                              \n",
      " 03:29:07 | Ep: 371/ 600 | Trn loss:  0.047903 - Acc: 98.6760 | Val loss:  1.962801 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 2  cdwn: 0                              \n",
      " 03:29:21 | Ep: 372/ 600 | Trn loss:  0.047814 - Acc: 98.6811 | Val loss:  1.963771 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 3  cdwn: 0                              \n",
      " 03:29:36 | Ep: 373/ 600 | Trn loss:  0.047731 - Acc: 98.6861 | Val loss:  1.965096 - Acc: 80.1435 | last_lr: 1.56250e-05  bad_ep: 4  cdwn: 0                              \n",
      " 03:29:50 | Ep: 374/ 600 | Trn loss:  0.047650 - Acc: 98.6872 | Val loss:  1.966216 - Acc: 80.1343 | last_lr: 1.56250e-05  bad_ep: 5  cdwn: 0                              \n",
      " 03:30:04 | Ep: 375/ 600 | Trn loss:  0.047565 - Acc: 98.6880 | Val loss:  1.967607 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 6  cdwn: 0                              \n",
      " 03:30:19 | Ep: 376/ 600 | Trn loss:  0.047486 - Acc: 98.6930 | Val loss:  1.968822 - Acc: 80.1343 | last_lr: 1.56250e-05  bad_ep: 7  cdwn: 0                              \n",
      " 03:30:33 | Ep: 377/ 600 | Trn loss:  0.047408 - Acc: 98.6962 | Val loss:  1.969840 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 8  cdwn: 0                              \n",
      " 03:30:47 | Ep: 378/ 600 | Trn loss:  0.047328 - Acc: 98.6973 | Val loss:  1.971333 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 9  cdwn: 0                              \n",
      " 03:31:02 | Ep: 379/ 600 | Trn loss:  0.047249 - Acc: 98.7009 | Val loss:  1.972319 - Acc: 80.1343 | last_lr: 1.56250e-05  bad_ep: 10  cdwn: 0                             \n",
      " 03:31:16 | Ep: 380/ 600 | Trn loss:  0.047173 - Acc: 98.7038 | Val loss:  1.973585 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 11  cdwn: 0                             \n",
      " 03:31:30 | Ep: 381/ 600 | Trn loss:  0.047101 - Acc: 98.7071 | Val loss:  1.974762 - Acc: 80.1157 | last_lr: 1.56250e-05  bad_ep: 12  cdwn: 0                             \n",
      " 03:31:45 | Ep: 382/ 600 | Trn loss:  0.047022 - Acc: 98.7089 | Val loss:  1.976204 - Acc: 80.1343 | last_lr: 1.56250e-05  bad_ep: 13  cdwn: 0                             \n",
      " 03:31:59 | Ep: 383/ 600 | Trn loss:  0.046950 - Acc: 98.7100 | Val loss:  1.977313 - Acc: 80.1389 | last_lr: 1.56250e-05  bad_ep: 14  cdwn: 0                             \n",
      " 03:32:12 | Ep: 384/ 600 | Trn loss:  0.046874 - Acc: 98.7143 | Val loss:  1.978435 - Acc: 80.1435 | last_lr: 1.56250e-05  bad_ep: 15  cdwn: 0                             \n",
      " 03:32:26 | Ep: 385/ 600 | Trn loss:  0.046803 - Acc: 98.7143 | Val loss:  1.979633 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 16  cdwn: 0                             \n",
      " 03:32:40 | Ep: 386/ 600 | Trn loss:  0.046729 - Acc: 98.7219 | Val loss:  1.980910 - Acc: 80.1574 | last_lr: 1.56250e-05  bad_ep: 17  cdwn: 0                             \n",
      " 03:32:55 | Ep: 387/ 600 | Trn loss:  0.046658 - Acc: 98.7204 | Val loss:  1.982121 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 18  cdwn: 0                             \n",
      " 03:33:09 | Ep: 388/ 600 | Trn loss:  0.046587 - Acc: 98.7262 | Val loss:  1.983250 - Acc: 80.1574 | last_lr: 1.56250e-05  bad_ep: 19  cdwn: 0                             \n",
      " 03:33:24 | Ep: 389/ 600 | Trn loss:  0.046516 - Acc: 98.7258 | Val loss:  1.984361 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 20  cdwn: 0                             \n",
      " 03:33:38 | Ep: 390/ 600 | Trn loss:  0.046447 - Acc: 98.7309 | Val loss:  1.985800 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 21  cdwn: 0                             \n",
      " 03:33:52 | Ep: 391/ 600 | Trn loss:  0.046374 - Acc: 98.7338 | Val loss:  1.986830 - Acc: 80.1713 | last_lr: 1.56250e-05  bad_ep: 22  cdwn: 0                             \n",
      " 03:34:07 | Ep: 392/ 600 | Trn loss:  0.046304 - Acc: 98.7399 | Val loss:  1.988086 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 23  cdwn: 0                             \n",
      " 03:34:21 | Ep: 393/ 600 | Trn loss:  0.046234 - Acc: 98.7435 | Val loss:  1.989497 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 24  cdwn: 0                             \n",
      " 03:34:35 | Ep: 394/ 600 | Trn loss:  0.046165 - Acc: 98.7453 | Val loss:  1.990567 - Acc: 80.1852 | last_lr: 1.56250e-05  bad_ep: 25  cdwn: 0                             \n",
      " 03:34:48 | Ep: 395/ 600 | Trn loss:  0.046100 - Acc: 98.7464 | Val loss:  1.991772 - Acc: 80.1898 | last_lr: 1.56250e-05  bad_ep: 26  cdwn: 0                             \n",
      " 03:35:02 | Ep: 396/ 600 | Trn loss:  0.046031 - Acc: 98.7504 | Val loss:  1.993142 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 27  cdwn: 0                             \n",
      " 03:35:16 | Ep: 397/ 600 | Trn loss:  0.045965 - Acc: 98.7518 | Val loss:  1.994245 - Acc: 80.1759 | last_lr: 1.56250e-05  bad_ep: 28  cdwn: 0                             \n",
      " 03:35:31 | Ep: 398/ 600 | Trn loss:  0.045896 - Acc: 98.7565 | Val loss:  1.995559 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 29  cdwn: 0                             \n",
      " 03:35:45 | Ep: 399/ 600 | Trn loss:  0.045831 - Acc: 98.7579 | Val loss:  1.996863 - Acc: 80.1759 | last_lr: 1.56250e-05  bad_ep: 30  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 03:35:59,937 - utils.utils_cellpainting - INFO: -  Model exported to NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_400.pt - epoch: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 03:35:59 | Ep: 400/ 600 | Trn loss:  0.045763 - Acc: 98.7630 | Val loss:  1.998145 - Acc: 80.1667 | last_lr: 1.56250e-05  bad_ep: 31  cdwn: 0 \n",
      " 03:36:14 | Ep: 401/ 600 | Trn loss:  0.045699 - Acc: 98.7623 | Val loss:  1.999401 - Acc: 80.1713 | last_lr: 1.56250e-05  bad_ep: 32  cdwn: 0                             \n",
      " 03:36:28 | Ep: 402/ 600 | Trn loss:  0.045632 - Acc: 98.7648 | Val loss:  2.000452 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 33  cdwn: 0                             \n",
      " 03:36:42 | Ep: 403/ 600 | Trn loss:  0.045566 - Acc: 98.7684 | Val loss:  2.001879 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 34  cdwn: 0                             \n",
      " 03:36:57 | Ep: 404/ 600 | Trn loss:  0.045502 - Acc: 98.7684 | Val loss:  2.003135 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 35  cdwn: 0                             \n",
      " 03:37:11 | Ep: 405/ 600 | Trn loss:  0.045436 - Acc: 98.7698 | Val loss:  2.004246 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 36  cdwn: 0                             \n",
      " 03:37:25 | Ep: 406/ 600 | Trn loss:  0.045374 - Acc: 98.7713 | Val loss:  2.005751 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 37  cdwn: 0                             \n",
      " 03:37:40 | Ep: 407/ 600 | Trn loss:  0.045304 - Acc: 98.7716 | Val loss:  2.007075 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 38  cdwn: 0                             \n",
      " 03:37:54 | Ep: 408/ 600 | Trn loss:  0.045242 - Acc: 98.7756 | Val loss:  2.008361 - Acc: 80.1944 | last_lr: 1.56250e-05  bad_ep: 39  cdwn: 0                             \n",
      " 03:38:08 | Ep: 409/ 600 | Trn loss:  0.045180 - Acc: 98.7774 | Val loss:  2.009320 - Acc: 80.1806 | last_lr: 1.56250e-05  bad_ep: 40  cdwn: 0                             \n",
      " 03:38:22 | Ep: 410/ 600 | Trn loss:  0.045116 - Acc: 98.7807 | Val loss:  2.010767 - Acc: 80.1898 | last_lr: 1.56250e-05  bad_ep: 41  cdwn: 0                             \n",
      " 03:38:36 | Ep: 411/ 600 | Trn loss:  0.045052 - Acc: 98.7825 | Val loss:  2.012161 - Acc: 80.1667 | last_lr: 1.56250e-05  bad_ep: 42  cdwn: 0                             \n",
      " 03:38:50 | Ep: 412/ 600 | Trn loss:  0.044988 - Acc: 98.7850 | Val loss:  2.013299 - Acc: 80.1852 | last_lr: 1.56250e-05  bad_ep: 43  cdwn: 0                             \n",
      " 03:39:04 | Ep: 413/ 600 | Trn loss:  0.044922 - Acc: 98.7875 | Val loss:  2.014675 - Acc: 80.1620 | last_lr: 1.56250e-05  bad_ep: 44  cdwn: 0                             \n",
      " 03:39:18 | Ep: 414/ 600 | Trn loss:  0.044863 - Acc: 98.7900 | Val loss:  2.015879 - Acc: 80.1667 | last_lr: 1.56250e-05  bad_ep: 45  cdwn: 0                             \n",
      " 03:39:32 | Ep: 415/ 600 | Trn loss:  0.044799 - Acc: 98.7944 | Val loss:  2.017383 - Acc: 80.1574 | last_lr: 1.56250e-05  bad_ep: 46  cdwn: 0                             \n",
      " 03:39:46 | Ep: 416/ 600 | Trn loss:  0.044736 - Acc: 98.7940 | Val loss:  2.018526 - Acc: 80.1759 | last_lr: 1.56250e-05  bad_ep: 47  cdwn: 0                             \n",
      " 03:40:00 | Ep: 417/ 600 | Trn loss:  0.044673 - Acc: 98.7991 | Val loss:  2.019896 - Acc: 80.1574 | last_lr: 1.56250e-05  bad_ep: 48  cdwn: 0                             \n",
      " 03:40:14 | Ep: 418/ 600 | Trn loss:  0.044613 - Acc: 98.8045 | Val loss:  2.021091 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 49  cdwn: 0                             \n",
      " 03:40:28 | Ep: 419/ 600 | Trn loss:  0.044549 - Acc: 98.8045 | Val loss:  2.022473 - Acc: 80.1481 | last_lr: 1.56250e-05  bad_ep: 50  cdwn: 0                             \n",
      " 03:40:43 | Ep: 420/ 600 | Trn loss:  0.044490 - Acc: 98.8074 | Val loss:  2.023621 - Acc: 80.1481 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 10                             \n",
      " 03:40:57 | Ep: 421/ 600 | Trn loss:  0.044412 - Acc: 98.8077 | Val loss:  2.021705 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 9                              \n",
      " 03:41:11 | Ep: 422/ 600 | Trn loss:  0.044318 - Acc: 98.8074 | Val loss:  2.022367 - Acc: 80.2083 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 8                              \n",
      " 03:41:26 | Ep: 423/ 600 | Trn loss:  0.044264 - Acc: 98.8081 | Val loss:  2.022979 - Acc: 80.2130 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 7                              \n",
      " 03:41:40 | Ep: 424/ 600 | Trn loss:  0.044216 - Acc: 98.8106 | Val loss:  2.023647 - Acc: 80.2083 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 6                              \n",
      " 03:41:54 | Ep: 425/ 600 | Trn loss:  0.044170 - Acc: 98.8117 | Val loss:  2.024301 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 5                              \n",
      " 03:42:09 | Ep: 426/ 600 | Trn loss:  0.044127 - Acc: 98.8124 | Val loss:  2.024786 - Acc: 80.2083 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 4                              \n",
      " 03:42:23 | Ep: 427/ 600 | Trn loss:  0.044084 - Acc: 98.8153 | Val loss:  2.025547 - Acc: 80.2130 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 3                              \n",
      " 03:42:37 | Ep: 428/ 600 | Trn loss:  0.044042 - Acc: 98.8164 | Val loss:  2.026137 - Acc: 80.2176 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 2                              \n",
      " 03:42:51 | Ep: 429/ 600 | Trn loss:  0.044002 - Acc: 98.8160 | Val loss:  2.026848 - Acc: 80.2130 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 1                              \n",
      " 03:43:06 | Ep: 430/ 600 | Trn loss:  0.043964 - Acc: 98.8178 | Val loss:  2.027339 - Acc: 80.2083 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 0                              \n",
      " 03:43:20 | Ep: 431/ 600 | Trn loss:  0.043926 - Acc: 98.8207 | Val loss:  2.028064 - Acc: 80.2083 | last_lr: 7.81250e-06  bad_ep: 1  cdwn: 0                              \n",
      " 03:43:34 | Ep: 432/ 600 | Trn loss:  0.043888 - Acc: 98.8236 | Val loss:  2.028869 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 2  cdwn: 0                              \n",
      " 03:43:49 | Ep: 433/ 600 | Trn loss:  0.043849 - Acc: 98.8247 | Val loss:  2.029392 - Acc: 80.2176 | last_lr: 7.81250e-06  bad_ep: 3  cdwn: 0                              \n",
      " 03:44:03 | Ep: 434/ 600 | Trn loss:  0.043812 - Acc: 98.8261 | Val loss:  2.030114 - Acc: 80.1991 | last_lr: 7.81250e-06  bad_ep: 4  cdwn: 0                              \n",
      " 03:44:17 | Ep: 435/ 600 | Trn loss:  0.043777 - Acc: 98.8265 | Val loss:  2.030862 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 5  cdwn: 0                              \n",
      " 03:44:31 | Ep: 436/ 600 | Trn loss:  0.043740 - Acc: 98.8286 | Val loss:  2.031420 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 6  cdwn: 0                              \n",
      " 03:44:45 | Ep: 437/ 600 | Trn loss:  0.043705 - Acc: 98.8294 | Val loss:  2.032164 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 7  cdwn: 0                              \n",
      " 03:44:59 | Ep: 438/ 600 | Trn loss:  0.043670 - Acc: 98.8315 | Val loss:  2.032868 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 8  cdwn: 0                              \n",
      " 03:45:13 | Ep: 439/ 600 | Trn loss:  0.043634 - Acc: 98.8337 | Val loss:  2.033666 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 9  cdwn: 0                              \n",
      " 03:45:27 | Ep: 440/ 600 | Trn loss:  0.043601 - Acc: 98.8344 | Val loss:  2.034194 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 10  cdwn: 0                             \n",
      " 03:45:41 | Ep: 441/ 600 | Trn loss:  0.043565 - Acc: 98.8359 | Val loss:  2.035009 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 11  cdwn: 0                             \n",
      " 03:45:55 | Ep: 442/ 600 | Trn loss:  0.043531 - Acc: 98.8380 | Val loss:  2.035607 - Acc: 80.1806 | last_lr: 7.81250e-06  bad_ep: 12  cdwn: 0                             \n",
      " 03:46:09 | Ep: 443/ 600 | Trn loss:  0.043498 - Acc: 98.8384 | Val loss:  2.036312 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 13  cdwn: 0                             \n",
      " 03:46:23 | Ep: 444/ 600 | Trn loss:  0.043464 - Acc: 98.8409 | Val loss:  2.037067 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 14  cdwn: 0                             \n",
      " 03:46:37 | Ep: 445/ 600 | Trn loss:  0.043430 - Acc: 98.8427 | Val loss:  2.037700 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 15  cdwn: 0                             \n",
      " 03:46:51 | Ep: 446/ 600 | Trn loss:  0.043399 - Acc: 98.8452 | Val loss:  2.038357 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 16  cdwn: 0                             \n",
      " 03:47:05 | Ep: 447/ 600 | Trn loss:  0.043364 - Acc: 98.8478 | Val loss:  2.039116 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 17  cdwn: 0                             \n",
      " 03:47:19 | Ep: 448/ 600 | Trn loss:  0.043333 - Acc: 98.8488 | Val loss:  2.039999 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 18  cdwn: 0                             \n",
      " 03:47:33 | Ep: 449/ 600 | Trn loss:  0.043299 - Acc: 98.8506 | Val loss:  2.040633 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 19  cdwn: 0                             \n",
      " 03:47:48 | Ep: 450/ 600 | Trn loss:  0.043267 - Acc: 98.8503 | Val loss:  2.041331 - Acc: 80.1759 | last_lr: 7.81250e-06  bad_ep: 20  cdwn: 0                             \n",
      " 03:48:02 | Ep: 451/ 600 | Trn loss:  0.043235 - Acc: 98.8506 | Val loss:  2.042057 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 21  cdwn: 0                             \n",
      " 03:48:16 | Ep: 452/ 600 | Trn loss:  0.043200 - Acc: 98.8539 | Val loss:  2.042731 - Acc: 80.1806 | last_lr: 7.81250e-06  bad_ep: 22  cdwn: 0                             \n",
      " 03:48:30 | Ep: 453/ 600 | Trn loss:  0.043170 - Acc: 98.8557 | Val loss:  2.043478 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 23  cdwn: 0                             \n",
      " 03:48:44 | Ep: 454/ 600 | Trn loss:  0.043139 - Acc: 98.8561 | Val loss:  2.044233 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 24  cdwn: 0                             \n",
      " 03:48:58 | Ep: 455/ 600 | Trn loss:  0.043106 - Acc: 98.8582 | Val loss:  2.044922 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 25  cdwn: 0                             \n",
      " 03:49:12 | Ep: 456/ 600 | Trn loss:  0.043075 - Acc: 98.8597 | Val loss:  2.045555 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 26  cdwn: 0                             \n",
      " 03:49:26 | Ep: 457/ 600 | Trn loss:  0.043042 - Acc: 98.8608 | Val loss:  2.046355 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 27  cdwn: 0                             \n",
      " 03:49:40 | Ep: 458/ 600 | Trn loss:  0.043012 - Acc: 98.8608 | Val loss:  2.047050 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 28  cdwn: 0                             \n",
      " 03:49:54 | Ep: 459/ 600 | Trn loss:  0.042982 - Acc: 98.8622 | Val loss:  2.047805 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 29  cdwn: 0                             \n",
      " 03:50:09 | Ep: 460/ 600 | Trn loss:  0.042950 - Acc: 98.8640 | Val loss:  2.048463 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 30  cdwn: 0                             \n",
      " 03:50:23 | Ep: 461/ 600 | Trn loss:  0.042918 - Acc: 98.8651 | Val loss:  2.049124 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 31  cdwn: 0                             \n",
      " 03:50:37 | Ep: 462/ 600 | Trn loss:  0.042888 - Acc: 98.8658 | Val loss:  2.049905 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 32  cdwn: 0                             \n",
      " 03:50:51 | Ep: 463/ 600 | Trn loss:  0.042856 - Acc: 98.8672 | Val loss:  2.050678 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 33  cdwn: 0                             \n",
      " 03:51:05 | Ep: 464/ 600 | Trn loss:  0.042826 - Acc: 98.8680 | Val loss:  2.051319 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 34  cdwn: 0                             \n",
      " 03:51:19 | Ep: 465/ 600 | Trn loss:  0.042795 - Acc: 98.8698 | Val loss:  2.052067 - Acc: 80.1991 | last_lr: 7.81250e-06  bad_ep: 35  cdwn: 0                             \n",
      " 03:51:33 | Ep: 466/ 600 | Trn loss:  0.042764 - Acc: 98.8705 | Val loss:  2.052738 - Acc: 80.1991 | last_lr: 7.81250e-06  bad_ep: 36  cdwn: 0                             \n",
      " 03:51:47 | Ep: 467/ 600 | Trn loss:  0.042734 - Acc: 98.8716 | Val loss:  2.053383 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 37  cdwn: 0                             \n",
      " 03:52:01 | Ep: 468/ 600 | Trn loss:  0.042703 - Acc: 98.8723 | Val loss:  2.054109 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 38  cdwn: 0                             \n",
      " 03:52:15 | Ep: 469/ 600 | Trn loss:  0.042672 - Acc: 98.8723 | Val loss:  2.054891 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 39  cdwn: 0                             \n",
      " 03:52:29 | Ep: 470/ 600 | Trn loss:  0.042642 - Acc: 98.8741 | Val loss:  2.055551 - Acc: 80.2037 | last_lr: 7.81250e-06  bad_ep: 40  cdwn: 0                             \n",
      " 03:52:42 | Ep: 471/ 600 | Trn loss:  0.042611 - Acc: 98.8741 | Val loss:  2.056325 - Acc: 80.1991 | last_lr: 7.81250e-06  bad_ep: 41  cdwn: 0                             \n",
      " 03:52:56 | Ep: 472/ 600 | Trn loss:  0.042582 - Acc: 98.8773 | Val loss:  2.057029 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 42  cdwn: 0                             \n",
      " 03:53:10 | Ep: 473/ 600 | Trn loss:  0.042552 - Acc: 98.8784 | Val loss:  2.057692 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 43  cdwn: 0                             \n",
      " 03:53:24 | Ep: 474/ 600 | Trn loss:  0.042522 - Acc: 98.8784 | Val loss:  2.058438 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 44  cdwn: 0                             \n",
      " 03:53:38 | Ep: 475/ 600 | Trn loss:  0.042491 - Acc: 98.8784 | Val loss:  2.059166 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 45  cdwn: 0                             \n",
      " 03:53:52 | Ep: 476/ 600 | Trn loss:  0.042463 - Acc: 98.8795 | Val loss:  2.059848 - Acc: 80.1944 | last_lr: 7.81250e-06  bad_ep: 46  cdwn: 0                             \n",
      " 03:54:05 | Ep: 477/ 600 | Trn loss:  0.042432 - Acc: 98.8791 | Val loss:  2.060511 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 47  cdwn: 0                             \n",
      " 03:54:19 | Ep: 478/ 600 | Trn loss:  0.042402 - Acc: 98.8813 | Val loss:  2.061309 - Acc: 80.1852 | last_lr: 7.81250e-06  bad_ep: 48  cdwn: 0                             \n",
      " 03:54:33 | Ep: 479/ 600 | Trn loss:  0.042372 - Acc: 98.8824 | Val loss:  2.061933 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 49  cdwn: 0                             \n",
      " 03:54:48 | Ep: 480/ 600 | Trn loss:  0.042342 - Acc: 98.8849 | Val loss:  2.062604 - Acc: 80.1898 | last_lr: 7.81250e-06  bad_ep: 50  cdwn: 0                             \n",
      " 03:55:02 | Ep: 481/ 600 | Trn loss:  0.042313 - Acc: 98.8853 | Val loss:  2.063210 - Acc: 80.1852 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 10                             \n",
      " 03:55:17 | Ep: 482/ 600 | Trn loss:  0.042237 - Acc: 98.8864 | Val loss:  2.062106 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 9                              \n",
      " 03:55:31 | Ep: 483/ 600 | Trn loss:  0.042195 - Acc: 98.8882 | Val loss:  2.062360 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 8                              \n",
      " 03:55:45 | Ep: 484/ 600 | Trn loss:  0.042171 - Acc: 98.8882 | Val loss:  2.062665 - Acc: 80.2037 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 7                              \n",
      " 03:56:00 | Ep: 485/ 600 | Trn loss:  0.042149 - Acc: 98.8889 | Val loss:  2.063003 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 6                              \n",
      " 03:56:14 | Ep: 486/ 600 | Trn loss:  0.042129 - Acc: 98.8892 | Val loss:  2.063300 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 5                              \n",
      " 03:56:28 | Ep: 487/ 600 | Trn loss:  0.042111 - Acc: 98.8892 | Val loss:  2.063608 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 4                              \n",
      " 03:56:43 | Ep: 488/ 600 | Trn loss:  0.042093 - Acc: 98.8900 | Val loss:  2.063892 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 3                              \n",
      " 03:56:57 | Ep: 489/ 600 | Trn loss:  0.042075 - Acc: 98.8914 | Val loss:  2.064212 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 2                              \n",
      " 03:57:11 | Ep: 490/ 600 | Trn loss:  0.042058 - Acc: 98.8921 | Val loss:  2.064494 - Acc: 80.2037 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 1                              \n",
      " 03:57:25 | Ep: 491/ 600 | Trn loss:  0.042041 - Acc: 98.8936 | Val loss:  2.064796 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 0                              \n",
      " 03:57:39 | Ep: 492/ 600 | Trn loss:  0.042024 - Acc: 98.8936 | Val loss:  2.065190 - Acc: 80.2037 | last_lr: 3.90625e-06  bad_ep: 1  cdwn: 0                              \n",
      " 03:57:53 | Ep: 493/ 600 | Trn loss:  0.042008 - Acc: 98.8939 | Val loss:  2.065524 - Acc: 80.2037 | last_lr: 3.90625e-06  bad_ep: 2  cdwn: 0                              \n",
      " 03:58:07 | Ep: 494/ 600 | Trn loss:  0.041992 - Acc: 98.8943 | Val loss:  2.065859 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 3  cdwn: 0                              \n",
      " 03:58:21 | Ep: 495/ 600 | Trn loss:  0.041976 - Acc: 98.8947 | Val loss:  2.066113 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 4  cdwn: 0                              \n",
      " 03:58:35 | Ep: 496/ 600 | Trn loss:  0.041960 - Acc: 98.8943 | Val loss:  2.066485 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 5  cdwn: 0                              \n",
      " 03:58:49 | Ep: 497/ 600 | Trn loss:  0.041944 - Acc: 98.8950 | Val loss:  2.066807 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 6  cdwn: 0                              \n",
      " 03:59:03 | Ep: 498/ 600 | Trn loss:  0.041929 - Acc: 98.8950 | Val loss:  2.067138 - Acc: 80.1991 | last_lr: 3.90625e-06  bad_ep: 7  cdwn: 0                              \n",
      " 03:59:16 | Ep: 499/ 600 | Trn loss:  0.041913 - Acc: 98.8954 | Val loss:  2.067446 - Acc: 80.1944 | last_lr: 3.90625e-06  bad_ep: 8  cdwn: 0                              \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 03:59:30,760 - utils.utils_cellpainting - INFO: -  Model exported to NN_base_embd600_150Ltnt_512_20240923_1943_BEST_20241002_1940_ep_500.pt - epoch: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 03:59:30 | Ep: 500/ 600 | Trn loss:  0.041899 - Acc: 98.8961 | Val loss:  2.067804 - Acc: 80.1991 | last_lr: 3.90625e-06  bad_ep: 9  cdwn: 0 \n",
      " 03:59:44 | Ep: 501/ 600 | Trn loss:  0.041883 - Acc: 98.8965 | Val loss:  2.068120 - Acc: 80.1991 | last_lr: 3.90625e-06  bad_ep: 10  cdwn: 0                             \n",
      " 03:59:59 | Ep: 502/ 600 | Trn loss:  0.041868 - Acc: 98.8957 | Val loss:  2.068466 - Acc: 80.1944 | last_lr: 3.90625e-06  bad_ep: 11  cdwn: 0                             \n",
      " 04:00:13 | Ep: 503/ 600 | Trn loss:  0.041852 - Acc: 98.8965 | Val loss:  2.068724 - Acc: 80.1944 | last_lr: 3.90625e-06  bad_ep: 12  cdwn: 0                             \n",
      " 04:00:27 | Ep: 504/ 600 | Trn loss:  0.041838 - Acc: 98.8979 | Val loss:  2.069080 - Acc: 80.1944 | last_lr: 3.90625e-06  bad_ep: 13  cdwn: 0                             \n",
      " 04:00:42 | Ep: 505/ 600 | Trn loss:  0.041823 - Acc: 98.8972 | Val loss:  2.069407 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 14  cdwn: 0                             \n",
      " 04:00:56 | Ep: 506/ 600 | Trn loss:  0.041808 - Acc: 98.8990 | Val loss:  2.069699 - Acc: 80.2083 | last_lr: 3.90625e-06  bad_ep: 15  cdwn: 0                             \n",
      " 04:01:11 | Ep: 507/ 600 | Trn loss:  0.041794 - Acc: 98.8994 | Val loss:  2.070007 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 16  cdwn: 0                             \n",
      " 04:01:25 | Ep: 508/ 600 | Trn loss:  0.041778 - Acc: 98.8994 | Val loss:  2.070345 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 17  cdwn: 0                             \n",
      " 04:01:40 | Ep: 509/ 600 | Trn loss:  0.041765 - Acc: 98.8997 | Val loss:  2.070671 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 18  cdwn: 0                             \n",
      " 04:01:54 | Ep: 510/ 600 | Trn loss:  0.041750 - Acc: 98.9019 | Val loss:  2.071023 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 19  cdwn: 0                             \n",
      " 04:02:09 | Ep: 511/ 600 | Trn loss:  0.041735 - Acc: 98.9019 | Val loss:  2.071345 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 20  cdwn: 0                             \n",
      " 04:02:23 | Ep: 512/ 600 | Trn loss:  0.041721 - Acc: 98.9026 | Val loss:  2.071645 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 21  cdwn: 0                             \n",
      " 04:02:37 | Ep: 513/ 600 | Trn loss:  0.041707 - Acc: 98.9022 | Val loss:  2.072009 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 22  cdwn: 0                             \n",
      " 04:02:51 | Ep: 514/ 600 | Trn loss:  0.041692 - Acc: 98.9033 | Val loss:  2.072304 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 23  cdwn: 0                             \n",
      " 04:03:05 | Ep: 515/ 600 | Trn loss:  0.041679 - Acc: 98.9040 | Val loss:  2.072637 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 24  cdwn: 0                             \n",
      " 04:03:19 | Ep: 516/ 600 | Trn loss:  0.041665 - Acc: 98.9040 | Val loss:  2.072944 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 25  cdwn: 0                             \n",
      " 04:03:32 | Ep: 517/ 600 | Trn loss:  0.041650 - Acc: 98.9040 | Val loss:  2.073273 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 26  cdwn: 0                             \n",
      " 04:03:46 | Ep: 518/ 600 | Trn loss:  0.041636 - Acc: 98.9058 | Val loss:  2.073616 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 27  cdwn: 0                             \n",
      " 04:04:00 | Ep: 519/ 600 | Trn loss:  0.041622 - Acc: 98.9055 | Val loss:  2.073952 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 28  cdwn: 0                             \n",
      " 04:04:14 | Ep: 520/ 600 | Trn loss:  0.041609 - Acc: 98.9062 | Val loss:  2.074214 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 29  cdwn: 0                             \n",
      " 04:04:28 | Ep: 521/ 600 | Trn loss:  0.041593 - Acc: 98.9062 | Val loss:  2.074544 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 30  cdwn: 0                             \n",
      " 04:04:42 | Ep: 522/ 600 | Trn loss:  0.041581 - Acc: 98.9062 | Val loss:  2.074855 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 31  cdwn: 0                             \n",
      " 04:04:55 | Ep: 523/ 600 | Trn loss:  0.041566 - Acc: 98.9058 | Val loss:  2.075208 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 32  cdwn: 0                             \n",
      " 04:05:10 | Ep: 524/ 600 | Trn loss:  0.041552 - Acc: 98.9066 | Val loss:  2.075496 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 33  cdwn: 0                             \n",
      " 04:05:24 | Ep: 525/ 600 | Trn loss:  0.041538 - Acc: 98.9062 | Val loss:  2.075816 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 34  cdwn: 0                             \n",
      " 04:05:38 | Ep: 526/ 600 | Trn loss:  0.041525 - Acc: 98.9076 | Val loss:  2.076111 - Acc: 80.2315 | last_lr: 3.90625e-06  bad_ep: 35  cdwn: 0                             \n",
      " 04:05:53 | Ep: 527/ 600 | Trn loss:  0.041511 - Acc: 98.9076 | Val loss:  2.076446 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 36  cdwn: 0                             \n",
      " 04:06:07 | Ep: 528/ 600 | Trn loss:  0.041497 - Acc: 98.9084 | Val loss:  2.076681 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 37  cdwn: 0                             \n",
      " 04:06:22 | Ep: 529/ 600 | Trn loss:  0.041484 - Acc: 98.9084 | Val loss:  2.077104 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 38  cdwn: 0                             \n",
      " 04:06:36 | Ep: 530/ 600 | Trn loss:  0.041469 - Acc: 98.9087 | Val loss:  2.077404 - Acc: 80.2130 | last_lr: 3.90625e-06  bad_ep: 39  cdwn: 0                             \n",
      " 04:06:50 | Ep: 531/ 600 | Trn loss:  0.041456 - Acc: 98.9098 | Val loss:  2.077646 - Acc: 80.2315 | last_lr: 3.90625e-06  bad_ep: 40  cdwn: 0                             \n",
      " 04:07:05 | Ep: 532/ 600 | Trn loss:  0.041442 - Acc: 98.9105 | Val loss:  2.077969 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 41  cdwn: 0                             \n",
      " 04:07:19 | Ep: 533/ 600 | Trn loss:  0.041429 - Acc: 98.9116 | Val loss:  2.078297 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 42  cdwn: 0                             \n",
      " 04:07:33 | Ep: 534/ 600 | Trn loss:  0.041414 - Acc: 98.9116 | Val loss:  2.078594 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 43  cdwn: 0                             \n",
      " 04:07:47 | Ep: 535/ 600 | Trn loss:  0.041401 - Acc: 98.9127 | Val loss:  2.078879 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 44  cdwn: 0                             \n",
      " 04:08:01 | Ep: 536/ 600 | Trn loss:  0.041387 - Acc: 98.9131 | Val loss:  2.079226 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 45  cdwn: 0                             \n",
      " 04:08:15 | Ep: 537/ 600 | Trn loss:  0.041374 - Acc: 98.9138 | Val loss:  2.079524 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 46  cdwn: 0                             \n",
      " 04:08:29 | Ep: 538/ 600 | Trn loss:  0.041360 - Acc: 98.9138 | Val loss:  2.079861 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 47  cdwn: 0                             \n",
      " 04:08:43 | Ep: 539/ 600 | Trn loss:  0.041346 - Acc: 98.9141 | Val loss:  2.080125 - Acc: 80.2222 | last_lr: 3.90625e-06  bad_ep: 48  cdwn: 0                             \n",
      " 04:08:57 | Ep: 540/ 600 | Trn loss:  0.041333 - Acc: 98.9152 | Val loss:  2.080387 - Acc: 80.2176 | last_lr: 3.90625e-06  bad_ep: 49  cdwn: 0                             \n",
      " 04:09:11 | Ep: 541/ 600 | Trn loss:  0.041319 - Acc: 98.9149 | Val loss:  2.080794 - Acc: 80.2269 | last_lr: 3.90625e-06  bad_ep: 50  cdwn: 0                             \n",
      " 04:09:26 | Ep: 542/ 600 | Trn loss:  0.041306 - Acc: 98.9152 | Val loss:  2.081093 - Acc: 80.2315 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 10                             \n",
      " 04:09:40 | Ep: 543/ 600 | Trn loss:  0.041259 - Acc: 98.9210 | Val loss:  2.080547 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 9                              \n",
      " 04:09:55 | Ep: 544/ 600 | Trn loss:  0.041236 - Acc: 98.9199 | Val loss:  2.080752 - Acc: 80.2685 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 8                              \n",
      " 04:10:09 | Ep: 545/ 600 | Trn loss:  0.041224 - Acc: 98.9203 | Val loss:  2.080974 - Acc: 80.2685 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 7                              \n",
      " 04:10:24 | Ep: 546/ 600 | Trn loss:  0.041213 - Acc: 98.9203 | Val loss:  2.081207 - Acc: 80.2593 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 6                              \n",
      " 04:10:38 | Ep: 547/ 600 | Trn loss:  0.041202 - Acc: 98.9203 | Val loss:  2.081403 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 5                              \n",
      " 04:10:53 | Ep: 548/ 600 | Trn loss:  0.041192 - Acc: 98.9206 | Val loss:  2.081636 - Acc: 80.2500 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 4                              \n",
      " 04:11:07 | Ep: 549/ 600 | Trn loss:  0.041183 - Acc: 98.9214 | Val loss:  2.081831 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 3                              \n",
      " 04:11:21 | Ep: 550/ 600 | Trn loss:  0.041173 - Acc: 98.9214 | Val loss:  2.082050 - Acc: 80.2500 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 2                              \n",
      " 04:11:35 | Ep: 551/ 600 | Trn loss:  0.041165 - Acc: 98.9214 | Val loss:  2.082273 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 1                              \n",
      " 04:11:49 | Ep: 552/ 600 | Trn loss:  0.041155 - Acc: 98.9206 | Val loss:  2.082500 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 0                              \n",
      " 04:12:03 | Ep: 553/ 600 | Trn loss:  0.041147 - Acc: 98.9224 | Val loss:  2.082725 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 1  cdwn: 0                              \n",
      " 04:12:17 | Ep: 554/ 600 | Trn loss:  0.041138 - Acc: 98.9228 | Val loss:  2.082915 - Acc: 80.2546 | last_lr: 1.95313e-06  bad_ep: 2  cdwn: 0                              \n",
      " 04:12:32 | Ep: 555/ 600 | Trn loss:  0.041129 - Acc: 98.9232 | Val loss:  2.083108 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 3  cdwn: 0                              \n",
      " 04:12:46 | Ep: 556/ 600 | Trn loss:  0.041120 - Acc: 98.9235 | Val loss:  2.083325 - Acc: 80.2685 | last_lr: 1.95313e-06  bad_ep: 4  cdwn: 0                              \n",
      " 04:13:01 | Ep: 557/ 600 | Trn loss:  0.041112 - Acc: 98.9239 | Val loss:  2.083568 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 5  cdwn: 0                              \n",
      " 04:13:15 | Ep: 558/ 600 | Trn loss:  0.041104 - Acc: 98.9235 | Val loss:  2.083733 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 6  cdwn: 0                              \n",
      " 04:13:29 | Ep: 559/ 600 | Trn loss:  0.041095 - Acc: 98.9232 | Val loss:  2.083993 - Acc: 80.2593 | last_lr: 1.95313e-06  bad_ep: 7  cdwn: 0                              \n",
      " 04:13:44 | Ep: 560/ 600 | Trn loss:  0.041087 - Acc: 98.9235 | Val loss:  2.084164 - Acc: 80.2593 | last_lr: 1.95313e-06  bad_ep: 8  cdwn: 0                              \n",
      " 04:13:58 | Ep: 561/ 600 | Trn loss:  0.041079 - Acc: 98.9235 | Val loss:  2.084362 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 9  cdwn: 0                              \n",
      " 04:14:12 | Ep: 562/ 600 | Trn loss:  0.041071 - Acc: 98.9246 | Val loss:  2.084610 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 10  cdwn: 0                             \n",
      " 04:14:27 | Ep: 563/ 600 | Trn loss:  0.041063 - Acc: 98.9253 | Val loss:  2.084820 - Acc: 80.2639 | last_lr: 1.95313e-06  bad_ep: 11  cdwn: 0                             \n",
      " Trn 563/600:  25%|████████████████████▍                                                              | 38/154 [00:03<00:10, 11.35it/s, Loss=0.0400, Acc=99.22, lbls=219.0]"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = fit(model, optimizer, scheduler, data_loader, metrics, start_epoch, end_epoch, device, CKPT_FILE, CKPT_PATH )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ac673-4b85-4d5a-ba01-40945db8419f",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2ac55-77cb-4515-92ea-a29ab4e899bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(filename)\n",
    " \n",
    "# save_checkpoint(end_epoch, model, optimizer, scheduler, metrics = metrics,\n",
    "#                 filename = CKPT_FILE.format(ep=end_epoch),\n",
    "#                 ckpt_path = CKPT_PATH, verbose = True)\n",
    "\n",
    "start_epoch, end_epoch\n",
    "\n",
    "# for mtrc in ['loss_trn', 'loss_val']:\n",
    "#     for i in range(len(metrics[mtrc])):\n",
    "#         # print(i)\n",
    "#         metrics[mtrc][i] = metrics[mtrc][i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7463c33-544c-47ba-9c2b-c908a28948e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         metrics['loss_trn'].append(trn_loss.item())\n",
    "#         metrics['acc_trn'].append(trn_acc)\n",
    "#         metrics['loss_val'].append(val_loss.item())\n",
    "#         metrics['acc_val'].append(val_acc)\n",
    "for idx, (trn_loss, trn_acc, val_loss, val_acc) in enumerate(zip(metrics['loss_trn'],metrics['acc_trn'],metrics['loss_val'],metrics['acc_val'])):\n",
    "    print(f\" {datetime.now().strftime('%X')} | Ep: {idx:3d}/{end_epoch:4d} | Trn loss: {trn_loss:9.6f} - Acc: {trn_acc:.4f} |\"\n",
    "      f\" Val loss: {val_loss:9.6f} - Acc: {val_acc:.4f} | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75622ea-9d55-42a5-afbd-b7453166bce0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modify TPSA Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4e52f-46c9-4506-8b0d-239f045f04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_y_72 = np.zeros_like(train_y)\n",
    "train_y_72.shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11392e3-cbea-49a8-9a0b-2030c1a0aee1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"                  min           max           std          mean           median\")\n",
    "for x in ['TPSA', 'lnTPSA', 'log10TPSA']:\n",
    "    print(f\"{x:12s} {df_train[x].min():13.7f} {df_train[x].max():13.7f} {df_train[x].std():13.7f} {df_train[x].mean():13.7f} {df_train[x].median():13.7f}\") \n",
    "\n",
    "df_train.TPSA.count()\n",
    "df_train[df_train.TPSA >= THRESHOLD].TPSA.count()/df_train.TPSA.count()\n",
    "df_train[df_train.TPSA < THRESHOLD].TPSA.count()/df_train.TPSA.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5bab9-6b23-4078-a398-dccbea38ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = df_train.Metadata_Permiation.value_counts()\n",
    "_tmp[0], _tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59dcba1-6add-4446-aa27-a30564f42e54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for threshold in [68, 69, 70, 71, 72, 100]:\n",
    "    _tmp = (df_train['Metadata_TPSA'] >= threshold).value_counts()\n",
    "    print(f\"\\n TPSA threshold {threshold} \\n Total samples: {_tmp.sum()}\")\n",
    "    print(f\" Label 0: {_tmp[False]:>7d}      % {_tmp[False]*100/_tmp.sum():2.2f} \")\n",
    "    print(f\" Label 1: {_tmp[True]:>7d}      % {_tmp[True]*100/_tmp.sum():2.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1d01b-3946-4668-9c10-5fb3f2b3bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(4,4))\n",
    "# fig.canvas.draw()  # Need to draw the figure to define renderer\n",
    "# ax.set_title(\"AngleLabel example\")\n",
    "# # Plot two crossing lines and label each angle between them with the above\n",
    "# center = (4.5, 650)\n",
    "# p1 = [(2.5, 710), (6.0, 605)]\n",
    "# p2 = [(3.0, 275), (5.5, 900)]\n",
    "# line1, = ax.plot(*zip(*p1))\n",
    "# line2, = ax.plot(*zip(*p2))\n",
    "# point, = ax.plot(*center, marker=\"o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19bd08-45c1-4d41-9d02-a5b59d30c53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:37:34.108730Z",
     "start_time": "2023-06-28T19:37:34.072553Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "num_bins = 200\n",
    "# fig, ax = plt.subplots()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "sigma = df_train.Metadata_TPSA.std()\n",
    "mu = df_train.Metadata_TPSA.mean()\n",
    "med = df_train.Metadata_TPSA.median()\n",
    "# the histogram of the data\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "n, bins, patches = plt.hist(df_train.Metadata_TPSA, num_bins, density=False, range=[0, 500],)\n",
    "# p1 = [(med, 710), (6.0, 605)]\n",
    "# _ = plt.vlines(x=med, ymin=10, ymax=17000, colors='red', linestyles='-', lw=1.75, label='Single Short Line')\n",
    "_ = plt.axvline(x=med, ymin=0, ymax=.97, color='red', linestyle='-', lw=1.75, label='Single Short Line')\n",
    "_ = plt.xlabel('TPSA Value');\n",
    "_ = plt.ylabel('# Compounds');\n",
    "_ = plt.title(fr'TPSA distribution -  $\\mu={mu:.3f}$    $\\sigma={sigma:.3f}$')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0)\n",
    "# axs[1].hist(dist2, bins=n_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c33d9-a56a-4175-9936-b16efed13334",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Stratified CV data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36185b9f-f76e-4556-a736-7a97ac07659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532d16b-50f2-486d-a2b8-22e960f6007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    use_groups = \"Group\" in type(cv).__name__\n",
    "    groups = group if use_groups else None\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=groups)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, 100],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3f078-8b33-4acc-b639-6daac6d9d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1165a3b-5756-443f-ad46-bf316c34929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1338)\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "n_splits = 4\n",
    "\n",
    "# Generate the class/group data\n",
    "# n_points = 100\n",
    "# X = rng.randn(100, 10)\n",
    "\n",
    "# percentiles_classes = [0.1, 0.3, 0.6]\n",
    "# y = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd8391-cbf3-4468-9aa2-d311c7f83bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate uneven groups\n",
    "\n",
    "# group_prior = rng.dirichlet([2] * 10)\n",
    "# group_prior.sum()\n",
    "# group_prior\n",
    "\n",
    "# groups = np.repeat(np.arange(10), rng.multinomial(100, group_prior))\n",
    "# groups.shape\n",
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be667cf-b73b-49d9-8f93-028feb33dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.repeat(0, train_X.shape[0])\n",
    "groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc3e15-7328-43d7-87b0-e662e89f8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_groups(train_y, groups, \"no groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b44ef-5b62-4008-8e90-fcd97dca2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "groups = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5f1e4-9fbf-4c51-a82a-ee2c870850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cv = KFold(n_splits)\n",
    "plot_cv_indices(cv, train_X, train_y, groups, ax, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1cd39-be31-4f80-b0b3-a064ddf5b59d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987503fe-4de3-4967-a228-9e5b7a6d30b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Read Embedded Features CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b33d4-10b8-44a2-a97b-3fb5e124812e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_TRAIN_INPUT = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = BASE_runmode ,datatype='train'))\n",
    "BASE_TEST_INPUT  = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = BASE_runmode ,datatype='test'))\n",
    "SNNL_TRAIN_INPUT = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = SNNL_runmode ,datatype='train'))\n",
    "SNNL_TEST_INPUT  = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = SNNL_runmode ,datatype='test'))\n",
    "BASE_TRAIN_INPUT\n",
    "BASE_TEST_INPUT \n",
    "SNNL_TRAIN_INPUT\n",
    "SNNL_TEST_INPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff17ab-dd6a-49fe-8733-8f3448537618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(SNNL_TEST_INPUT )\n",
    "df_train = pd.read_csv(SNNL_TRAIN_INPUT)\n",
    "\n",
    "# df_train = pd.read_csv(BASE_TRAIN_INPUT)\n",
    "# df_test = pd.read_csv(BASE_TEST_INPUT )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, nrows = 100 )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, usecols = ['Metadata_Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a273e-36aa-4b1b-8a49-3c911fe62659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.shape\n",
    "df_test.columns\n",
    "df_test.iloc[:5,:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21aa50d-b501-4532-9c1f-62a2c960f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(TRAIN_INPUT, nrows = 100 )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, usecols = ['Metadata_Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e266886-b249-4370-84ef-242c34c98e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = df_test.iloc[:,10:11].to_numpy().ravel().astype(np.uint8)\n",
    "test_y.sum()\n",
    "test_y.shape, type(test_y), test_y.dtype\n",
    "test_X = df_test.iloc[:,11:].to_numpy()\n",
    "test_X.shape,type(test_X), test_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccbf57-4fa7-4842-919b-103d14e44c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape\n",
    "df_train.info()\n",
    "df_train.iloc[:5,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d392e-68eb-4474-ad37-12244f4d23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "312000+34542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710ee4c-badf-4f28-a214-f8354f6c1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_train.iloc[:,10:11].to_numpy().ravel().astype(np.uint8)\n",
    "train_y.sum()\n",
    "train_y.shape, type(train_y), train_y.dtype\n",
    "\n",
    "train_X = df_train.iloc[:,11:].to_numpy()\n",
    "train_X.shape,type(train_X) ,train_X.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c738a2-74d5-4702-a93f-36428714aedf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Standardize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba790ed-fea3-4803-bf33-91b2a0d74fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab780bd-8b49-46ce-b18b-abc1e0ff181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "# print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ed6ad-1c8c-4c10-9bc5-82e6fcc9fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy = True)\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a118cd-aed2-4e64-a4da-8de20a99be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After Standard Scaler Transformation\")\n",
    "print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685b4df-8975-4935-8bd2-edba44873a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts([(\"Training\", train_y), (\"Test\", test_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7ad73-1936-428c-bd8e-341f594d816b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cp311]",
   "language": "python",
   "name": "conda-env-cp311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
