{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# XGBoost - Without XGBoost's Dask interface\n",
    "\n",
    "**Using Optuna for hyper-parameter search  to predict TPSA from Pharmacophores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:25.298115Z",
     "start_time": "2023-12-21T20:50:24.855884Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T10:55:29.477009Z",
     "iopub.status.busy": "2024-01-05T10:55:29.476527Z",
     "iopub.status.idle": "2024-01-05T10:55:29.937865Z",
     "shell.execute_reply": "2024-01-05T10:55:29.936292Z",
     "shell.execute_reply.started": "2024-01-05T10:55:29.476963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload  \n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:28.460258Z",
     "start_time": "2023-12-21T20:50:25.868966Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T10:55:29.941138Z",
     "iopub.status.busy": "2024-01-05T10:55:29.940419Z",
     "iopub.status.idle": "2024-01-05T10:55:32.463828Z",
     "shell.execute_reply": "2024-01-05T10:55:32.463040Z",
     "shell.execute_reply.started": "2024-01-05T10:55:29.941095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniforge3/envs/cp/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 10.0.1. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import itertools\n",
    "from collections.abc import Iterator\n",
    "from   datetime import datetime\n",
    "from pprint import PrettyPrinter\n",
    "import joblib\n",
    "\n",
    "from utils import *\n",
    "from utils_ml import model_selection\n",
    "# from multiprocessing import Pool, process\n",
    "\n",
    "import dask.dataframe as dd \n",
    "pp = PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:28.476862Z",
     "start_time": "2023-12-21T20:50:28.461907Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T10:55:32.465762Z",
     "iopub.status.busy": "2024-01-05T10:55:32.465303Z",
     "iopub.status.idle": "2024-01-05T10:55:32.489621Z",
     "shell.execute_reply": "2024-01-05T10:55:32.488914Z",
     "shell.execute_reply.started": "2024-01-05T10:55:32.465724Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Train.ipynb\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost and dask imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:31.139023Z",
     "start_time": "2023-12-21T20:50:30.891155Z"
    },
    "execution": {
     "iopub.execute_input": "2024-01-05T10:55:32.490736Z",
     "iopub.status.busy": "2024-01-05T10:55:32.490522Z",
     "iopub.status.idle": "2024-01-05T10:55:33.111046Z",
     "shell.execute_reply": "2024-01-05T10:55:33.110301Z",
     "shell.execute_reply.started": "2024-01-05T10:55:32.490714Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# from dask_cuda import LocalCUDACluster\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import LocalCluster\n",
    "import dask_ml.model_selection as dcv\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.model_selection import GridSearchCV, IncrementalSearchCV, HyperbandSearchCV\n",
    "from dask_ml.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T10:55:33.113045Z",
     "iopub.status.busy": "2024-01-05T10:55:33.112791Z",
     "iopub.status.idle": "2024-01-05T10:55:33.140360Z",
     "shell.execute_reply": "2024-01-05T10:55:33.139661Z",
     "shell.execute_reply.started": "2024-01-05T10:55:33.113023Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/04/24-14:56:44.475938\n",
      "2024-56-04 14:01:44.476080\n"
     ]
    }
   ],
   "source": [
    "# time.strftime(' %x%X')\n",
    "# datetime.now().strftime('%X.%f')\n",
    "# time.strftime('%X %x %Z')\n",
    "print(datetime.now().strftime('%D-%X.%f'))\n",
    "time_fmt = '%Y-%M-%d %H:%m:%S.%f'\n",
    "print(datetime.now().strftime(time_fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 14:56:44,500 - INFO: -  1/7- engine connected\n",
      "2024-01-04 14:56:44,501 - WARNING: -  1/7- engine connected\n",
      "2024-01-04 14:56:44,502 - ERROR: -  1/7- engine connected\n",
      "2024-01-04 14:56:44,502 - CRITICAL: -  1/7- engine connected\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logLevel = os.environ.get('LOG_LEVEL', 'INFO').upper()\n",
    "FORMAT = '%(asctime)s - %(levelname)s: - %(message)s'\n",
    "logging.basicConfig(level=\"INFO\", format= FORMAT)\n",
    "logging.getLogger(\"imported_module\").setLevel(logging.CRITICAL)\n",
    "logging.info(f\" 1/7- engine connected\")\n",
    "logging.warning(f\" 1/7- engine connected\")\n",
    "logging.error(f\" 1/7- engine connected\")\n",
    "logging.critical(f\" 1/7- engine connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:32.339732Z",
     "start_time": "2023-12-21T20:50:32.323764Z"
    }
   },
   "outputs": [],
   "source": [
    "def result_model_selection(results, name):\n",
    "    df_results = pd.DataFrame({'model'     : [name] * len(results.cv_results_['params']),\n",
    "                               'params'    : results.cv_results_['params'],\n",
    "                               'mean score': results.cv_results_['mean_test_score'],\n",
    "                               'std score' : results.cv_results_['std_test_score'],\n",
    "                               'rank'      : results.cv_results_['rank_test_score']\n",
    "                              })\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dask cluster and client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:41.337029Z",
     "start_time": "2023-12-21T20:50:40.947431Z"
    }
   },
   "outputs": [],
   "source": [
    "# cluster = LocalCluster(\"Kevins_Cluster\", n_workers=2, threads_per_worker=2)\n",
    "# cluster = LocalCluster()\n",
    "\n",
    "# client = Client(cluster.scheduler_address)\n",
    "# client = Client(\"tcp://127.0.0.1:37937\")\n",
    "# client = Client(processes = False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client close failed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.close()\n",
    "    del client\n",
    "except Exception as e:\n",
    "    print(\"Client close failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster close failed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    del cluster\n",
    "except Exception as e:\n",
    "    print(\"Cluster close failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:41.337029Z",
     "start_time": "2023-12-21T20:50:40.947431Z"
    }
   },
   "outputs": [],
   "source": [
    "# cluster = LocalCluster()\n",
    "# client = Client(\"tcp://127.0.0.1:37937\")\n",
    "# client = Client(processes = False)\n",
    "# cluster = LocalCluster(\"Kevins_Cluster\", n_workers=2, threads_per_worker=2)\n",
    "# client = Client(cluster.scheduler_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster\n",
    "\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.workers\n",
    "# cluster.scale(2)\n",
    "# cluster.close()\n",
    "# client.close()\n",
    "# del cluster\n",
    "\n",
    "# cluster.name\n",
    "# print(cluster)\n",
    "# cluster.dashboard_link\n",
    "# cluster.scheduler_address\n",
    "# cluster.scheduler_spec\n",
    "# cluster.workers\n",
    "\n",
    "# cluster.scheduler.stop()\n",
    "# cluster.scheduler.close()\n",
    "\n",
    "# client \n",
    "# client.status\n",
    "# client.connection_args\n",
    "# del client\n",
    "\n",
    "# with open(\"./metadata/parquet_columns.pkl\",'rb') as f:\n",
    "#     ParquetColumns = pickle.load(f)\n",
    "\n",
    "# for k,v in ParquetColumns.items():\n",
    "#     print(f\" {k:20s}   items: {len(v)}\")\n",
    "\n",
    "# type(ParquetColumns['Cells']['Cells_AreaShape_Area'])\n",
    "# ParquetColumns['Cells']\n",
    "# del ParquetColumns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:35.620802Z",
     "start_time": "2023-12-21T20:50:35.605234Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix = '' ### Target-2' , 'MOA'\n",
    "input_path =\"./input/\"\n",
    "output_path =\"./output_11102023/\"\n",
    "prefix_lc = prefix.lower().replace('-', '_')\n",
    "\n",
    "CompoundExtendedMetadata2SampleFile = f\"{output_path}{prefix_lc}compound_extended_metadata_2samples.csv\"\n",
    "CompoundProfiles2SampleFileCSV      = f\"{output_path}{prefix_lc}compound_profiles_2samples.csv\"\n",
    "CompoundExtendedMetadataSampleFile  = f\"{output_path}{prefix_lc}compound_extended_metadata_samples.csv\"\n",
    "featureSelectionFile                = f\"{output_path}feature_selection_columns.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:35.940324Z",
     "start_time": "2023-12-21T20:50:35.923756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Compound Extended Metadata 2 SampleFile  : ./output_11102023/compound_extended_metadata_2samples.csv\n",
      " Compound Profiles 2 Samples File CSV     : ./output_11102023/compound_profiles_2samples.csv\n",
      " \n",
      " featureSelectionFile                     : ./output_11102023/feature_selection_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f\" Compound Extended Metadata 2 SampleFile  : {CompoundExtendedMetadata2SampleFile }\")\n",
    "print(f\" Compound Profiles 2 Samples File CSV     : {CompoundProfiles2SampleFileCSV}\")\n",
    "print(f\" \")\n",
    "print(f\" featureSelectionFile                     : {featureSelectionFile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read column metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:50:55.041400Z",
     "start_time": "2023-12-21T20:50:55.011436Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " selected                1477 \n",
      " dropped_correlation     2193 \n",
      " dropped_variance        0 \n",
      " len(x_columms)    : 1477\n",
      " len(y_columms)    : 1\n",
      " len(all_columms)  : 1478\n"
     ]
    }
   ],
   "source": [
    "with open(\"./metadata/feature_selection_columns.pkl\", 'rb') as f: \n",
    "    x = pickle.load(f)\n",
    "for i in x:\n",
    "    print(f\" {i:20s}    {len(x[i])} \")\n",
    "\n",
    "X_columns = x['selected']\n",
    "y_columns = [ \"Metadata_log10TPSA\"]\n",
    "\n",
    "all_columns = [\"Metadata_log10TPSA\"]\n",
    "all_columns.extend(x['selected'])\n",
    "\n",
    "x_columns_drop = [\"Metadata_Source\", \"Metadata_Batch\", \"Metadata_Plate\", \"Metadata_Well\", \"Metadata_TPSA\", \"Metadata_lnTPSA\", \"Metadata_log10TPSA\"]\n",
    "# x_columns_drop.extend([\"Metadata_JCP2022\"])\n",
    "\n",
    "x_columns_dtype = {x: np.dtype('float32') for x in X_columns}\n",
    "y_columns_dtype = {x: np.dtype('float32') for x in y_columns} ## \"Metadata_log10TPSA\":np.dtype('float64')}\n",
    "all_columns_dtype = {x: np.dtype('float32') for x in all_columns}\n",
    "\n",
    "print(f\" len(x_columms)    : {len(X_columns)}\")\n",
    "print(f\" len(y_columms)    : {len(y_columns)}\")\n",
    "print(f\" len(all_columms)  : {len(all_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read compound profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Profiles file       :  ./output_11102023/compound_profiles_2samples.csv\n",
      " Features select file:  ./output_11102023/feature_selection_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "# Apply feature selection\n",
    "profilesFile = CompoundProfiles2SampleFileCSV ## +'.'+ type_bz2\n",
    "\n",
    "print(f\" Profiles file       :  {profilesFile}\")\n",
    "print(f\" Features select file:  {featureSelectionFile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:38:33.906700Z",
     "start_time": "2023-07-31T18:38:33.684133Z"
    }
   },
   "outputs": [],
   "source": [
    "df_profiles = dd.read_csv(profilesFile, usecols=all_columns, dtype= all_columns_dtype)\n",
    "\n",
    "# df_profiles.info()\n",
    "# df_profiles.head(6)\n",
    "# del df_X\n",
    "# del df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_log10TPSA</th>\n",
       "      <th>Cells_AreaShape_BoundingBoxMaximum_X</th>\n",
       "      <th>Cells_AreaShape_Center_X</th>\n",
       "      <th>Cells_AreaShape_Center_Y</th>\n",
       "      <th>Cells_AreaShape_Compactness</th>\n",
       "      <th>Cells_AreaShape_Eccentricity</th>\n",
       "      <th>Cells_AreaShape_EulerNumber</th>\n",
       "      <th>Cells_AreaShape_Extent</th>\n",
       "      <th>Cells_AreaShape_MajorAxisLength</th>\n",
       "      <th>Cells_AreaShape_MedianRadius</th>\n",
       "      <th>...</th>\n",
       "      <th>Nuclei_Texture_SumAverage_DNA_10_01_256</th>\n",
       "      <th>Nuclei_Texture_SumAverage_ER_10_01_256</th>\n",
       "      <th>Nuclei_Texture_SumAverage_Mito_10_01_256</th>\n",
       "      <th>Nuclei_Texture_SumAverage_RNA_10_01_256</th>\n",
       "      <th>Nuclei_Texture_SumEntropy_DNA_10_03_256</th>\n",
       "      <th>Nuclei_Texture_SumVariance_AGP_10_03_256</th>\n",
       "      <th>Nuclei_Texture_SumVariance_DNA_10_03_256</th>\n",
       "      <th>Nuclei_Texture_SumVariance_ER_10_01_256</th>\n",
       "      <th>Nuclei_Texture_SumVariance_Mito_10_03_256</th>\n",
       "      <th>Nuclei_Texture_SumVariance_RNA_10_01_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.803116</td>\n",
       "      <td>-0.377545</td>\n",
       "      <td>-0.294115</td>\n",
       "      <td>-1.370007</td>\n",
       "      <td>-0.010496</td>\n",
       "      <td>-0.296029</td>\n",
       "      <td>-0.134166</td>\n",
       "      <td>-0.207722</td>\n",
       "      <td>-0.156127</td>\n",
       "      <td>-0.230863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.591573</td>\n",
       "      <td>0.950152</td>\n",
       "      <td>0.110363</td>\n",
       "      <td>-0.151072</td>\n",
       "      <td>-0.267783</td>\n",
       "      <td>-0.319627</td>\n",
       "      <td>-0.135347</td>\n",
       "      <td>0.033476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.771293</td>\n",
       "      <td>-0.939467</td>\n",
       "      <td>-0.850871</td>\n",
       "      <td>-1.398116</td>\n",
       "      <td>-0.045341</td>\n",
       "      <td>-0.525316</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>-0.510080</td>\n",
       "      <td>-0.222982</td>\n",
       "      <td>-0.286020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551443</td>\n",
       "      <td>-0.421324</td>\n",
       "      <td>0.020442</td>\n",
       "      <td>0.349053</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>-0.150682</td>\n",
       "      <td>-0.108719</td>\n",
       "      <td>-0.561259</td>\n",
       "      <td>-0.330110</td>\n",
       "      <td>-0.246885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.771293</td>\n",
       "      <td>-0.939467</td>\n",
       "      <td>-0.850871</td>\n",
       "      <td>-1.398116</td>\n",
       "      <td>-0.045341</td>\n",
       "      <td>-0.525316</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>-0.510080</td>\n",
       "      <td>-0.222982</td>\n",
       "      <td>-0.286020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551443</td>\n",
       "      <td>-0.421324</td>\n",
       "      <td>0.020442</td>\n",
       "      <td>0.349053</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>-0.150682</td>\n",
       "      <td>-0.108719</td>\n",
       "      <td>-0.561259</td>\n",
       "      <td>-0.330110</td>\n",
       "      <td>-0.246885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metadata_log10TPSA  Cells_AreaShape_BoundingBoxMaximum_X  Cells_AreaShape_Center_X  Cells_AreaShape_Center_Y  Cells_AreaShape_Compactness  \\\n",
       "0            1.803116                             -0.377545                 -0.294115                 -1.370007                    -0.010496   \n",
       "1            1.771293                             -0.939467                 -0.850871                 -1.398116                    -0.045341   \n",
       "2            1.771293                             -0.939467                 -0.850871                 -1.398116                    -0.045341   \n",
       "\n",
       "   Cells_AreaShape_Eccentricity  Cells_AreaShape_EulerNumber  Cells_AreaShape_Extent  Cells_AreaShape_MajorAxisLength  Cells_AreaShape_MedianRadius  ...  \\\n",
       "0                     -0.296029                    -0.134166               -0.207722                        -0.156127                     -0.230863  ...   \n",
       "1                     -0.525316                     0.146076               -0.510080                        -0.222982                     -0.286020  ...   \n",
       "2                     -0.525316                     0.146076               -0.510080                        -0.222982                     -0.286020  ...   \n",
       "\n",
       "   Nuclei_Texture_SumAverage_DNA_10_01_256  Nuclei_Texture_SumAverage_ER_10_01_256  Nuclei_Texture_SumAverage_Mito_10_01_256  Nuclei_Texture_SumAverage_RNA_10_01_256  \\\n",
       "0                                 0.151205                                0.016566                                  0.591573                                 0.950152   \n",
       "1                                 0.551443                               -0.421324                                  0.020442                                 0.349053   \n",
       "2                                 0.551443                               -0.421324                                  0.020442                                 0.349053   \n",
       "\n",
       "   Nuclei_Texture_SumEntropy_DNA_10_03_256  Nuclei_Texture_SumVariance_AGP_10_03_256  Nuclei_Texture_SumVariance_DNA_10_03_256  Nuclei_Texture_SumVariance_ER_10_01_256  \\\n",
       "0                                 0.110363                                 -0.151072                                 -0.267783                                -0.319627   \n",
       "1                                 0.372093                                 -0.150682                                 -0.108719                                -0.561259   \n",
       "2                                 0.372093                                 -0.150682                                 -0.108719                                -0.561259   \n",
       "\n",
       "   Nuclei_Texture_SumVariance_Mito_10_03_256  Nuclei_Texture_SumVariance_RNA_10_01_256  \n",
       "0                                  -0.135347                                  0.033476  \n",
       "1                                  -0.330110                                 -0.246885  \n",
       "2                                  -0.330110                                 -0.246885  \n",
       "\n",
       "[3 rows x 1478 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_profiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:38:33.906700Z",
     "start_time": "2023-07-31T18:38:33.684133Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_X = dd.read_csv(profilesFile, blocksize=\"100MB\", usecols=X_columns, dtype= x_columns_dtype)  ##, index_col = 'CASRN')\n",
    "# df_y = dd.read_csv(profilesFile, blocksize=\"100MB\", usecols=y_columns, dtype=y_columns_dtype)  ##, index_col = 'CASRN')\n",
    "\n",
    "# df_X.info()\n",
    "# df_X.head()\n",
    "# df_X.shape\n",
    "\n",
    "# df_y_array.info()\n",
    "# df_y_array.head()\n",
    "# df_y_array.shape\n",
    "\n",
    "# df_X_array = df_X.to_dask_array(lengths = True)\n",
    "\n",
    "# df_X_array = df_X_array.rechunk(chunks=(10000,-1))\n",
    "# df_X_array.to_zarr('df_X_array.zarr' ) \n",
    "\n",
    "# df_y_array = df_y.to_dask_array(lengths = True)\n",
    "\n",
    "# df_y_array = df_y_array.rechunk(chunks=(10000,-1))\n",
    "# df_y_array.to_zarr('df_y_array.zarr' ) \n",
    "\n",
    "# df_X_array.to_hdf5('df_X_array.hdf5' , '/x')  \n",
    "# df_y_array.to_hdf5('df_y_array.hdf5' , '/x')  \n",
    "\n",
    "# del df_X, df_y, df_X_array, df_y_array\n",
    "\n",
    "# df_y = df_profiles[y_columns].compute()\n",
    "# df_X = df_profiles[list(x['selected'])] ## .drop(labels=x_columns_drop, axis =1)\n",
    "\n",
    "# df_X_array = dask.array.from_zarr('df_X_array.zarr' )\n",
    "\n",
    "# df_y_array = dask.array.from_zarr('df_y_array.zarr' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBoost - Using Optuna for hyper-parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv_splits(n_folds: int = 5,) -> Iterator[tuple[dd.DataFrame, dd.DataFrame]]:\n",
    "    frac = [1 / n_folds] * n_folds\n",
    "    print(frac, n_folds)\n",
    "    splits = df_profiles.random_split(frac, shuffle=True)\n",
    "    # print(f\"splits: {type(splits)} \")\n",
    "    for i in range(n_folds):\n",
    "        print(type(splits[i]))\n",
    "        train = [splits[j] for j in range(n_folds) if j != i]\n",
    "        train = dd.concat(train)\n",
    "        test = splits[i] \n",
    "        # print(type(train), type(test))\n",
    "        yield train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T15:34:59.292418Z",
     "iopub.status.busy": "2024-01-03T15:34:59.292141Z",
     "iopub.status.idle": "2024-01-03T15:34:59.492785Z",
     "shell.execute_reply": "2024-01-03T15:34:59.492018Z",
     "shell.execute_reply.started": "2024-01-03T15:34:59.292401Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(**study_params):\n",
    "    scores = []\n",
    "    client = None\n",
    "    \n",
    "    for i, (train, test) in enumerate(make_cv_splits()):\n",
    "        logging.info(f\"Training/Test split #{i}\")\n",
    "        y_train = train[y_columns]\n",
    "        X_train = train.drop(columns=y_columns)\n",
    "        y_test = test[y_columns]\n",
    "        X_test = test.drop(columns=y_columns)\n",
    "\n",
    "        logging.info(f\"Building DMatrix...\")\n",
    "        d_train = xgb.DMatrix(\n",
    "            # client, \n",
    "            X_train, y_train,\n",
    "        )\n",
    "        d_test = xgb.DMatrix(X_test)\n",
    "        logging.info(f\"Building DMatrix...Completed\")\n",
    "\n",
    "        logging.info(f\"Training model...\")\n",
    "        model = xgb.train(\n",
    "            # client,\n",
    "            {\"tree_method\": \"hist\", **study_params},\n",
    "            d_train,\n",
    "            num_boost_round=24,\n",
    "            evals=[(d_train, \"train\")],\n",
    "        )\n",
    "        logging.info(f\"Training model...Completed\")\n",
    "\n",
    "        logging.info(f\"Running model on test data...\")\n",
    "        predictions = model.predict(# client, \n",
    "                                    # model, \n",
    "                                    # X_test,\n",
    "                                    d_test\n",
    "                                   )\n",
    "        logging.info(f\"Running model on test data...Completed\")\n",
    "\n",
    "        logging.info(f\"Measuring accuracy of model vs. ground truth...\")\n",
    "        score = mean_squared_error(\n",
    "            y_true = y_test.to_dask_array(),\n",
    "            y_pred = predictions,\n",
    "            # y_true = y_test,\n",
    "            # y_pred = predictions.to_dask_array(),\n",
    "            squared=False,\n",
    "            compute=False,\n",
    "        )\n",
    "        logging.info(f\"Measuring accuracy of model vs. ground truth...Completed\")\n",
    " \n",
    "        # Compute predictions and mean squared error for this iteration\n",
    "        # while we start the next one\n",
    "        scores.append(score.reshape(1).persist())\n",
    "        del d_train, d_test, y_test, X_test,  model, predictions, score\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    scores = da.concatenate(scores).compute()\n",
    "    print(f\"RSME={scores.mean()} +/- {scores.std()}\")\n",
    "    return scores.mean()\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T15:35:00.017633Z",
     "iopub.status.busy": "2024-01-03T15:35:00.017336Z",
     "iopub.status.idle": "2024-01-03T15:35:00.037647Z",
     "shell.execute_reply": "2024-01-03T15:35:00.036983Z",
     "shell.execute_reply.started": "2024-01-03T15:35:00.017614Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\"     : trial.suggest_int(\"n_estimators\", 75, 125),\n",
    "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\", 0.5, 0.7),\n",
    "        # \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.5, 1),\n",
    "        # \"colsample_bynode\" : trial.suggest_float(\"colsample_bynode\", 0.5, 1),\n",
    "        # \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1),\n",
    "        # \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        \"max_depth\"        : trial.suggest_int(\"max_depth\", 1, 6),\n",
    "        \"max_leaves\"       : trial.suggest_int(\"max_leaves\", 0, 2),\n",
    "        # \"max_cat_to_onehot\": trial.suggest_int(\"max_cat_to_onehot\", 1, 10),\n",
    "    }\n",
    "    \n",
    "    print(f\"Training model (trial #{trial.number}) - Parameters:\")\n",
    "    for k, v in params.items():\n",
    "        print(f\"  {k}={v}\")\n",
    "    return train_model(**params)\n",
    "    # return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T15:35:00.487104Z",
     "iopub.status.busy": "2024-01-03T15:35:00.486647Z",
     "iopub.status.idle": "2024-01-03T15:35:00.558191Z",
     "shell.execute_reply": "2024-01-03T15:35:00.557566Z",
     "shell.execute_reply.started": "2024-01-03T15:35:00.487075Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "try:\n",
    "    optuna.delete_study(storage=\"sqlite:///example.db\", study_name=\"kevin-study-1\")\n",
    "except Exception as e:\n",
    "    print(\"delete failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T15:35:00.802035Z",
     "iopub.status.busy": "2024-01-03T15:35:00.801332Z",
     "iopub.status.idle": "2024-01-03T15:35:00.854775Z",
     "shell.execute_reply": "2024-01-03T15:35:00.854174Z",
     "shell.execute_reply.started": "2024-01-03T15:35:00.801999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-03 16:35:00,849] A new study created in RDB with name: kevin-study-1\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(storage=\"sqlite:///example.db\",\n",
    "                            study_name=\"kevin-study-1\",\n",
    "                            direction=\"maximize\", load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T15:35:01.086354Z",
     "iopub.status.busy": "2024-01-03T15:35:01.085933Z",
     "iopub.status.idle": "2024-01-03T16:39:44.930118Z",
     "shell.execute_reply": "2024-01-03T16:39:44.928461Z",
     "shell.execute_reply.started": "2024-01-03T15:35:01.086334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  0:00:00.597776\n",
      "Training model (trial #0) - Parameters:\n",
      "  n_estimators=96\n",
      "  learning_rate=0.6772057433643197\n",
      "  max_depth=6\n",
      "  max_leaves=2\n",
      "[0.2, 0.2, 0.2, 0.2, 0.2] 5\n",
      "splits: <class 'list'> \n",
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:35:03,127 - INFO: - Building DMatrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> <class 'dask.dataframe.core.DataFrame'>\n",
      "Training/Test split #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:44:31,050 - INFO: - Building DMatrix...Completed\n",
      "2024-01-03 16:44:31,055 - INFO: - Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:44:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181279512/work/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.46213\n",
      "[1]\ttrain-rmse:0.21765\n",
      "[2]\ttrain-rmse:0.17330\n",
      "[3]\ttrain-rmse:0.16795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:44:46,909 - INFO: - Training model...Completed\n",
      "2024-01-03 16:44:46,911 - INFO: - Running model on test data...\n",
      "2024-01-03 16:44:46,930 - INFO: - Running model on test data...Completed\n",
      "2024-01-03 16:44:46,933 - INFO: - Measuring accuracy of model vs. ground truth...\n",
      "2024-01-03 16:44:46,949 - INFO: - Measuring accuracy of model vs. ground truth...Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:48:00,625 - INFO: - Building DMatrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> <class 'dask.dataframe.core.DataFrame'>\n",
      "Training/Test split #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:57:42,437 - INFO: - Building DMatrix...Completed\n",
      "2024-01-03 16:57:42,441 - INFO: - Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181279512/work/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.46187\n",
      "[1]\ttrain-rmse:0.21742\n",
      "[2]\ttrain-rmse:0.17306\n",
      "[3]\ttrain-rmse:0.16771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:57:56,799 - INFO: - Training model...Completed\n",
      "2024-01-03 16:57:56,801 - INFO: - Running model on test data...\n",
      "2024-01-03 16:57:56,831 - INFO: - Running model on test data...Completed\n",
      "2024-01-03 16:57:56,834 - INFO: - Measuring accuracy of model vs. ground truth...\n",
      "2024-01-03 16:57:56,848 - INFO: - Measuring accuracy of model vs. ground truth...Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "<class 'dask.dataframe.core.DataFrame'> <class 'dask.dataframe.core.DataFrame'>\n",
      "Training/Test split #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:01:10,748 - INFO: - Building DMatrix...\n",
      "2024-01-03 17:10:49,847 - INFO: - Building DMatrix...Completed\n",
      "2024-01-03 17:10:49,850 - INFO: - Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:10:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181279512/work/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.46210\n",
      "[1]\ttrain-rmse:0.21781\n",
      "[2]\ttrain-rmse:0.17353\n",
      "[3]\ttrain-rmse:0.16818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:11:02,552 - INFO: - Training model...Completed\n",
      "2024-01-03 17:11:02,564 - INFO: - Running model on test data...\n",
      "2024-01-03 17:11:02,581 - INFO: - Running model on test data...Completed\n",
      "2024-01-03 17:11:02,583 - INFO: - Measuring accuracy of model vs. ground truth...\n",
      "2024-01-03 17:11:02,593 - INFO: - Measuring accuracy of model vs. ground truth...Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:14:10,214 - INFO: - Building DMatrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> <class 'dask.dataframe.core.DataFrame'>\n",
      "Training/Test split #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:23:19,367 - INFO: - Building DMatrix...Completed\n",
      "2024-01-03 17:23:19,375 - INFO: - Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181279512/work/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.46200\n",
      "[1]\ttrain-rmse:0.21747\n",
      "[2]\ttrain-rmse:0.17307\n",
      "[3]\ttrain-rmse:0.16771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:23:32,391 - INFO: - Training model...Completed\n",
      "2024-01-03 17:23:32,393 - INFO: - Running model on test data...\n",
      "2024-01-03 17:23:32,419 - INFO: - Running model on test data...Completed\n",
      "2024-01-03 17:23:32,420 - INFO: - Measuring accuracy of model vs. ground truth...\n",
      "2024-01-03 17:23:32,444 - INFO: - Measuring accuracy of model vs. ground truth...Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:26:46,540 - INFO: - Building DMatrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'> <class 'dask.dataframe.core.DataFrame'>\n",
      "Training/Test split #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:36:21,250 - INFO: - Building DMatrix...Completed\n",
      "2024-01-03 17:36:21,260 - INFO: - Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:36:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181279512/work/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.46201\n",
      "[1]\ttrain-rmse:0.21757\n",
      "[2]\ttrain-rmse:0.17322\n",
      "[3]\ttrain-rmse:0.16785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:36:34,027 - INFO: - Training model...Completed\n",
      "2024-01-03 17:36:34,028 - INFO: - Running model on test data...\n",
      "2024-01-03 17:36:34,048 - INFO: - Running model on test data...Completed\n",
      "2024-01-03 17:36:34,050 - INFO: - Measuring accuracy of model vs. ground truth...\n",
      "2024-01-03 17:36:34,073 - INFO: - Measuring accuracy of model vs. ground truth...Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-03 17:39:44,920] Trial 0 finished with value: 0.1684536188840866 and parameters: {'n_estimators': 96, 'learning_rate': 0.6772057433643197, 'max_depth': 6, 'max_leaves': 2}. Best is trial 0 with value: 0.1684536188840866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "RSME=0.1684536188840866 +/- 0.0007142742979340255\n",
      "Number of finished trials:  1\n",
      "Best trial:\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total time:  {datetime.now() - start}\")\n",
    "\n",
    "study.optimize(objective, n_trials=10, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T11:35:49.191279Z",
     "iopub.status.busy": "2024-01-03T11:35:49.190638Z",
     "iopub.status.idle": "2024-01-03T11:42:02.496882Z",
     "shell.execute_reply": "2024-01-03T11:42:02.495842Z",
     "shell.execute_reply.started": "2024-01-03T11:35:49.191255Z"
    }
   },
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  Number of estimators: {}\".format(trial.user_attrs[\"n_estimators\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:51:34.419906Z",
     "start_time": "2023-12-21T20:51:34.402698Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-22T11:55:35.682396Z",
     "iopub.status.busy": "2023-12-22T11:55:35.682188Z",
     "iopub.status.idle": "2023-12-22T11:55:35.698897Z",
     "shell.execute_reply": "2023-12-22T11:55:35.698139Z",
     "shell.execute_reply.started": "2023-12-22T11:55:35.682384Z"
    }
   },
   "outputs": [],
   "source": [
    "# xgb_grid_parameters = {\n",
    "#     'learning_rate': [0.1, 0.01],\n",
    "#     'max_depth': [12, 10 ,8], \n",
    "#     'max_depth': [15,10,5],\n",
    "#     'min_child_weight':[5,3,2,1], \n",
    "#     'min_child_weight':[2,3], \n",
    "#     'gamma':[1,5, 10],  \n",
    "#     'gamma':[2.5, 3, 3.5, 4],  \n",
    "#     'subsample':[i/10.0 for i in range(6,11)],\n",
    "#     'subsample':[0.5],\n",
    "#     'colsample_bytree':[i/10.0 for i in range(5,11)], \n",
    "#     'colsample_bytree':[0.5], \n",
    "#     'n_estimators': [1250, 1000, 750, 500, 200]}\n",
    "# xgb_reg.set_params(**xgb_grid_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-03T15:22:08.592709Z",
     "iopub.status.idle": "2024-01-03T15:22:08.593505Z",
     "shell.execute_reply": "2024-01-03T15:22:08.593386Z",
     "shell.execute_reply.started": "2024-01-03T15:22:08.593367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# client.get_versions(check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBoost - Training using XGBoost native interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**`xgboost.train`** `(params, dtrain, num_boost_round=10, *, `\\\n",
    "`evals=None, obj=None, feval=None, maximize=None, early_stopping_rounds=None, `\\\n",
    "`evals_result=None, verbose_eval=True, xgb_model=None, callbacks=None, custom_metric=None)`\n",
    "\n",
    "**Parameters** \n",
    "\n",
    "**param** `(Dic[str, Any])`  Booster params\n",
    "\n",
    "**tree_method** string [default= auto] - The tree construction algorithm used in XGBoost. See description in the reference paper and Tree Methods. \\\n",
    "Choices: `auto, exact, approx, hist` - this is a combination of commonly used updaters. For other updaters like refresh, set the parameter updater directly.\\\n",
    "    `auto:` Same as the hist tree method.\\\n",
    "    `exact:` Exact greedy algorithm. Enumerates all split candidates.\\\n",
    "    `approx:` Approximate greedy algorithm using quantile sketch and gradient histogram.\\\n",
    "    `hist:` Faster histogram optimized approximate greedy algorithm.y algorithm.\n",
    "\n",
    "**Returns:** Booster: a trained booster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del output, dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "dtrain = xgb.dask.DaskDMatrix(client, train_X, train_y)\n",
    "\n",
    "dval = xgb.dask.DaskDMatrix(client, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    " \n",
    "    # X and y must be Dask dataframes or arrays\n",
    "    # num_obs = 1e5\n",
    "    # num_features = 20\n",
    "    # X = da.random.random(size=(num_obs, num_features), chunks=(1000, num_features))\n",
    "    # y = da.random.random(size=(num_obs, 1), chunks=(1000, 1))\n",
    "    # dtrain = xgb.dask.DaskDMatrix(client, X, y)\n",
    "    # or\n",
    "    # dtrain = xgb.dask.DaskQuantileDMatrix(client, X, y)\n",
    "    \n",
    "    early_stopping_rounds=20\n",
    "    es = xgb.callback.EarlyStopping(rounds=early_stopping_rounds, save_best=True)\n",
    "    \n",
    "    output = xgb.dask.train(\n",
    "        client,\n",
    "        {\"verbosity\": 2, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\"},\n",
    "        dtrain,\n",
    "        num_boost_round=200,\n",
    "        evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "        # xgb_model= output['booster'],\n",
    "        callbacks = [es],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "type(output['booster'])\n",
    "# output\n",
    "output['booster'][133]\n",
    "output['booster'].best_ntree_limit\n",
    "# output['history']['train']['rmse']\n",
    "# output['history']['val']['rmse']\n",
    "# prev_history = output['history']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(output['history']['train']['rmse']);\n",
    "plt.plot(output['history']['val']['rmse']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.yticks(fontsize = 12)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlim(10,50)\n",
    "ax = xgb.plot_importance(output['booster'], max_num_features= 30, ax = ax)\n",
    "# for label in ( ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "#     label.set_fontsize(22)\n",
    "ax.get_yticklabels()\n",
    "# ax.autoscale(enable=None, axis=\"y\", tight=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output['booster'][133].save_model('./save_20231218_233500_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = output['booster'][133].save_config()\n",
    "type(config)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output['booster'][133].save_model('./save_20231218_233500_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training using XGBoost Scikit-Learn Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:21:44.632586Z",
     "iopub.status.busy": "2023-12-18T16:21:44.632369Z",
     "iopub.status.idle": "2023-12-18T16:21:44.662923Z",
     "shell.execute_reply": "2023-12-18T16:21:44.661900Z",
     "shell.execute_reply.started": "2023-12-18T16:21:44.632572Z"
    }
   },
   "source": [
    "**XGBRegressor**\n",
    "\n",
    "Implementation of the scikit-learn API for XGBoost regression. See Using the Scikit-Learn Estimator Interface for more information.\n",
    "\n",
    "- **Gamma:** Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
    "\n",
    "- **max_depth:** Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. 0 indicates no limit on depth. \\\n",
    "  Beware that XGBoost aggressively consumes memory when training a deep tree. exact tree method requires non-zero value.\n",
    "\n",
    "- **min_child_weight:** Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of \\\n",
    "  instance weight less than min_child_weight, then the building process will give up further partitioning.\n",
    "\n",
    "- **subsample:** Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting.\\\n",
    "   Subsampling will occur once in every boosting iteration.\n",
    "  \n",
    "\n",
    "- **colsample_bytree:** is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "\n",
    "\n",
    "- **lambda:** L2 regularization term on weights. Increasing this value will make model more conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:08:43.483858Z",
     "start_time": "2023-05-29T13:08:43.470308Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import get_scorer_names\n",
    "# pp.pprint(get_scorer_names())\n",
    "# for i in get_scorer_names() :\n",
    "#     if \"error\" in i:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = xgb.callback.EarlyStopping(rounds=10, \n",
    "                                        metric_name='rmse', \n",
    "                                        # data_name='Validation_0', \n",
    "                                        save_best=True, \n",
    "                                        maximize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop.best_scores\n",
    "early_stop.metric_name\n",
    "early_stop.current_rounds\n",
    "# early_stop.stopping_history\n",
    "# len(early_stop.best_scores['validation_']['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:51:27.276277Z",
     "start_time": "2023-12-21T20:51:27.258417Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(random_state =123, \n",
    "                           n_jobs=None,\n",
    "                           objective ='reg:squarederror', \n",
    "                           eval_metric = \"rmse\",\n",
    "                           tree_method='hist', \n",
    "                           # early_stopping_rounds= 4,\n",
    "                           booster = 'gbtree', \n",
    "                           # device = \"cuda\",\n",
    "                           # gpu_id = 0,\n",
    "                           # client = client, \n",
    "                           verbosity=2,\n",
    "                           # subsample = 1,\n",
    "                           # sampling_method=\"uniform\",\n",
    "                           # callbacks = [early_stop],\n",
    "                          )\n",
    "# xgb.XGBRFRegressor \n",
    "# xgb.XGBModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgb_reg.set_params(tree_method=\"hist\", device = \"cuda\")\n",
    "# xgb_reg.set_params(early_stopping_rounds= 3)\n",
    "# xgb_reg.set_params(gpu_id = 0)\n",
    "# xgb.client = client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:08:43.435878Z",
     "start_time": "2023-05-29T13:08:43.422634Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Default Parameters :\\n')\n",
    "pp.pprint(xgb_reg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_pcfp = model_selection(xgb_reg, \n",
    "                           # xgb_grid_parameters, train_X, train_y, \n",
    "                           # scoring =  'neg_mean_squared_error', cv=5, \n",
    "                           # GridSearch = True, \n",
    "                           # n_iter=30, \n",
    "                           # n_jobs=6, \n",
    "                           # verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reg.fit(train_X, train_y, verbose = 3, eval_set=[(train_X, train_y), (val_X, val_y)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T20:51:47.413295Z",
     "start_time": "2023-12-21T20:51:47.395575Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_train = GridSearchCV(xgb_reg, xgb_grid_parameters, \n",
    "#                                # cv=3, \n",
    "#                                n_jobs = 1,\n",
    "#                                scoring = None,\n",
    "#                                # refit = True,\n",
    "#                           )\n",
    "model_train = IncrementalSearchCV(xgb_reg, \n",
    "                                  xgb_grid_parameters, \n",
    "                                  n_initial_parameters=1,\n",
    "                                  # cv=3, \n",
    "                                  # n_jobs = 1,\n",
    "                                    patience = 5,\n",
    "                                    random_state = 1234, \n",
    "                               scoring = None,\n",
    "                               # refit = True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-21T20:51:49.289Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    # model_train.fit(train_X, train_y, eval_set=[(train_X, train_y),(val_X, val_y)],  verbose = 3 )\n",
    "    model_train.fit(train_X, train_y, eval_set=[(train_X, train_y),(val_X, val_y)], verbose = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb_reg.get_booster()\n",
    "history = xgb_reg.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history\n",
    "xgb_reg.best_iteration\n",
    "xgb_reg.base_score\n",
    "xgb_reg.best_ntree_limit\n",
    "# xgb_reg.best_score\n",
    "xgb_reg.callbacks\n",
    "xgb_reg.eval_metric\n",
    "type(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(xgb_reg.feature_importances_[xgb_reg.feature_importances_ < 1e-06])\n",
    "xgb_reg.feature_importances_ \n",
    "xgb_reg.feature_names_in_\n",
    "xgb_reg.n_features_in_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score = xgb_reg.score(train_X, train_y)\n",
    "\n",
    "val_score = xgb_reg.score(val_X, val_y)\n",
    "\n",
    "test_score = xgb_reg.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" R2 score - Training   : {train_score:0.6f}\")\n",
    "print(f\" R2 score - Validation : {val_score:0.6f}\")\n",
    "print(f\" R2 score - Test data  : {test_score:0.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.yticks(fontsize = 12)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlim(10,50)\n",
    "ax = xgb.plot_importance(xgb_reg, max_num_features= 30, ax = ax)\n",
    "# for label in ( ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "#     label.set_fontsize(22)\n",
    "ax.get_yticklabels()\n",
    "# ax.autoscale(enable=None, axis=\"y\", tight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:06:58.842127Z",
     "start_time": "2023-05-29T13:06:58.768177Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx = my_enumerator()\n",
    "# fn = model_selectiona\n",
    "# args = (1,xgb_reg, xgb_grid_parameters, train_X, train_y)\n",
    "\n",
    "# kwargs = dict({'scoring':'neg_mean_squared_error', 'cv':5, 'GridSearch':True, 'n_iter':30, 'n_jobs':6, 'verbose': 4}) \n",
    " \n",
    "# start_time = time.perf_counter()\n",
    "# print(f\" {datetime.now().strftime('%X.%f')} | Started \")   \n",
    "# pool = Pool(processes=2)\n",
    "\n",
    "# # result = pool.starmap_async(get_pharmacophores, enumerate(df_iterator)) \n",
    "# # results = starmap_with_kwargs_async(pool, fn, args, kwargs, processes = 1)\n",
    "# results = pool.apply_async(fn,args, kwargs)\n",
    "\n",
    "# print(f\" {datetime.now().strftime('%X.%f')} | starmap_with_kwargs_async() | close pool. . .  \") \n",
    "# pool.close()\n",
    "\n",
    "# print(f\" {datetime.now().strftime('%X.%f')} | starmap_with_kwargs_async() | Waiting for results. . .  \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T06:46:05.202291Z",
     "start_time": "2023-05-29T06:42:57.543329Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "## returns: a: labeled_feature, b: unlabeled_feature, c: labeled_Y, d: df_labeled.index, e: df_unlabled.index\n",
    "# a,b,c,d,e = prepare_input(train_labels, train_ecfp6_bits, target = 'logLD50_mmolkg', encoder = None)\n",
    "\n",
    "## Calls \n",
    "# xgb_pcfp = model_selection(xgb_reg, \n",
    "                           # xgb_grid_parameters, train_X, train_y, \n",
    "                           # scoring =  'neg_mean_squared_error', cv=5, \n",
    "                           # GridSearch = True, \n",
    "                           # n_iter=30, \n",
    "                           # n_jobs=6, \n",
    "                           # verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:14:06.717763Z",
     "start_time": "2023-05-29T13:14:06.714456Z"
    }
   },
   "outputs": [],
   "source": [
    "#  verbose is 3\n",
    "# Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
    "# Best parameters set found on development set: {'colsample_bytree': 0.5, 'gamma': 2.5, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 3, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# Best score: -0.06345690434364994\n",
    "# Grid scores on development set:\n",
    "\n",
    "# -0.06349 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 2.5, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 2, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06346 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 2.5, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 3, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06505 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 3, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 2, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06508 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 3, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 3, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06638 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 3.5, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 2, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06638 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 3.5, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 3, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06788 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 4, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 2, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# -0.06788 (+/-0.002) for {'colsample_bytree': 0.5, 'gamma': 4, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 3, 'n_estimators': 1500, 'subsample': 0.5}\n",
    "# CPU times: user 6.46 s, sys: 286 ms, total: 6.74 s\n",
    "# Wall time: 3min 7s\n",
    "    \n",
    "#     \tmodel\tparams\tmean score\tstd score\trank\n",
    "# 0\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 2.5, 'learn...\t-0.063492\t0.001178\t2\n",
    "# 1\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 2.5, 'learn...\t-0.063457\t0.001010\t1\n",
    "# 2\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 3, 'learnin...\t-0.065046\t0.000987\t3\n",
    "# 3\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 3, 'learnin...\t-0.065080\t0.000957\t4\n",
    "# 4\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 3.5, 'learn...\t-0.066377\t0.001204\t5\n",
    "# 5\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 3.5, 'learn...\t-0.066377\t0.001204\t5\n",
    "# 6\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 4, 'learnin...\t-0.067878\t0.001242\t7\n",
    "# 7\txgb_pcfp\t{'colsample_bytree': 0.5, 'gamma': 4, 'learnin...\t-0.067878\t0.001242\t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T06:46:59.045989Z",
     "start_time": "2023-05-29T06:46:58.921341Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_results = result_model_selection(results = xgb_pcfp, name='xgb_pcfp');\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:14:32.636531Z",
     "start_time": "2023-05-29T13:14:32.633881Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_results.sort_values('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T13:13:55.010803Z",
     "start_time": "2023-05-29T13:13:55.007705Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_results.loc[1].params - \n",
    "# {'colsample_bytree': 0.5,\n",
    "#  'gamma': 2.5,\n",
    "#  'learning_rate': 0.1,\n",
    "#  'max_depth': 15,\n",
    "#  'min_child_weight': 3,\n",
    "#  'n_estimators': 1500,\n",
    "#  'subsample': 0.5} \n",
    "\n",
    "\n",
    "# df_results.loc[2].params = \n",
    "# {'colsample_bytree': 0.5,\n",
    "#  'gamma': 2.5,\n",
    "#  'learning_rate': 0.1,\n",
    "#  'max_depth': 15,\n",
    "#  'min_child_weight': 3,\n",
    "#  'n_estimators': 1500,\n",
    "#  'subsample': 0.5}\n",
    "\n",
    "# df_results.loc[12].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T14:01:07.309204Z",
     "start_time": "2023-05-28T14:01:07.217230Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL_RESULTS = []\n",
    "ALL_RESULTS.append(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - Cancer Dataset (Classification example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:38:33.906700Z",
     "start_time": "2023-07-31T18:38:33.684133Z"
    },
    "execution": {
     "iopub.status.busy": "2024-01-10T14:17:55.221658Z",
     "iopub.status.idle": "2024-01-10T14:17:55.221938Z",
     "shell.execute_reply": "2024-01-10T14:17:55.221824Z",
     "shell.execute_reply.started": "2024-01-10T14:17:55.221811Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import optuna\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "SEED = 108\n",
    "N_FOLDS = 3\n",
    "CV_RESULT_DIR = \"./xgboost_cv_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-10T14:17:55.223110Z",
     "iopub.status.idle": "2024-01-10T14:17:55.223474Z",
     "shell.execute_reply": "2024-01-10T14:17:55.223344Z",
     "shell.execute_reply.started": "2024-01-10T14:17:55.223330Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optuna example that optimizes a classifier configuration for cancer dataset using XGBoost.\n",
    "\n",
    "In this example, we optimize the accuracy of cancer detection using the XGBoost. The accuracy is\n",
    "estimated by cross-validation. We optimize both the choice of booster model and its\n",
    "hyperparameters.\n",
    "\"\"\"\n",
    "def propose_parameters(trial):\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\"  :  \"reg:squarederror\",\n",
    "        \"eval_metric\":  \"rmse\",\n",
    "        \"booster\"    :  \"gbtree\",   ## trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    return param\n",
    "    \n",
    "def objective(trial):\n",
    "    # (data, target) = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    df_X = dd.read_csv(profilesFile, usecols=X_columns, dtype=x_columns_dtype)\n",
    "    df_y = dd.read_csv(profilesFile, usecols=y_columns, dtype=y_columns_dtype)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(df_X, label=df_y)\n",
    "\n",
    "    param = propose_parameters(trial)\n",
    "     \n",
    "    xgb_cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=10000,\n",
    "        nfold=N_FOLDS,\n",
    "        stratified=True,\n",
    "        early_stopping_rounds=100,\n",
    "        seed=SEED,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Set n_estimators as a trial attribute; Accessible via study.trials_dataframe().\n",
    "    trial.set_user_attr(\"n_estimators\", len(xgb_cv_results))\n",
    "\n",
    "    # Save cross-validation results.\n",
    "    filepath = os.path.join(CV_RESULT_DIR, \"{}.csv\".format(trial.number))\n",
    "    xgb_cv_results.to_csv(filepath, index=False)\n",
    "\n",
    "    # Extract the best score.\n",
    "    best_score = xgb_cv_results[\"test-auc-mean\"].values[-1]\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-10T14:17:55.224508Z",
     "iopub.status.idle": "2024-01-10T14:17:55.224831Z",
     "shell.execute_reply": "2024-01-10T14:17:55.224715Z",
     "shell.execute_reply.started": "2024-01-10T14:17:55.224701Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CV_RESULT_DIR):\n",
    "        os.mkdir(CV_RESULT_DIR)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    print(\"  Number of estimators: {}\".format(trial.user_attrs[\"n_estimators\"]))\n",
    "\n",
    "    shutil.rmtree(CV_RESULT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-10T14:17:55.225760Z",
     "iopub.status.idle": "2024-01-10T14:17:55.226062Z",
     "shell.execute_reply": "2024-01-10T14:17:55.225946Z",
     "shell.execute_reply.started": "2024-01-10T14:17:55.225932Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "study = optuna.delete_study(storage=\"sqlite:///example.db\",\n",
    "                            study_name=\"kevin-study-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cp]",
   "language": "python",
   "name": "conda-env-cp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.631px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
