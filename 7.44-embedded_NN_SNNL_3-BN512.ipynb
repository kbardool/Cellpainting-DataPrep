{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418c282c-2b25-4f32-96cf-883b40b84c36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "  # Apply encoder to morphological profiles to get latent space representations :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da93a6-653f-4a55-9b3a-e72ab79a1121",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a104a277-3ad3-438a-b706-d4499f709f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T10:29:16.111588Z",
     "start_time": "2023-04-12T10:29:15.764305Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:15.363078Z",
     "iopub.status.busy": "2024-10-03T17:55:15.362526Z",
     "iopub.status.idle": "2024-10-03T17:55:15.386743Z",
     "shell.execute_reply": "2024-10-03T17:55:15.385864Z",
     "shell.execute_reply.started": "2024-10-03T17:55:15.363035Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2\n",
    "from IPython.display import display, HTML, Image\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7478f60a-2ea2-4407-bd91-f068349f222b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T10:29:16.111588Z",
     "start_time": "2023-04-12T10:29:15.764305Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:15.388265Z",
     "iopub.status.busy": "2024-10-03T17:55:15.388027Z",
     "iopub.status.idle": "2024-10-03T17:55:18.008438Z",
     "shell.execute_reply": "2024-10-03T17:55:18.007636Z",
     "shell.execute_reply.started": "2024-10-03T17:55:15.388246Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert ./src\n",
      "insert ../pt-snnl\n",
      "insert ../..\n",
      "['../..', '../pt-snnl', './src', '/home/kevin/WSL-shared/cellpainting/cj-datasets', '/home/kevin/miniforge3/envs/cp311/lib/python311.zip', '/home/kevin/miniforge3/envs/cp311/lib/python3.11', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/lib-dynload', '', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages', '/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages/huggingface_hub-0.20.3-py3.8.egg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa37f2d7ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from types import SimpleNamespace\n",
    "import pprint\n",
    "import logging\n",
    "from datetime import datetime\n",
    "for p in ['./src','../pt-snnl','../..']:\n",
    "    if p not in sys.path:\n",
    "        print(f\"insert {p}\")\n",
    "        sys.path.insert(0, p)\n",
    "print(sys.path)\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as sps\n",
    "import sklearn.metrics as skm\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt  # for making figures\n",
    "from torchinfo import summary\n",
    "\n",
    "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=180, profile=None, sci_mode=None)\n",
    "torch.manual_seed(42);   # seed rng for reproducibility\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pd.options.display.width = 132\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"AE-MAIN-SNNL.ipynb\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "\n",
    "torch.set_num_threads(4)  ## <--- limit to ~ 2 CPUs\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b939a031-286c-430c-890d-946ea497d8e3",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:18.009931Z",
     "iopub.status.busy": "2024-10-03T17:55:18.009540Z",
     "iopub.status.idle": "2024-10-03T17:55:20.066583Z",
     "shell.execute_reply": "2024-10-03T17:55:20.065509Z",
     "shell.execute_reply.started": "2024-10-03T17:55:18.009908Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniforge3/envs/cp311/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from KevinsRoutines.utils.utils_general import list_namespace, save_to_pickle, load_from_pickle, get_device\n",
    "import KevinsRoutines.utils as myutils\n",
    "# import snnl.utils as utils\n",
    "# from utils.utils_ptsnnl import display_cellpainting_batch, get_device\n",
    "from utils.utils_cellpainting import label_counts, balance_datasets,save_checkpoint, load_checkpoint\n",
    "\n",
    "from utils.utils_notebooks import plot_cls_metrics, compute_classification_metrics, run_model_on_test_data,\\\n",
    "                                train, validation, accuracy_fn, fit, build_model, define_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48065ef-8765-4b2f-a448-3d0d0dbf3609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:20.068228Z",
     "iopub.status.busy": "2024-10-03T17:55:20.068028Z",
     "iopub.status.idle": "2024-10-03T17:55:20.913298Z",
     "shell.execute_reply": "2024-10-03T17:55:20.912215Z",
     "shell.execute_reply.started": "2024-10-03T17:55:20.068207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Id   Device Name                    Total Memory                     InUse                            Free Memory \n",
      "   0     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 325,058,560 B / (0.30 GB)  \t 33,744,814,080 B / (31.43 GB)   *** CURRENT DEVICE *** \n",
      "   1     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 325,058,560 B / (0.30 GB)  \t 33,744,814,080 B / (31.43 GB)  \n",
      "   2     NVIDIA TITAN Xp                12,774,539,264 B/ (11.90 GB)  \t 157,417,472 B / (0.15 GB)  \t 12,617,121,792 B / (11.75 GB)  \n",
      "\n",
      " Current CUDA Device is:  \"cuda:0\"  Device Name: Quadro GV100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myutils.get_device(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12352c5-443c-414b-bb2b-6ea5ba801515",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:20.914422Z",
     "iopub.status.busy": "2024-10-03T17:55:20.914227Z",
     "iopub.status.idle": "2024-10-03T17:55:20.959527Z",
     "shell.execute_reply": "2024-10-03T17:55:20.958435Z",
     "shell.execute_reply.started": "2024-10-03T17:55:20.914402Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 19:55:20,952 - __main__ - INFO: -  Excution started : 2024_10_03_19:55:20 \n",
      "2024-10-03 19:55:20,953 - __main__ - INFO: -  Pytorch version  : 2.2.0\n",
      "2024-10-03 19:55:20,954 - __main__ - INFO: -  Scipy version    : 1.11.4  \t\t Numpy version : 1.26.2\n",
      "2024-10-03 19:55:20,955 - __main__ - INFO: -  Pandas version   : 2.2.0  \n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y_%m_%d_%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logLevel = os.environ.get('LOG_LEVEL', 'INFO').upper()\n",
    "FORMAT = '%(asctime)s - %(name)s - %(levelname)s: - %(message)s'\n",
    "logging.basicConfig(level=\"INFO\", format= FORMAT)\n",
    "logger.info(f\" Excution started : {timestamp} \")\n",
    "logger.info(f\" Pytorch version  : {torch.__version__}\")\n",
    "logger.info(f\" Scipy version    : {scipy.__version__}  \\t\\t Numpy version : {np.__version__}\")\n",
    "logger.info(f\" Pandas version   : {pd.__version__}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08245ac5-58a6-4cba-b1e3-314685a0961a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:45:10.550334Z",
     "start_time": "2023-07-31T18:45:07.868769Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:20.960567Z",
     "iopub.status.busy": "2024-10-03T17:55:20.960378Z",
     "iopub.status.idle": "2024-10-03T17:55:21.027449Z",
     "shell.execute_reply": "2024-10-03T17:55:21.026608Z",
     "shell.execute_reply.started": "2024-10-03T17:55:20.960547Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afcf4f8-5cd4-4a9c-a178-4c1b39f0c954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:21.028362Z",
     "iopub.status.busy": "2024-10-03T17:55:21.028182Z",
     "iopub.status.idle": "2024-10-03T17:55:21.086798Z",
     "shell.execute_reply": "2024-10-03T17:55:21.085493Z",
     "shell.execute_reply.started": "2024-10-03T17:55:21.028344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Switched to: \"cuda:1\"   Device Name: Quadro GV100                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Id   Device Name                    Total Memory                     InUse                            Free Memory \n",
      "   0     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 325,058,560 B / (0.30 GB)  \t 33,744,814,080 B / (31.43 GB)  \n",
      "   1     Quadro GV100                   34,069,872,640 B/ (31.73 GB)  \t 325,058,560 B / (0.30 GB)  \t 33,744,814,080 B / (31.43 GB)   *** CURRENT DEVICE *** \n",
      "   2     NVIDIA TITAN Xp                12,774,539,264 B/ (11.90 GB)  \t 157,417,472 B / (0.15 GB)  \t 12,617,121,792 B / (11.75 GB)  \n",
      "\n",
      " Current CUDA Device is:  \"cuda:1\"  Device Name: Quadro GV100\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "myutils.set_device(1)\n",
    "device  = myutils.get_device(verbose = True)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac793b-be20-4c56-8bab-989c05caad80",
   "metadata": {},
   "source": [
    "# Args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25082b2-753b-4069-b183-00a90f611b68",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:26.810202Z",
     "iopub.status.busy": "2024-10-03T17:55:26.809653Z",
     "iopub.status.idle": "2024-10-03T17:55:26.851469Z",
     "shell.execute_reply": "2024-10-03T17:55:26.850731Z",
     "shell.execute_reply.started": "2024-10-03T17:55:26.810151Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM    = 150\n",
    "COMPOUNDS_PER_BATCH = 600\n",
    "\n",
    "MODEL_TYPE = 'batch_norm'\n",
    "# MODEL_TYPE = 'single_layer'\n",
    "# MODEL_TYPE = 'relu'\n",
    "n_input    = LATENT_DIM  # the embedding dimensionality \n",
    "n_hidden_1 = 512  # the number of neurons in the hidden layer of the MLP\n",
    "n_hidden_2 = 512  # the number of neurons in the hidden layer of the MLP\n",
    "n_hidden_3 = 128\n",
    "\n",
    "METADATA_COLS = ['Metadata_Source', 'Metadata_Batch', 'Metadata_Plate', 'Metadata_Well', 'Metadata_JCP2022', 'Metadata_Hash', 'Metadata_Bin', 'Metadata_TPSA', 'Metadata_lnTPSA', 'Metadata_log10TPSA', 'Metadata_Permiation']\n",
    "# METADATA_COLS += [f'Feature_{x:03d}' for x in range(LATENT_DIM)]\n",
    "input_cols = LATENT_DIM + len(METADATA_COLS)\n",
    "print(len(METADATA_COLS))\n",
    "print(input_cols)\n",
    "\n",
    "INPUT_PATH = f\"/home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/\"\n",
    "CKPT_PATH = \"./saved_models/embedding_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ba5b40-139d-4ad4-b6c4-51e4e19a0dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:27.582418Z",
     "iopub.status.busy": "2024-10-03T17:55:27.581993Z",
     "iopub.status.idle": "2024-10-03T17:55:27.612877Z",
     "shell.execute_reply": "2024-10-03T17:55:27.612202Z",
     "shell.execute_reply.started": "2024-10-03T17:55:27.582376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240909_2130\n"
     ]
    }
   ],
   "source": [
    "# RUN_DATETIME = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "# RUN_DATETIME = '20240909_1801'\n",
    "# RUN_DATETIME = '20240909_1800'\n",
    "# RUN_DATETIME = '20240909_2100'\n",
    "# RUN_DATETIME = '20240916_1830'\n",
    "# RUN_DATETIME = '20240921_0700'\n",
    "# RUN_DATETIME = '20240926_1900'\n",
    "# RUN_DATETIME = '20240927_2345'\n",
    "RUN_DATETIME = '20240909_2130'\n",
    "print(RUN_DATETIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60285362-f1d0-48f0-91d3-1787dce08036",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:30.236029Z",
     "iopub.status.busy": "2024-10-03T17:55:30.235534Z",
     "iopub.status.idle": "2024-10-03T17:55:30.270746Z",
     "shell.execute_reply": "2024-10-03T17:55:30.270046Z",
     "shell.execute_reply.started": "2024-10-03T17:55:30.235984Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SNNL AUTOENCODERS \n",
    "AE_RUNMODE = \"snnl\"\n",
    "# AE_DATETIME = \"20240718_1956\"\n",
    "AE_DATETIME = \"20240906_2201\"     # Autoencoder training - SNNL, CPB = 600, Latent 150, WD = 0.001, SNN Factor 3\n",
    "# AE_DATETIME = \"20240917_2004\"     # Autoencoder training - SNNL, CPB = 600, Latent 250, WD = 0.001, SNN Factor 3\n",
    "\n",
    "## BASELINE AUTOENCODERS \n",
    "# AE_RUNMODE = 'base'\n",
    "# AE_DATETIME = \"20240917_2017\"     # Autoencoder training - Baseline, CPB = 600, Latent 250, WD = 0.001 (SNN Factor 0)\n",
    "\n",
    "# AE_CKPTTYPE = \"BEST\"\n",
    "AE_CKPTTYPE = \"LAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593a54d5-8fa0-42d0-bbae-e0f29019cb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:32.576994Z",
     "iopub.status.busy": "2024-10-03T17:55:32.576502Z",
     "iopub.status.idle": "2024-10-03T17:55:32.615362Z",
     "shell.execute_reply": "2024-10-03T17:55:32.614790Z",
     "shell.execute_reply.started": "2024-10-03T17:55:32.576950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_{ep}\n"
     ]
    }
   ],
   "source": [
    "CKPT_FILE = f\"NN_{AE_RUNMODE.lower()}_embd600_{LATENT_DIM}Ltnt_512_{AE_DATETIME}_{AE_CKPTTYPE}_{RUN_DATETIME}_ep_{{ep}}\"\n",
    "print(CKPT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b67fd3-5cee-433b-b177-60d588e8b7e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:34.731264Z",
     "iopub.status.busy": "2024-10-03T17:55:34.730783Z",
     "iopub.status.idle": "2024-10-03T17:55:34.768605Z",
     "shell.execute_reply": "2024-10-03T17:55:34.767957Z",
     "shell.execute_reply.started": "2024-10-03T17:55:34.731221Z"
    }
   },
   "outputs": [],
   "source": [
    "## total rows = 346,542\n",
    "## Trn file sz: 312,000 \n",
    "## Train      : 277,200    (312_000 - (21,600 + 12,600 + 600) = 277,200\n",
    "## Validation :  21,600\n",
    "## Test       :  12,600\n",
    "## Leftover   :     600\n",
    "cellpainting_args = {'compounds_per_batch': COMPOUNDS_PER_BATCH,\n",
    "                     'train_start'        : 0,\n",
    "                     'train_end'          : 277_200,\n",
    "                     'val_start'          : 0,\n",
    "                     'val_end'            : 21_600,\n",
    "                     'test_start'         : 0,\n",
    "                     'test_end'           : 12_600, \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2a6e1c4-2637-42f1-b545-9b71ea07855d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:35.902958Z",
     "iopub.status.busy": "2024-10-03T17:55:35.902452Z",
     "iopub.status.idle": "2024-10-03T17:55:35.971964Z",
     "shell.execute_reply": "2024-10-03T17:55:35.971280Z",
     "shell.execute_reply.started": "2024-10-03T17:55:35.902914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 19:55:35,937 - utils.dataloader - INFO: -  Building CellPantingDataset for train\n",
      "2024-10-03 19:55:35,938 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train.csv\n",
      "2024-10-03 19:55:35,939 - utils.dataloader - INFO: -  type    :  train\n",
      "2024-10-03 19:55:35,939 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-03 19:55:35,940 - utils.dataloader - INFO: -  end     :  277200\n",
      "2024-10-03 19:55:35,940 - utils.dataloader - INFO: -  numrows :  277200\n",
      "2024-10-03 19:55:35,941 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-03 19:55:35,942 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-03 19:55:35,942 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-03 19:55:35,943 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-03 19:55:35,943 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-03 19:55:35,944 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-03 19:55:35,945 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-03 19:55:35,945 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 154\n",
      "2024-10-03 19:55:35,946 - utils.dataloader - INFO: -  Rows covered by 154 full size batches (1800 rows) per epoch:  277200\n",
      "2024-10-03 19:55:35,947 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-03 19:55:35,947 - utils.dataloader - INFO: -  \n",
      "2024-10-03 19:55:35,948 - utils.dataloader - INFO: -  Building CellPantingDataset for val\n",
      "2024-10-03 19:55:35,949 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train_sub_val.csv\n",
      "2024-10-03 19:55:35,949 - utils.dataloader - INFO: -  type    :  val\n",
      "2024-10-03 19:55:35,950 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-03 19:55:35,950 - utils.dataloader - INFO: -  end     :  21600\n",
      "2024-10-03 19:55:35,951 - utils.dataloader - INFO: -  numrows :  21600\n",
      "2024-10-03 19:55:35,951 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-03 19:55:35,952 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-03 19:55:35,952 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-03 19:55:35,953 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-03 19:55:35,953 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-03 19:55:35,953 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-03 19:55:35,954 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-03 19:55:35,954 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 12\n",
      "2024-10-03 19:55:35,955 - utils.dataloader - INFO: -  Rows covered by 12 full size batches (1800 rows) per epoch:  21600\n",
      "2024-10-03 19:55:35,955 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-03 19:55:35,956 - utils.dataloader - INFO: -  \n",
      "2024-10-03 19:55:35,956 - utils.dataloader - INFO: -  Building CellPantingDataset for test\n",
      "2024-10-03 19:55:35,957 - utils.dataloader - INFO: -  filename:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train_sub_test.csv\n",
      "2024-10-03 19:55:35,957 - utils.dataloader - INFO: -  type    :  test\n",
      "2024-10-03 19:55:35,958 - utils.dataloader - INFO: -  start   :  0\n",
      "2024-10-03 19:55:35,958 - utils.dataloader - INFO: -  end     :  12600\n",
      "2024-10-03 19:55:35,958 - utils.dataloader - INFO: -  numrows :  12600\n",
      "2024-10-03 19:55:35,959 - utils.dataloader - INFO: -  names   :  None     usecols :  None\n",
      "2024-10-03 19:55:35,963 - utils.dataloader - INFO: -  batch_size  :  1\n",
      "2024-10-03 19:55:35,964 - utils.dataloader - INFO: -  sample_size :  3\n",
      "2024-10-03 19:55:35,964 - utils.dataloader - INFO: -  compounds_per_batch :  600\n",
      "2024-10-03 19:55:35,964 - utils.dataloader - INFO: -  rows per batch (chunksize) :  1800\n",
      "2024-10-03 19:55:35,965 - utils.dataloader - INFO: -  TPSA threshold :  100\n",
      "2024-10-03 19:55:35,965 - utils.dataloader - INFO: -  Each mini-batch contains 600.0 compounds with 3 samples per compound : total 1800 rows\n",
      "2024-10-03 19:55:35,966 - utils.dataloader - INFO: -  Number of 1800 row full size batches per epoch: 7\n",
      "2024-10-03 19:55:35,966 - utils.dataloader - INFO: -  Rows covered by 7 full size batches (1800 rows) per epoch:  12600\n",
      "2024-10-03 19:55:35,967 - utils.dataloader - INFO: -  Last partial batch contains : 0 rows\n",
      "2024-10-03 19:55:35,967 - utils.dataloader - INFO: -  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAIN_INPUT:  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train.csv\n",
      " TEST_INPUT :  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train_sub_test.csv\n",
      " ALL_INPUT  :  /home/kevin/WSL-shared/cellpainting/cj-datasets/output_11102023/3_sample_embeddings/3smpl_prfl_embedding_161_HashOrder_snnl_20240906_2201_LAST_train_sub_val.csv\n",
      " load {}\n",
      " Dataset size: 277200   rows per batch: 1800  tpsa_threshold: 100\n",
      " Dataset size: 21600   rows per batch: 1800  tpsa_threshold: 100\n",
      " Dataset size: 12600   rows per batch: 1800  tpsa_threshold: 100\n"
     ]
    }
   ],
   "source": [
    "data_loader = define_datasets(cellpainting_args, AE_RUNMODE, AE_DATETIME, input_cols, AE_CKPTTYPE, INPUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af485a0-e4bd-4e05-8764-39a5d9f908c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417e03f3-163a-42d4-8055-7e39f9c3f8af",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-09-30T17:42:08.234824Z",
     "iopub.status.busy": "2024-09-30T17:42:08.234546Z",
     "iopub.status.idle": "2024-09-30T17:42:08.260053Z",
     "shell.execute_reply": "2024-09-30T17:42:08.259550Z",
     "shell.execute_reply.started": "2024-09-30T17:42:08.234805Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN_INPUT_FILE = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train.csv\"\n",
    "# TEST_INPUT_FILE  = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train_sub_test.csv\"\n",
    "# VAL_INPUT_FILE   = f\"3smpl_prfl_embedding_{input_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_train_sub_val.csv\"\n",
    "# # ALL_INPUT_FILE   = f\"3smpl_prfl_embedding_{num_cols}_HashOrder_{AE_RUNMODE}_{AE_DATETIME}_{AE_CKPTTYPE}_sub_val.csv\"\n",
    "\n",
    "# TRAIN_INPUT = os.path.join(INPUT_PATH, TRAIN_INPUT_FILE)\n",
    "# TEST_INPUT  = os.path.join(INPUT_PATH, TEST_INPUT_FILE)\n",
    "# VAL_INPUT   = os.path.join(INPUT_PATH, VAL_INPUT_FILE)\n",
    "\n",
    "# print(f\" TRAIN_INPUT:  {TRAIN_INPUT}\")\n",
    "# print(f\" TEST_INPUT :  {TEST_INPUT }\")\n",
    "# print(f\" ALL_INPUT  :  {VAL_INPUT }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f7cf1f-5231-41b9-a050-690a4a482fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:42:08.261028Z",
     "iopub.status.busy": "2024-09-30T17:42:08.260745Z",
     "iopub.status.idle": "2024-09-30T17:42:08.290834Z",
     "shell.execute_reply": "2024-09-30T17:42:08.290304Z",
     "shell.execute_reply.started": "2024-09-30T17:42:08.261010Z"
    }
   },
   "outputs": [],
   "source": [
    "## total rows = 346,542\n",
    "## Trn file sz: 312,000 \n",
    "## Train      : 277,200    (312_000 - (21,600 + 12,600 + 600) = 277,200\n",
    "## Validation :  21,600\n",
    "## Test       :  12,600\n",
    "## Leftover   :     600\n",
    "# cellpainting_args = {'sample_size': 3,\n",
    "#                      'batch_size': 1,\n",
    "#                      'compounds_per_batch': 600,\n",
    "#                      'training_path'  : TRAIN_INPUT,\n",
    "#                      'validation_path': TRAIN_INPUT,\n",
    "#                      'test_path'      : TRAIN_INPUT,\n",
    "#                      'train_start'    : 0,\n",
    "#                      'train_end'      : 277_200,  # 277,200 samples\n",
    "#                      'val_start'      : 277_200,  # \n",
    "#                      'val_end'        : 298_800,  # 21_600 samples\n",
    "#                      'test_start'     : 298_800,  # \n",
    "#                      'test_end'       : 311_400,  # 12_600 samples\n",
    "#                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac80b685-550e-43a7-b48d-af4518aa718a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:42:08.292976Z",
     "iopub.status.busy": "2024-09-30T17:42:08.292720Z",
     "iopub.status.idle": "2024-09-30T17:42:08.317292Z",
     "shell.execute_reply": "2024-09-30T17:42:08.316705Z",
     "shell.execute_reply.started": "2024-09-30T17:42:08.292957Z"
    }
   },
   "outputs": [],
   "source": [
    "# cellpainting_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dda57be-1cd6-4598-b05e-a1c8b68176df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:38:37.838420Z",
     "iopub.status.busy": "2024-09-30T17:38:37.838031Z",
     "iopub.status.idle": "2024-09-30T17:38:37.868696Z",
     "shell.execute_reply": "2024-09-30T17:38:37.868128Z",
     "shell.execute_reply.started": "2024-09-30T17:38:37.838384Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Load CellPainting Dataset\n",
    "# data : keys to the dataset settings (and resulting keys in output dictionary)\n",
    "# dataset = dict()\n",
    "# data_loader = dict()\n",
    "\n",
    "# print(f\" load {dataset}\")\n",
    "# for datatype in ['train', 'val', 'test']:\n",
    "#     dataset[datatype] = CellpaintingDataset(type = datatype, **cellpainting_args)\n",
    "#     data_loader[datatype] = InfiniteDataLoader(dataset = dataset[datatype], batch_size=1, shuffle = False, num_workers = 0, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5465d0ad-2f89-45a5-9e48-a55da7c4fa47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:38:38.018048Z",
     "iopub.status.busy": "2024-09-30T17:38:38.017860Z",
     "iopub.status.idle": "2024-09-30T17:38:38.043213Z",
     "shell.execute_reply": "2024-09-30T17:38:38.042621Z",
     "shell.execute_reply.started": "2024-09-30T17:38:38.018030Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# for dataset in ['train', 'val', 'test']:\n",
    "#     for idx, batch in enumerate(data_loader[dataset]):\n",
    "#         print(batch[0].shape[0], batch[1].sum())\n",
    "#         # display_cellpainting_batch(idx, batch)\n",
    "#         if idx == 1:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1247a1cd-eda6-4231-9603-feab85fea20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:38:38.199996Z",
     "iopub.status.busy": "2024-09-30T17:38:38.199809Z",
     "iopub.status.idle": "2024-09-30T17:38:38.225270Z",
     "shell.execute_reply": "2024-09-30T17:38:38.224738Z",
     "shell.execute_reply.started": "2024-09-30T17:38:38.199978Z"
    }
   },
   "outputs": [],
   "source": [
    "# # -----------------------------------------\n",
    "# #  Count pos/neg labels in each dataset\n",
    "# # -----------------------------------------\n",
    "# for datatype in ['train', 'val', 'test']:\n",
    "#     MINIBATCH_SIZE = data_loader[datatype].dataset.sample_size * data_loader[datatype].dataset.compounds_per_batch\n",
    "#     print(f\" {datatype.capitalize()} Minibatch size : {MINIBATCH_SIZE} \\n\") \n",
    "# # for datatype in ['val', 'test']:\n",
    "#     minibatches = len(data_loader[datatype]) // MINIBATCH_SIZE\n",
    "#     ttl_rows = 0\n",
    "#     ttl_pos_labels = 0\n",
    "#     with tqdm.tqdm(enumerate(data_loader[datatype]), initial=0, total = minibatches, position=0, file=sys.stdout,\n",
    "#                    leave= False, desc=f\" Count labels \") as t_warmup:\n",
    "#         for batch_count, (batch_features, batch_labels, _, _, _, _) in t_warmup:\n",
    "#             ttl_rows += batch_labels.shape[0]\n",
    "#             ttl_pos_labels += batch_labels.sum()\n",
    "#     ttl_neg_labels = ttl_rows - ttl_pos_labels\n",
    "#     ttl = f\"\\n Dataset: {datatype} -  len of {datatype} data loader: {len(data_loader[datatype])}   number of batches: {minibatches}\"\n",
    "#     print(ttl)\n",
    "#     print('-'*len(ttl))\n",
    "#     print(f\" total rows     : {ttl_rows:7d}\")\n",
    "#     print(f\" total pos rows : {ttl_pos_labels:7.0f} - {ttl_pos_labels*100.0/ttl_rows:5.2f}%\")\n",
    "#     print(f\" total neg rows : {ttl_neg_labels:7.0f} - {ttl_neg_labels*100.0/ttl_rows:5.2f}%\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424ff70-bcba-4702-bbb1-9d1871a5489d",
   "metadata": {},
   "source": [
    "     Minibatch size : 1800 \n",
    "                                                                                                 \n",
    "     Dataset: train - len of train data loader: 277200   number of batches: 154  \n",
    "    ------------------------------\n",
    "     total rows     :  277200\n",
    "     total pos rows :   33129 - 11.95%\n",
    "     total neg rows :  244071 - 88.05%\n",
    "\n",
    "     Dataset: val - len of val data loader: 21600   number of batches: 12\n",
    "    ------------------------------\n",
    "     total rows     :   21600\n",
    "     total pos rows :    2532 - 11.72%\n",
    "     total neg rows :   19068 - 88.28%\n",
    "    \n",
    "     Dataset: test - len of test data loader: 12600   number of batches: 7\n",
    "    ------------------------------\n",
    "     total rows     :   12600\n",
    "     total pos rows :    1431 - 11.36%\n",
    "     total neg rows :   11169 - 88.64%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a34d7988-3fab-4356-bad5-1511fe8bad40",
   "metadata": {},
   "source": [
    "# Define Neural Net Model \n",
    "\n",
    "- **4 layer model :**\n",
    "\n",
    "    Input --> Hidden1 --> (BN/NL) ---> Hidden2 ---> (BN/NL) ---> Hidden3 --->  (BN/NL) ---> 1\n",
    "   \n",
    "    -  **20240909_1800** : Run on 4 FC layers model, model configuration UNKNOWN\n",
    "    -  **20240909_1801** : Run on 4 FC layers model, Relu non linearities (NO Batch Norm)\n",
    "    -  **20240909_2100** : Run on 4 FC layers model, with BATCH NORM / Tanh 256,256,128\n",
    "\n",
    "    -  **20240930_1930** : Run on 4 FC layers model, with BATCH NORM/ Tanh 512,512,128\n",
    "      \n",
    " - **Single Hidden Layer - 256**\n",
    "\n",
    "   Input --> Hidden1 --> (Tanh) --->  1\n",
    "    -  **20240916_1830** : Run on 1 FC layers model, Input --> 256 --> Tanh --> 1 ,  Read from 20240906_2201 (SNNL - CPB 600, LAT 150, SNN Factor 3)\n",
    "    -  **20240926_1900** : Run on 1 FC layers model, Input --> 256 --> Tanh --> 1 ,  Read from 20240917_2017 (BASELINE - CPB 600, LAT 250, SNN Factor 0)\n",
    "    -  **20240926_1930** : Run on 1 FC layers model, Input --> 256 --> Tanh --> 1 ,  Read from 20240917_2004 (SNNL - CPB 600, LAT 250, SNN Factor 3)\n",
    "    -  **20240926_2000** : Run on 1 FC layers model, Input --> 256 --> Tanh --> 1 ,  Read from 20240924_0146 (SNNL - CPB 600, LAT 250, SNN Factor 30)\n",
    "<br>\n",
    "\n",
    " - **Single Hidden Layer - 256**\n",
    "\n",
    "    -  **20240921_0700** : Run on 1 FC layers model (includes final layer), Input --> 512 --> Tanh --> 1 ,  Read from 20240906_2201 (SNNL - CPB 600, LAT 150, SNN Factor 3)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32c6590-d212-4f37-8ce1-4ee46fd4246a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:45:44.380055Z",
     "start_time": "2023-07-31T18:45:41.073911Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:40.171177Z",
     "iopub.status.busy": "2024-10-03T17:55:40.170691Z",
     "iopub.status.idle": "2024-10-03T17:55:40.270063Z",
     "shell.execute_reply": "2024-10-03T17:55:40.269138Z",
     "shell.execute_reply.started": "2024-10-03T17:55:40.171135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %                   Mult-Adds                 Trainable\n",
      "==============================================================================================================================================================================================\n",
      "Sequential                               [30, 150]                 [30, 1]                   --                             --                   --                        True\n",
      "├─Linear: 1-1                            [30, 150]                 [30, 512]                 77,312                     18.95%                   2,319,360                 True\n",
      "│    └─weight                                                                                ├─76,800\n",
      "│    └─bias                                                                                  └─512\n",
      "├─BatchNorm1d: 1-2                       [30, 512]                 [30, 512]                 1,024                       0.25%                   30,720                    True\n",
      "│    └─weight                                                                                ├─512\n",
      "│    └─bias                                                                                  └─512\n",
      "├─Tanh: 1-3                              [30, 512]                 [30, 512]                 --                             --                   --                        --\n",
      "├─Linear: 1-4                            [30, 512]                 [30, 512]                 262,656                    64.37%                   7,879,680                 True\n",
      "│    └─weight                                                                                ├─262,144\n",
      "│    └─bias                                                                                  └─512\n",
      "├─BatchNorm1d: 1-5                       [30, 512]                 [30, 512]                 1,024                       0.25%                   30,720                    True\n",
      "│    └─weight                                                                                ├─512\n",
      "│    └─bias                                                                                  └─512\n",
      "├─Tanh: 1-6                              [30, 512]                 [30, 512]                 --                             --                   --                        --\n",
      "├─Linear: 1-7                            [30, 512]                 [30, 128]                 65,664                     16.09%                   1,969,920                 True\n",
      "│    └─weight                                                                                ├─65,536\n",
      "│    └─bias                                                                                  └─128\n",
      "├─BatchNorm1d: 1-8                       [30, 128]                 [30, 128]                 256                         0.06%                   7,680                     True\n",
      "│    └─weight                                                                                ├─128\n",
      "│    └─bias                                                                                  └─128\n",
      "├─Tanh: 1-9                              [30, 128]                 [30, 128]                 --                             --                   --                        --\n",
      "├─Linear: 1-10                           [30, 128]                 [30, 1]                   129                         0.03%                   3,870                     True\n",
      "│    └─weight                                                                                ├─128\n",
      "│    └─bias                                                                                  └─1\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 408,065\n",
      "Trainable params: 408,065\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 12.24\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.55\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 2.20\n",
      "==============================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = build_model(MODEL_TYPE, input = n_input, hidden_1 = n_hidden_1, hidden_2 = n_hidden_2, hidden_3=n_hidden_3, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516fbc97-8c0d-4ba9-820d-c37c4eaebf27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:47:48.292853Z",
     "start_time": "2023-07-31T18:47:45.651556Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:42.257108Z",
     "iopub.status.busy": "2024-10-03T17:55:42.256618Z",
     "iopub.status.idle": "2024-10-03T17:55:42.300177Z",
     "shell.execute_reply": "2024-10-03T17:55:42.299482Z",
     "shell.execute_reply.started": "2024-10-03T17:55:42.257065Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parm shape: torch.Size([512, 150])                 # elements:    76800    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([512, 512])                 # elements:   262144    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([512])                      # elements:      512    Required gradient calc: True\n",
      "Parm shape: torch.Size([128, 512])                 # elements:    65536    Required gradient calc: True\n",
      "Parm shape: torch.Size([128])                      # elements:      128    Required gradient calc: True\n",
      "Parm shape: torch.Size([128])                      # elements:      128    Required gradient calc: True\n",
      "Parm shape: torch.Size([128])                      # elements:      128    Required gradient calc: True\n",
      "Parm shape: torch.Size([1, 128])                   # elements:      128    Required gradient calc: True\n",
      "Parm shape: torch.Size([1])                        # elements:        1    Required gradient calc: True\n",
      "Total num of parameters: 408065\n",
      "==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %                   Mult-Adds                 Trainable\n",
      "==============================================================================================================================================================================================\n",
      "Sequential                               [30, 150]                 [30, 1]                   --                             --                   --                        True\n",
      "├─Linear: 1-1                            [30, 150]                 [30, 512]                 77,312                     18.95%                   2,319,360                 True\n",
      "│    └─weight                                                                                ├─76,800\n",
      "│    └─bias                                                                                  └─512\n",
      "├─BatchNorm1d: 1-2                       [30, 512]                 [30, 512]                 1,024                       0.25%                   30,720                    True\n",
      "│    └─weight                                                                                ├─512\n",
      "│    └─bias                                                                                  └─512\n",
      "├─Tanh: 1-3                              [30, 512]                 [30, 512]                 --                             --                   --                        --\n",
      "├─Linear: 1-4                            [30, 512]                 [30, 512]                 262,656                    64.37%                   7,879,680                 True\n",
      "│    └─weight                                                                                ├─262,144\n",
      "│    └─bias                                                                                  └─512\n",
      "├─BatchNorm1d: 1-5                       [30, 512]                 [30, 512]                 1,024                       0.25%                   30,720                    True\n",
      "│    └─weight                                                                                ├─512\n",
      "│    └─bias                                                                                  └─512\n",
      "├─Tanh: 1-6                              [30, 512]                 [30, 512]                 --                             --                   --                        --\n",
      "├─Linear: 1-7                            [30, 512]                 [30, 128]                 65,664                     16.09%                   1,969,920                 True\n",
      "│    └─weight                                                                                ├─65,536\n",
      "│    └─bias                                                                                  └─128\n",
      "├─BatchNorm1d: 1-8                       [30, 128]                 [30, 128]                 256                         0.06%                   7,680                     True\n",
      "│    └─weight                                                                                ├─128\n",
      "│    └─bias                                                                                  └─128\n",
      "├─Tanh: 1-9                              [30, 128]                 [30, 128]                 --                             --                   --                        --\n",
      "├─Linear: 1-10                           [30, 128]                 [30, 1]                   129                         0.03%                   3,870                     True\n",
      "│    └─weight                                                                                ├─128\n",
      "│    └─bias                                                                                  └─1\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 408,065\n",
      "Trainable params: 408,065\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 12.24\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.55\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 2.20\n",
      "==============================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "parameters = model.parameters()\n",
    "ttl_nelements = 0\n",
    "for p in parameters:\n",
    "    print(f\"Parm shape: {str(p.shape):35s}    # elements: {p.nelement():8d}    Required gradient calc: {p.requires_grad}\")\n",
    "    ttl_nelements += p.nelement()\n",
    "print(f\"Total num of parameters: {ttl_nelements}\")  # number of parameters in total\n",
    "\n",
    "col_names = [\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"mult_adds\", \"trainable\"]\n",
    "\n",
    "summary_input_size = (30, n_input)\n",
    "_ = summary(model, verbose = 2, input_size=summary_input_size, col_names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc6a92e-2ca2-4ed8-b9f9-38d720f13973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:48:09.459977Z",
     "start_time": "2023-07-31T18:48:09.429767Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:43.977349Z",
     "iopub.status.busy": "2024-10-03T17:55:43.976854Z",
     "iopub.status.idle": "2024-10-03T17:55:44.016007Z",
     "shell.execute_reply": "2024-10-03T17:55:44.015443Z",
     "shell.execute_reply.started": "2024-10-03T17:55:43.977307Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = { 'loss_trn' : [], 'acc_trn' : [], 'loss_val' : [], 'acc_val' : []}\n",
    "\n",
    "start_epoch, end_epoch = 0,0\n",
    "init_LR = 1.0e-3\n",
    "# curr_LR = init_LR\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_LR)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.3 , patience=20, cooldown=10,)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma=0.1, last_epoch =-1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.5, threshold=1.0e-06, patience=50, cooldown=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb012c-1066-4a40-ba6d-8bd792e06ffb",
   "metadata": {},
   "source": [
    "### Read checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d8cc5c1-a8b4-4488-ba18-c7b6180722ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:44.655071Z",
     "iopub.status.busy": "2024-10-03T17:55:44.654661Z",
     "iopub.status.idle": "2024-10-03T17:55:44.686029Z",
     "shell.execute_reply": "2024-10-03T17:55:44.685379Z",
     "shell.execute_reply.started": "2024-10-03T17:55:44.655033Z"
    }
   },
   "outputs": [],
   "source": [
    "# loaded_epoch\n",
    "# optimizer.state_dict()\n",
    "# scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d093781-edac-4acb-a6ed-8c9f322228e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:45.320568Z",
     "iopub.status.busy": "2024-10-03T17:55:45.320157Z",
     "iopub.status.idle": "2024-10-03T17:55:45.352720Z",
     "shell.execute_reply": "2024-10-03T17:55:45.352086Z",
     "shell.execute_reply.started": "2024-10-03T17:55:45.320531Z"
    }
   },
   "outputs": [],
   "source": [
    "# model, optimizer, scheudler, end_epoch = load_checkpoint(model, optimizer, scheduler, checkpoint_file.format(ep=100), ckpt_path = CKPT_PATH)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9599cdd1-7434-4360-aa21-d8130696ffc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:45.619973Z",
     "iopub.status.busy": "2024-10-03T17:55:45.619697Z",
     "iopub.status.idle": "2024-10-03T17:55:45.648235Z",
     "shell.execute_reply": "2024-10-03T17:55:45.647527Z",
     "shell.execute_reply.started": "2024-10-03T17:55:45.619954Z"
    }
   },
   "outputs": [],
   "source": [
    "# end_epoch\n",
    "# optimizer.state_dict()\n",
    "# scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53a7c8-de53-45ec-ac18-2519c89e3ce5",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ec54be-10d4-4b6e-85c9-8175fab24f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T18:48:09.459977Z",
     "start_time": "2023-07-31T18:48:09.429767Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:47.216821Z",
     "iopub.status.busy": "2024-10-03T17:55:47.216339Z",
     "iopub.status.idle": "2024-10-03T17:55:47.255396Z",
     "shell.execute_reply": "2024-10-03T17:55:47.254767Z",
     "shell.execute_reply.started": "2024-10-03T17:55:47.216779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 600\n"
     ]
    }
   ],
   "source": [
    "# start_epoch = 0\n",
    "# start_epoch = loaded_epoch\n",
    "start_epoch = end_epoch\n",
    "end_epoch += 600\n",
    "# start_epoch, end_epoch = 0,100\n",
    "print(start_epoch, end_epoch)\n",
    "_ = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b26ae239-ec9d-4afc-aef9-387fa19d0ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T19:00:14.450630Z",
     "start_time": "2023-07-31T18:49:12.235999Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T17:55:48.123685Z",
     "iopub.status.busy": "2024-10-03T17:55:48.123199Z",
     "iopub.status.idle": "2024-10-03T20:05:49.392012Z",
     "shell.execute_reply": "2024-10-03T20:05:49.391233Z",
     "shell.execute_reply.started": "2024-10-03T17:55:48.123643Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19:56:03 | Ep:   1/ 600 | Trn loss:  0.405897 - Acc: 86.2926 | Val loss:  0.354494 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:56:16 | Ep:   2/ 600 | Trn loss:  0.358459 - Acc: 88.0364 | Val loss:  0.351901 - Acc: 88.2778 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:56:29 | Ep:   3/ 600 | Trn loss:  0.356163 - Acc: 88.0437 | Val loss:  0.351947 - Acc: 88.2778 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 19:56:42 | Ep:   4/ 600 | Trn loss:  0.355132 - Acc: 88.0501 | Val loss:  0.352421 - Acc: 88.2870 | last_lr: 1.00000e-03  bad_ep: 2  cdwn: 0                              \n",
      " 19:56:55 | Ep:   5/ 600 | Trn loss:  0.354414 - Acc: 88.0534 | Val loss:  0.352092 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 3  cdwn: 0                              \n",
      " 19:57:08 | Ep:   6/ 600 | Trn loss:  0.353851 - Acc: 88.0548 | Val loss:  0.351427 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:57:21 | Ep:   7/ 600 | Trn loss:  0.353436 - Acc: 88.0620 | Val loss:  0.350960 - Acc: 88.2731 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:57:33 | Ep:   8/ 600 | Trn loss:  0.353117 - Acc: 88.0617 | Val loss:  0.350670 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:57:46 | Ep:   9/ 600 | Trn loss:  0.352843 - Acc: 88.0617 | Val loss:  0.350396 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:57:59 | Ep:  10/ 600 | Trn loss:  0.352616 - Acc: 88.0628 | Val loss:  0.350244 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:58:12 | Ep:  11/ 600 | Trn loss:  0.352420 - Acc: 88.0631 | Val loss:  0.350060 - Acc: 88.2685 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:58:25 | Ep:  12/ 600 | Trn loss:  0.352246 - Acc: 88.0646 | Val loss:  0.349878 - Acc: 88.2731 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:58:38 | Ep:  13/ 600 | Trn loss:  0.352093 - Acc: 88.0653 | Val loss:  0.349705 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:58:51 | Ep:  14/ 600 | Trn loss:  0.351959 - Acc: 88.0675 | Val loss:  0.349560 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:59:03 | Ep:  15/ 600 | Trn loss:  0.351828 - Acc: 88.0660 | Val loss:  0.349414 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:59:16 | Ep:  16/ 600 | Trn loss:  0.351722 - Acc: 88.0664 | Val loss:  0.349305 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:59:29 | Ep:  17/ 600 | Trn loss:  0.351593 - Acc: 88.0657 | Val loss:  0.349210 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:59:41 | Ep:  18/ 600 | Trn loss:  0.351487 - Acc: 88.0682 | Val loss:  0.349135 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 19:59:54 | Ep:  19/ 600 | Trn loss:  0.351379 - Acc: 88.0696 | Val loss:  0.349056 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:00:07 | Ep:  20/ 600 | Trn loss:  0.351271 - Acc: 88.0700 | Val loss:  0.349012 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:00:19 | Ep:  21/ 600 | Trn loss:  0.351175 - Acc: 88.0689 | Val loss:  0.348951 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:00:32 | Ep:  22/ 600 | Trn loss:  0.351085 - Acc: 88.0700 | Val loss:  0.348844 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:00:45 | Ep:  23/ 600 | Trn loss:  0.350995 - Acc: 88.0722 | Val loss:  0.348720 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:00:58 | Ep:  24/ 600 | Trn loss:  0.350890 - Acc: 88.0732 | Val loss:  0.348718 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:01:11 | Ep:  25/ 600 | Trn loss:  0.350798 - Acc: 88.0714 | Val loss:  0.348615 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:01:23 | Ep:  26/ 600 | Trn loss:  0.350714 - Acc: 88.0754 | Val loss:  0.348611 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:01:36 | Ep:  27/ 600 | Trn loss:  0.350622 - Acc: 88.0747 | Val loss:  0.348511 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:01:49 | Ep:  28/ 600 | Trn loss:  0.350530 - Acc: 88.0732 | Val loss:  0.348484 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:02:02 | Ep:  29/ 600 | Trn loss:  0.350440 - Acc: 88.0736 | Val loss:  0.348428 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:02:14 | Ep:  30/ 600 | Trn loss:  0.350345 - Acc: 88.0736 | Val loss:  0.348380 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:02:27 | Ep:  31/ 600 | Trn loss:  0.350239 - Acc: 88.0758 | Val loss:  0.348297 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:02:40 | Ep:  32/ 600 | Trn loss:  0.350146 - Acc: 88.0776 | Val loss:  0.348240 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:02:53 | Ep:  33/ 600 | Trn loss:  0.350044 - Acc: 88.0804 | Val loss:  0.348171 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:03:06 | Ep:  34/ 600 | Trn loss:  0.349943 - Acc: 88.0851 | Val loss:  0.348129 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:03:18 | Ep:  35/ 600 | Trn loss:  0.349844 - Acc: 88.0884 | Val loss:  0.348145 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 20:03:31 | Ep:  36/ 600 | Trn loss:  0.349742 - Acc: 88.0924 | Val loss:  0.348076 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:03:44 | Ep:  37/ 600 | Trn loss:  0.349629 - Acc: 88.0978 | Val loss:  0.348099 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 20:03:57 | Ep:  38/ 600 | Trn loss:  0.349519 - Acc: 88.0985 | Val loss:  0.348062 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:04:09 | Ep:  39/ 600 | Trn loss:  0.349425 - Acc: 88.0981 | Val loss:  0.348120 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 20:04:22 | Ep:  40/ 600 | Trn loss:  0.349324 - Acc: 88.0974 | Val loss:  0.348053 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 0  cdwn: 0                              \n",
      " 20:04:35 | Ep:  41/ 600 | Trn loss:  0.349213 - Acc: 88.1028 | Val loss:  0.348114 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 1  cdwn: 0                              \n",
      " 20:04:48 | Ep:  42/ 600 | Trn loss:  0.349105 - Acc: 88.1043 | Val loss:  0.348107 - Acc: 88.2593 | last_lr: 1.00000e-03  bad_ep: 2  cdwn: 0                              \n",
      " 20:05:01 | Ep:  43/ 600 | Trn loss:  0.348987 - Acc: 88.1068 | Val loss:  0.348062 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 3  cdwn: 0                              \n",
      " 20:05:13 | Ep:  44/ 600 | Trn loss:  0.348885 - Acc: 88.1093 | Val loss:  0.348178 - Acc: 88.2546 | last_lr: 1.00000e-03  bad_ep: 4  cdwn: 0                              \n",
      " 20:05:26 | Ep:  45/ 600 | Trn loss:  0.348768 - Acc: 88.1100 | Val loss:  0.348183 - Acc: 88.2407 | last_lr: 1.00000e-03  bad_ep: 5  cdwn: 0                              \n",
      " 20:05:39 | Ep:  46/ 600 | Trn loss:  0.348654 - Acc: 88.1147 | Val loss:  0.348255 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 6  cdwn: 0                              \n",
      " 20:05:51 | Ep:  47/ 600 | Trn loss:  0.348498 - Acc: 88.1165 | Val loss:  0.348189 - Acc: 88.2407 | last_lr: 1.00000e-03  bad_ep: 7  cdwn: 0                              \n",
      " 20:06:04 | Ep:  48/ 600 | Trn loss:  0.348398 - Acc: 88.1162 | Val loss:  0.348341 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 8  cdwn: 0                              \n",
      " 20:06:17 | Ep:  49/ 600 | Trn loss:  0.348240 - Acc: 88.1227 | Val loss:  0.348397 - Acc: 88.2361 | last_lr: 1.00000e-03  bad_ep: 9  cdwn: 0                              \n",
      " 20:06:30 | Ep:  50/ 600 | Trn loss:  0.348106 - Acc: 88.1227 | Val loss:  0.348437 - Acc: 88.2222 | last_lr: 1.00000e-03  bad_ep: 10  cdwn: 0                             \n",
      " 20:06:43 | Ep:  51/ 600 | Trn loss:  0.347985 - Acc: 88.1266 | Val loss:  0.348571 - Acc: 88.2269 | last_lr: 1.00000e-03  bad_ep: 11  cdwn: 0                             \n",
      " 20:06:56 | Ep:  52/ 600 | Trn loss:  0.347851 - Acc: 88.1288 | Val loss:  0.348647 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 12  cdwn: 0                             \n",
      " 20:07:08 | Ep:  53/ 600 | Trn loss:  0.347727 - Acc: 88.1331 | Val loss:  0.348710 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 13  cdwn: 0                             \n",
      " 20:07:21 | Ep:  54/ 600 | Trn loss:  0.347584 - Acc: 88.1306 | Val loss:  0.348808 - Acc: 88.2315 | last_lr: 1.00000e-03  bad_ep: 14  cdwn: 0                             \n",
      " 20:07:34 | Ep:  55/ 600 | Trn loss:  0.347433 - Acc: 88.1378 | Val loss:  0.348880 - Acc: 88.2407 | last_lr: 1.00000e-03  bad_ep: 15  cdwn: 0                             \n",
      " 20:07:47 | Ep:  56/ 600 | Trn loss:  0.347275 - Acc: 88.1389 | Val loss:  0.348944 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 16  cdwn: 0                             \n",
      " 20:08:00 | Ep:  57/ 600 | Trn loss:  0.347107 - Acc: 88.1353 | Val loss:  0.348938 - Acc: 88.2639 | last_lr: 1.00000e-03  bad_ep: 17  cdwn: 0                             \n",
      " 20:08:13 | Ep:  58/ 600 | Trn loss:  0.346937 - Acc: 88.1432 | Val loss:  0.349027 - Acc: 88.2500 | last_lr: 1.00000e-03  bad_ep: 18  cdwn: 0                             \n",
      " 20:08:26 | Ep:  59/ 600 | Trn loss:  0.346750 - Acc: 88.1429 | Val loss:  0.349240 - Acc: 88.2407 | last_lr: 1.00000e-03  bad_ep: 19  cdwn: 0                             \n",
      " 20:08:39 | Ep:  60/ 600 | Trn loss:  0.346588 - Acc: 88.1526 | Val loss:  0.349280 - Acc: 88.2407 | last_lr: 1.00000e-03  bad_ep: 20  cdwn: 0                             \n",
      " 20:08:52 | Ep:  61/ 600 | Trn loss:  0.346422 - Acc: 88.1558 | Val loss:  0.349157 - Acc: 88.2361 | last_lr: 1.00000e-03  bad_ep: 21  cdwn: 0                             \n",
      " 20:09:05 | Ep:  62/ 600 | Trn loss:  0.346245 - Acc: 88.1598 | Val loss:  0.349350 - Acc: 88.2454 | last_lr: 1.00000e-03  bad_ep: 22  cdwn: 0                             \n",
      " 20:09:18 | Ep:  63/ 600 | Trn loss:  0.346041 - Acc: 88.1620 | Val loss:  0.349257 - Acc: 88.2361 | last_lr: 1.00000e-03  bad_ep: 23  cdwn: 0                             \n",
      " 20:09:31 | Ep:  64/ 600 | Trn loss:  0.345860 - Acc: 88.1714 | Val loss:  0.349465 - Acc: 88.2361 | last_lr: 1.00000e-03  bad_ep: 24  cdwn: 0                             \n",
      " 20:09:44 | Ep:  65/ 600 | Trn loss:  0.345650 - Acc: 88.1778 | Val loss:  0.349435 - Acc: 88.2269 | last_lr: 1.00000e-03  bad_ep: 25  cdwn: 0                             \n",
      " 20:09:56 | Ep:  66/ 600 | Trn loss:  0.345440 - Acc: 88.1797 | Val loss:  0.349435 - Acc: 88.2083 | last_lr: 1.00000e-03  bad_ep: 26  cdwn: 0                             \n",
      " 20:10:09 | Ep:  67/ 600 | Trn loss:  0.345267 - Acc: 88.1793 | Val loss:  0.349423 - Acc: 88.2130 | last_lr: 1.00000e-03  bad_ep: 27  cdwn: 0                             \n",
      " 20:10:22 | Ep:  68/ 600 | Trn loss:  0.345026 - Acc: 88.1894 | Val loss:  0.349591 - Acc: 88.2037 | last_lr: 1.00000e-03  bad_ep: 28  cdwn: 0                             \n",
      " 20:10:35 | Ep:  69/ 600 | Trn loss:  0.344799 - Acc: 88.1916 | Val loss:  0.349695 - Acc: 88.2176 | last_lr: 1.00000e-03  bad_ep: 29  cdwn: 0                             \n",
      " 20:10:47 | Ep:  70/ 600 | Trn loss:  0.344565 - Acc: 88.1981 | Val loss:  0.349671 - Acc: 88.2037 | last_lr: 1.00000e-03  bad_ep: 30  cdwn: 0                             \n",
      " 20:11:00 | Ep:  71/ 600 | Trn loss:  0.344345 - Acc: 88.2042 | Val loss:  0.349797 - Acc: 88.2037 | last_lr: 1.00000e-03  bad_ep: 31  cdwn: 0                             \n",
      " 20:11:13 | Ep:  72/ 600 | Trn loss:  0.344162 - Acc: 88.1999 | Val loss:  0.349806 - Acc: 88.1991 | last_lr: 1.00000e-03  bad_ep: 32  cdwn: 0                             \n",
      " 20:11:26 | Ep:  73/ 600 | Trn loss:  0.343902 - Acc: 88.2089 | Val loss:  0.349980 - Acc: 88.1759 | last_lr: 1.00000e-03  bad_ep: 33  cdwn: 0                             \n",
      " 20:11:39 | Ep:  74/ 600 | Trn loss:  0.343701 - Acc: 88.2071 | Val loss:  0.350115 - Acc: 88.1944 | last_lr: 1.00000e-03  bad_ep: 34  cdwn: 0                             \n",
      " 20:11:52 | Ep:  75/ 600 | Trn loss:  0.343428 - Acc: 88.2172 | Val loss:  0.350178 - Acc: 88.1759 | last_lr: 1.00000e-03  bad_ep: 35  cdwn: 0                             \n",
      " 20:12:05 | Ep:  76/ 600 | Trn loss:  0.343155 - Acc: 88.2247 | Val loss:  0.350201 - Acc: 88.1852 | last_lr: 1.00000e-03  bad_ep: 36  cdwn: 0                             \n",
      " 20:12:17 | Ep:  77/ 600 | Trn loss:  0.342943 - Acc: 88.2294 | Val loss:  0.350221 - Acc: 88.1620 | last_lr: 1.00000e-03  bad_ep: 37  cdwn: 0                             \n",
      " 20:12:30 | Ep:  78/ 600 | Trn loss:  0.342672 - Acc: 88.2294 | Val loss:  0.350374 - Acc: 88.1898 | last_lr: 1.00000e-03  bad_ep: 38  cdwn: 0                             \n",
      " 20:12:43 | Ep:  79/ 600 | Trn loss:  0.342375 - Acc: 88.2385 | Val loss:  0.350540 - Acc: 88.1759 | last_lr: 1.00000e-03  bad_ep: 39  cdwn: 0                             \n",
      " 20:12:56 | Ep:  80/ 600 | Trn loss:  0.342054 - Acc: 88.2442 | Val loss:  0.350795 - Acc: 88.1898 | last_lr: 1.00000e-03  bad_ep: 40  cdwn: 0                             \n",
      " 20:13:09 | Ep:  81/ 600 | Trn loss:  0.341755 - Acc: 88.2529 | Val loss:  0.351143 - Acc: 88.1713 | last_lr: 1.00000e-03  bad_ep: 41  cdwn: 0                             \n",
      " 20:13:22 | Ep:  82/ 600 | Trn loss:  0.341455 - Acc: 88.2605 | Val loss:  0.351317 - Acc: 88.1481 | last_lr: 1.00000e-03  bad_ep: 42  cdwn: 0                             \n",
      " 20:13:35 | Ep:  83/ 600 | Trn loss:  0.341116 - Acc: 88.2691 | Val loss:  0.351536 - Acc: 88.1620 | last_lr: 1.00000e-03  bad_ep: 43  cdwn: 0                             \n",
      " 20:13:48 | Ep:  84/ 600 | Trn loss:  0.340823 - Acc: 88.2825 | Val loss:  0.352099 - Acc: 88.1481 | last_lr: 1.00000e-03  bad_ep: 44  cdwn: 0                             \n",
      " 20:14:01 | Ep:  85/ 600 | Trn loss:  0.340467 - Acc: 88.2908 | Val loss:  0.352487 - Acc: 88.1343 | last_lr: 1.00000e-03  bad_ep: 45  cdwn: 0                             \n",
      " 20:14:14 | Ep:  86/ 600 | Trn loss:  0.340100 - Acc: 88.2973 | Val loss:  0.352969 - Acc: 88.1435 | last_lr: 1.00000e-03  bad_ep: 46  cdwn: 0                             \n",
      " 20:14:26 | Ep:  87/ 600 | Trn loss:  0.339653 - Acc: 88.3081 | Val loss:  0.353743 - Acc: 88.1111 | last_lr: 1.00000e-03  bad_ep: 47  cdwn: 0                             \n",
      " 20:14:39 | Ep:  88/ 600 | Trn loss:  0.339395 - Acc: 88.3106 | Val loss:  0.354554 - Acc: 88.1065 | last_lr: 1.00000e-03  bad_ep: 48  cdwn: 0                             \n",
      " 20:14:52 | Ep:  89/ 600 | Trn loss:  0.339013 - Acc: 88.3236 | Val loss:  0.355761 - Acc: 88.0926 | last_lr: 1.00000e-03  bad_ep: 49  cdwn: 0                             \n",
      " 20:15:05 | Ep:  90/ 600 | Trn loss:  0.338612 - Acc: 88.3258 | Val loss:  0.356637 - Acc: 88.1389 | last_lr: 1.00000e-03  bad_ep: 50  cdwn: 0                             \n",
      " 20:15:18 | Ep:  91/ 600 | Trn loss:  0.338229 - Acc: 88.3366 | Val loss:  0.357588 - Acc: 88.1481 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 20:15:31 | Ep:  92/ 600 | Trn loss:  0.337009 - Acc: 88.3366 | Val loss:  0.355823 - Acc: 88.0370 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 20:15:44 | Ep:  93/ 600 | Trn loss:  0.336343 - Acc: 88.3561 | Val loss:  0.356592 - Acc: 88.0046 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 20:15:57 | Ep:  94/ 600 | Trn loss:  0.335581 - Acc: 88.3716 | Val loss:  0.356900 - Acc: 87.9676 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 20:16:10 | Ep:  95/ 600 | Trn loss:  0.334858 - Acc: 88.3885 | Val loss:  0.357662 - Acc: 87.9676 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 20:16:23 | Ep:  96/ 600 | Trn loss:  0.334210 - Acc: 88.4001 | Val loss:  0.358339 - Acc: 87.9583 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 20:16:36 | Ep:  97/ 600 | Trn loss:  0.333530 - Acc: 88.4196 | Val loss:  0.358913 - Acc: 87.9352 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 20:16:49 | Ep:  98/ 600 | Trn loss:  0.332878 - Acc: 88.4380 | Val loss:  0.359427 - Acc: 87.9167 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 20:17:01 | Ep:  99/ 600 | Trn loss:  0.332219 - Acc: 88.4545 | Val loss:  0.360015 - Acc: 87.9444 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 2                              \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 20:17:14,650 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_100.pt - epoch: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20:17:14 | Ep: 100/ 600 | Trn loss:  0.331571 - Acc: 88.4729 | Val loss:  0.360854 - Acc: 87.9583 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 1 \n",
      " 20:17:27 | Ep: 101/ 600 | Trn loss:  0.330945 - Acc: 88.4812 | Val loss:  0.361946 - Acc: 87.9491 | last_lr: 5.00000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 20:17:40 | Ep: 102/ 600 | Trn loss:  0.330297 - Acc: 88.5036 | Val loss:  0.362928 - Acc: 87.9491 | last_lr: 5.00000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 20:17:53 | Ep: 103/ 600 | Trn loss:  0.329652 - Acc: 88.5206 | Val loss:  0.364184 - Acc: 87.9259 | last_lr: 5.00000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 20:18:06 | Ep: 104/ 600 | Trn loss:  0.329007 - Acc: 88.5364 | Val loss:  0.365260 - Acc: 87.9120 | last_lr: 5.00000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 20:18:19 | Ep: 105/ 600 | Trn loss:  0.328351 - Acc: 88.5595 | Val loss:  0.366208 - Acc: 87.9120 | last_lr: 5.00000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 20:18:31 | Ep: 106/ 600 | Trn loss:  0.327683 - Acc: 88.5790 | Val loss:  0.367693 - Acc: 87.8935 | last_lr: 5.00000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 20:18:44 | Ep: 107/ 600 | Trn loss:  0.327024 - Acc: 88.5949 | Val loss:  0.368353 - Acc: 87.8657 | last_lr: 5.00000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 20:18:57 | Ep: 108/ 600 | Trn loss:  0.326369 - Acc: 88.6100 | Val loss:  0.369068 - Acc: 87.8611 | last_lr: 5.00000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 20:19:10 | Ep: 109/ 600 | Trn loss:  0.325727 - Acc: 88.6328 | Val loss:  0.370372 - Acc: 87.8519 | last_lr: 5.00000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 20:19:22 | Ep: 110/ 600 | Trn loss:  0.325078 - Acc: 88.6411 | Val loss:  0.371682 - Acc: 87.8102 | last_lr: 5.00000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 20:19:35 | Ep: 111/ 600 | Trn loss:  0.324438 - Acc: 88.6591 | Val loss:  0.373504 - Acc: 87.7917 | last_lr: 5.00000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 20:19:48 | Ep: 112/ 600 | Trn loss:  0.323778 - Acc: 88.6753 | Val loss:  0.374921 - Acc: 87.7593 | last_lr: 5.00000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 20:20:00 | Ep: 113/ 600 | Trn loss:  0.323101 - Acc: 88.6970 | Val loss:  0.375926 - Acc: 87.7454 | last_lr: 5.00000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 20:20:13 | Ep: 114/ 600 | Trn loss:  0.322417 - Acc: 88.7143 | Val loss:  0.377053 - Acc: 87.7176 | last_lr: 5.00000e-04  bad_ep: 13  cdwn: 0                             \n",
      " 20:20:26 | Ep: 115/ 600 | Trn loss:  0.321736 - Acc: 88.7269 | Val loss:  0.378608 - Acc: 87.6759 | last_lr: 5.00000e-04  bad_ep: 14  cdwn: 0                             \n",
      " 20:20:39 | Ep: 116/ 600 | Trn loss:  0.321049 - Acc: 88.7453 | Val loss:  0.380285 - Acc: 87.6296 | last_lr: 5.00000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 20:20:51 | Ep: 117/ 600 | Trn loss:  0.320372 - Acc: 88.7644 | Val loss:  0.380714 - Acc: 87.5972 | last_lr: 5.00000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 20:21:04 | Ep: 118/ 600 | Trn loss:  0.319683 - Acc: 88.7799 | Val loss:  0.381957 - Acc: 87.5463 | last_lr: 5.00000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 20:21:17 | Ep: 119/ 600 | Trn loss:  0.318987 - Acc: 88.8081 | Val loss:  0.382542 - Acc: 87.4815 | last_lr: 5.00000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 20:21:30 | Ep: 120/ 600 | Trn loss:  0.318289 - Acc: 88.8272 | Val loss:  0.383781 - Acc: 87.4491 | last_lr: 5.00000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 20:21:43 | Ep: 121/ 600 | Trn loss:  0.317573 - Acc: 88.8452 | Val loss:  0.383733 - Acc: 87.4491 | last_lr: 5.00000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 20:21:56 | Ep: 122/ 600 | Trn loss:  0.316867 - Acc: 88.8662 | Val loss:  0.384585 - Acc: 87.4306 | last_lr: 5.00000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 20:22:09 | Ep: 123/ 600 | Trn loss:  0.316166 - Acc: 88.8907 | Val loss:  0.384771 - Acc: 87.4120 | last_lr: 5.00000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 20:22:21 | Ep: 124/ 600 | Trn loss:  0.315457 - Acc: 88.9152 | Val loss:  0.384655 - Acc: 87.3657 | last_lr: 5.00000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 20:22:34 | Ep: 125/ 600 | Trn loss:  0.314749 - Acc: 88.9325 | Val loss:  0.384387 - Acc: 87.3843 | last_lr: 5.00000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 20:22:47 | Ep: 126/ 600 | Trn loss:  0.314037 - Acc: 88.9535 | Val loss:  0.384452 - Acc: 87.3657 | last_lr: 5.00000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 20:23:00 | Ep: 127/ 600 | Trn loss:  0.313354 - Acc: 88.9686 | Val loss:  0.385325 - Acc: 87.3704 | last_lr: 5.00000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 20:23:13 | Ep: 128/ 600 | Trn loss:  0.312664 - Acc: 88.9877 | Val loss:  0.388262 - Acc: 87.3426 | last_lr: 5.00000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 20:23:26 | Ep: 129/ 600 | Trn loss:  0.311984 - Acc: 89.0061 | Val loss:  0.390361 - Acc: 87.3194 | last_lr: 5.00000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 20:23:39 | Ep: 130/ 600 | Trn loss:  0.311278 - Acc: 89.0209 | Val loss:  0.391990 - Acc: 87.2685 | last_lr: 5.00000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 20:23:52 | Ep: 131/ 600 | Trn loss:  0.310615 - Acc: 89.0310 | Val loss:  0.394149 - Acc: 87.2037 | last_lr: 5.00000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 20:24:05 | Ep: 132/ 600 | Trn loss:  0.309927 - Acc: 89.0563 | Val loss:  0.394912 - Acc: 87.1852 | last_lr: 5.00000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 20:24:18 | Ep: 133/ 600 | Trn loss:  0.309263 - Acc: 89.0801 | Val loss:  0.395837 - Acc: 87.1713 | last_lr: 5.00000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 20:24:31 | Ep: 134/ 600 | Trn loss:  0.308633 - Acc: 89.0978 | Val loss:  0.396493 - Acc: 87.1481 | last_lr: 5.00000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 20:24:43 | Ep: 135/ 600 | Trn loss:  0.307973 - Acc: 89.1136 | Val loss:  0.396931 - Acc: 87.1852 | last_lr: 5.00000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 20:24:56 | Ep: 136/ 600 | Trn loss:  0.307334 - Acc: 89.1349 | Val loss:  0.397826 - Acc: 87.1944 | last_lr: 5.00000e-04  bad_ep: 35  cdwn: 0                             \n",
      " 20:25:09 | Ep: 137/ 600 | Trn loss:  0.306685 - Acc: 89.1530 | Val loss:  0.398887 - Acc: 87.1944 | last_lr: 5.00000e-04  bad_ep: 36  cdwn: 0                             \n",
      " 20:25:22 | Ep: 138/ 600 | Trn loss:  0.306045 - Acc: 89.1663 | Val loss:  0.399714 - Acc: 87.2037 | last_lr: 5.00000e-04  bad_ep: 37  cdwn: 0                             \n",
      " 20:25:35 | Ep: 139/ 600 | Trn loss:  0.305391 - Acc: 89.1789 | Val loss:  0.400056 - Acc: 87.1991 | last_lr: 5.00000e-04  bad_ep: 38  cdwn: 0                             \n",
      " 20:25:48 | Ep: 140/ 600 | Trn loss:  0.304708 - Acc: 89.2100 | Val loss:  0.401307 - Acc: 87.1898 | last_lr: 5.00000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 20:26:01 | Ep: 141/ 600 | Trn loss:  0.304094 - Acc: 89.2287 | Val loss:  0.403742 - Acc: 87.0880 | last_lr: 5.00000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 20:26:14 | Ep: 142/ 600 | Trn loss:  0.303583 - Acc: 89.2367 | Val loss:  0.404755 - Acc: 87.1065 | last_lr: 5.00000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 20:26:27 | Ep: 143/ 600 | Trn loss:  0.302896 - Acc: 89.2565 | Val loss:  0.405994 - Acc: 87.0324 | last_lr: 5.00000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 20:26:40 | Ep: 144/ 600 | Trn loss:  0.302190 - Acc: 89.2666 | Val loss:  0.408701 - Acc: 86.8796 | last_lr: 5.00000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 20:26:53 | Ep: 145/ 600 | Trn loss:  0.301536 - Acc: 89.2792 | Val loss:  0.410017 - Acc: 86.8056 | last_lr: 5.00000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 20:27:06 | Ep: 146/ 600 | Trn loss:  0.300957 - Acc: 89.2973 | Val loss:  0.412196 - Acc: 86.6806 | last_lr: 5.00000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 20:27:19 | Ep: 147/ 600 | Trn loss:  0.300314 - Acc: 89.3142 | Val loss:  0.411135 - Acc: 86.7269 | last_lr: 5.00000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 20:27:32 | Ep: 148/ 600 | Trn loss:  0.299721 - Acc: 89.3279 | Val loss:  0.413460 - Acc: 86.5648 | last_lr: 5.00000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 20:27:44 | Ep: 149/ 600 | Trn loss:  0.298983 - Acc: 89.3427 | Val loss:  0.416468 - Acc: 86.4028 | last_lr: 5.00000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 20:27:57 | Ep: 150/ 600 | Trn loss:  0.298444 - Acc: 89.3525 | Val loss:  0.415859 - Acc: 86.4630 | last_lr: 5.00000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 20:28:10 | Ep: 151/ 600 | Trn loss:  0.297882 - Acc: 89.3651 | Val loss:  0.416417 - Acc: 86.4167 | last_lr: 5.00000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 20:28:23 | Ep: 152/ 600 | Trn loss:  0.297307 - Acc: 89.3777 | Val loss:  0.416397 - Acc: 86.3843 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 20:28:36 | Ep: 153/ 600 | Trn loss:  0.300648 - Acc: 89.1977 | Val loss:  0.392236 - Acc: 87.0787 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 20:28:49 | Ep: 154/ 600 | Trn loss:  0.299446 - Acc: 89.2348 | Val loss:  0.391482 - Acc: 87.2315 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 20:29:02 | Ep: 155/ 600 | Trn loss:  0.297904 - Acc: 89.2918 | Val loss:  0.390494 - Acc: 87.3472 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 20:29:15 | Ep: 156/ 600 | Trn loss:  0.296639 - Acc: 89.3333 | Val loss:  0.390683 - Acc: 87.3380 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 20:29:28 | Ep: 157/ 600 | Trn loss:  0.295573 - Acc: 89.3658 | Val loss:  0.391215 - Acc: 87.3333 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 20:29:41 | Ep: 158/ 600 | Trn loss:  0.294644 - Acc: 89.3892 | Val loss:  0.391854 - Acc: 87.3009 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 20:29:54 | Ep: 159/ 600 | Trn loss:  0.293785 - Acc: 89.4123 | Val loss:  0.392477 - Acc: 87.2870 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 20:30:07 | Ep: 160/ 600 | Trn loss:  0.292959 - Acc: 89.4434 | Val loss:  0.393108 - Acc: 87.2593 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 2                              \n",
      " 20:30:20 | Ep: 161/ 600 | Trn loss:  0.292162 - Acc: 89.4686 | Val loss:  0.393748 - Acc: 87.2454 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 1                              \n",
      " 20:30:33 | Ep: 162/ 600 | Trn loss:  0.291386 - Acc: 89.4903 | Val loss:  0.394404 - Acc: 87.2500 | last_lr: 2.50000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 20:30:46 | Ep: 163/ 600 | Trn loss:  0.290628 - Acc: 89.5105 | Val loss:  0.395088 - Acc: 87.2315 | last_lr: 2.50000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 20:30:58 | Ep: 164/ 600 | Trn loss:  0.289885 - Acc: 89.5307 | Val loss:  0.395793 - Acc: 87.2130 | last_lr: 2.50000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 20:31:11 | Ep: 165/ 600 | Trn loss:  0.289156 - Acc: 89.5501 | Val loss:  0.396502 - Acc: 87.1898 | last_lr: 2.50000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 20:31:24 | Ep: 166/ 600 | Trn loss:  0.288438 - Acc: 89.5675 | Val loss:  0.397199 - Acc: 87.1991 | last_lr: 2.50000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 20:31:37 | Ep: 167/ 600 | Trn loss:  0.287726 - Acc: 89.5913 | Val loss:  0.397894 - Acc: 87.1620 | last_lr: 2.50000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 20:31:50 | Ep: 168/ 600 | Trn loss:  0.287022 - Acc: 89.6115 | Val loss:  0.398606 - Acc: 87.1574 | last_lr: 2.50000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 20:32:03 | Ep: 169/ 600 | Trn loss:  0.286326 - Acc: 89.6360 | Val loss:  0.399332 - Acc: 87.1481 | last_lr: 2.50000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 20:32:15 | Ep: 170/ 600 | Trn loss:  0.285636 - Acc: 89.6533 | Val loss:  0.400072 - Acc: 87.1065 | last_lr: 2.50000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 20:32:28 | Ep: 171/ 600 | Trn loss:  0.284951 - Acc: 89.6775 | Val loss:  0.400817 - Acc: 87.0787 | last_lr: 2.50000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 20:32:41 | Ep: 172/ 600 | Trn loss:  0.284272 - Acc: 89.6977 | Val loss:  0.401558 - Acc: 87.0185 | last_lr: 2.50000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 20:32:54 | Ep: 173/ 600 | Trn loss:  0.283597 - Acc: 89.7201 | Val loss:  0.402296 - Acc: 87.0000 | last_lr: 2.50000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 20:33:07 | Ep: 174/ 600 | Trn loss:  0.282925 - Acc: 89.7442 | Val loss:  0.403030 - Acc: 86.9630 | last_lr: 2.50000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 20:33:20 | Ep: 175/ 600 | Trn loss:  0.282254 - Acc: 89.7612 | Val loss:  0.403763 - Acc: 86.9537 | last_lr: 2.50000e-04  bad_ep: 13  cdwn: 0                             \n",
      " 20:33:33 | Ep: 176/ 600 | Trn loss:  0.281586 - Acc: 89.7774 | Val loss:  0.404494 - Acc: 86.9306 | last_lr: 2.50000e-04  bad_ep: 14  cdwn: 0                             \n",
      " 20:33:46 | Ep: 177/ 600 | Trn loss:  0.280918 - Acc: 89.7958 | Val loss:  0.405228 - Acc: 86.9120 | last_lr: 2.50000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 20:33:59 | Ep: 178/ 600 | Trn loss:  0.280251 - Acc: 89.8066 | Val loss:  0.405967 - Acc: 86.8657 | last_lr: 2.50000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 20:34:12 | Ep: 179/ 600 | Trn loss:  0.279585 - Acc: 89.8294 | Val loss:  0.406707 - Acc: 86.8333 | last_lr: 2.50000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 20:34:25 | Ep: 180/ 600 | Trn loss:  0.278920 - Acc: 89.8506 | Val loss:  0.407456 - Acc: 86.8380 | last_lr: 2.50000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 20:34:38 | Ep: 181/ 600 | Trn loss:  0.278256 - Acc: 89.8676 | Val loss:  0.408213 - Acc: 86.8519 | last_lr: 2.50000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 20:34:51 | Ep: 182/ 600 | Trn loss:  0.277592 - Acc: 89.8903 | Val loss:  0.408975 - Acc: 86.8241 | last_lr: 2.50000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 20:35:04 | Ep: 183/ 600 | Trn loss:  0.276927 - Acc: 89.9138 | Val loss:  0.409748 - Acc: 86.7870 | last_lr: 2.50000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 20:35:17 | Ep: 184/ 600 | Trn loss:  0.276261 - Acc: 89.9380 | Val loss:  0.410526 - Acc: 86.7731 | last_lr: 2.50000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 20:35:30 | Ep: 185/ 600 | Trn loss:  0.275594 - Acc: 89.9560 | Val loss:  0.411315 - Acc: 86.7870 | last_lr: 2.50000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 20:35:44 | Ep: 186/ 600 | Trn loss:  0.274927 - Acc: 89.9733 | Val loss:  0.412108 - Acc: 86.7685 | last_lr: 2.50000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 20:35:57 | Ep: 187/ 600 | Trn loss:  0.274260 - Acc: 89.9978 | Val loss:  0.412906 - Acc: 86.7731 | last_lr: 2.50000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 20:36:10 | Ep: 188/ 600 | Trn loss:  0.273593 - Acc: 90.0195 | Val loss:  0.413722 - Acc: 86.7824 | last_lr: 2.50000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 20:36:23 | Ep: 189/ 600 | Trn loss:  0.272926 - Acc: 90.0444 | Val loss:  0.414551 - Acc: 86.7407 | last_lr: 2.50000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 20:36:36 | Ep: 190/ 600 | Trn loss:  0.272258 - Acc: 90.0624 | Val loss:  0.415393 - Acc: 86.7222 | last_lr: 2.50000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 20:36:49 | Ep: 191/ 600 | Trn loss:  0.271590 - Acc: 90.0859 | Val loss:  0.416247 - Acc: 86.6806 | last_lr: 2.50000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 20:37:02 | Ep: 192/ 600 | Trn loss:  0.270922 - Acc: 90.1053 | Val loss:  0.417110 - Acc: 86.6898 | last_lr: 2.50000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 20:37:15 | Ep: 193/ 600 | Trn loss:  0.270254 - Acc: 90.1234 | Val loss:  0.417987 - Acc: 86.6759 | last_lr: 2.50000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 20:37:28 | Ep: 194/ 600 | Trn loss:  0.269586 - Acc: 90.1418 | Val loss:  0.418868 - Acc: 86.6713 | last_lr: 2.50000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 20:37:41 | Ep: 195/ 600 | Trn loss:  0.268918 - Acc: 90.1620 | Val loss:  0.419772 - Acc: 86.6528 | last_lr: 2.50000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 20:37:54 | Ep: 196/ 600 | Trn loss:  0.268250 - Acc: 90.1861 | Val loss:  0.420685 - Acc: 86.6389 | last_lr: 2.50000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 20:38:07 | Ep: 197/ 600 | Trn loss:  0.267582 - Acc: 90.2045 | Val loss:  0.421629 - Acc: 86.6296 | last_lr: 2.50000e-04  bad_ep: 35  cdwn: 0                             \n",
      " 20:38:20 | Ep: 198/ 600 | Trn loss:  0.266914 - Acc: 90.2237 | Val loss:  0.422585 - Acc: 86.6343 | last_lr: 2.50000e-04  bad_ep: 36  cdwn: 0                             \n",
      " 20:38:33 | Ep: 199/ 600 | Trn loss:  0.266247 - Acc: 90.2428 | Val loss:  0.423557 - Acc: 86.6111 | last_lr: 2.50000e-04  bad_ep: 37  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 20:38:46,512 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_200.pt - epoch: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20:38:46 | Ep: 200/ 600 | Trn loss:  0.265579 - Acc: 90.2612 | Val loss:  0.424539 - Acc: 86.6019 | last_lr: 2.50000e-04  bad_ep: 38  cdwn: 0 \n",
      " 20:38:59 | Ep: 201/ 600 | Trn loss:  0.264910 - Acc: 90.2810 | Val loss:  0.425535 - Acc: 86.6204 | last_lr: 2.50000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 20:39:12 | Ep: 202/ 600 | Trn loss:  0.264240 - Acc: 90.3070 | Val loss:  0.426537 - Acc: 86.6019 | last_lr: 2.50000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 20:39:25 | Ep: 203/ 600 | Trn loss:  0.263569 - Acc: 90.3294 | Val loss:  0.427530 - Acc: 86.5833 | last_lr: 2.50000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 20:39:38 | Ep: 204/ 600 | Trn loss:  0.262897 - Acc: 90.3514 | Val loss:  0.428532 - Acc: 86.5694 | last_lr: 2.50000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 20:39:51 | Ep: 205/ 600 | Trn loss:  0.262224 - Acc: 90.3672 | Val loss:  0.429513 - Acc: 86.5509 | last_lr: 2.50000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 20:40:05 | Ep: 206/ 600 | Trn loss:  0.261550 - Acc: 90.3864 | Val loss:  0.430487 - Acc: 86.5278 | last_lr: 2.50000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 20:40:18 | Ep: 207/ 600 | Trn loss:  0.260877 - Acc: 90.4019 | Val loss:  0.431450 - Acc: 86.4954 | last_lr: 2.50000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 20:40:30 | Ep: 208/ 600 | Trn loss:  0.260203 - Acc: 90.4149 | Val loss:  0.432415 - Acc: 86.4259 | last_lr: 2.50000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 20:40:43 | Ep: 209/ 600 | Trn loss:  0.259529 - Acc: 90.4380 | Val loss:  0.433384 - Acc: 86.4259 | last_lr: 2.50000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 20:40:56 | Ep: 210/ 600 | Trn loss:  0.258854 - Acc: 90.4643 | Val loss:  0.434363 - Acc: 86.3935 | last_lr: 2.50000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 20:41:09 | Ep: 211/ 600 | Trn loss:  0.258179 - Acc: 90.4816 | Val loss:  0.435348 - Acc: 86.3750 | last_lr: 2.50000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 20:41:22 | Ep: 212/ 600 | Trn loss:  0.257503 - Acc: 90.5065 | Val loss:  0.436359 - Acc: 86.3657 | last_lr: 2.50000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 20:41:34 | Ep: 213/ 600 | Trn loss:  0.256828 - Acc: 90.5271 | Val loss:  0.437389 - Acc: 86.3426 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 10                             \n",
      " 20:41:47 | Ep: 214/ 600 | Trn loss:  0.264136 - Acc: 90.2125 | Val loss:  0.439935 - Acc: 86.2269 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 9                              \n",
      " 20:42:00 | Ep: 215/ 600 | Trn loss:  0.265409 - Acc: 90.1735 | Val loss:  0.438117 - Acc: 86.3519 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 8                              \n",
      " 20:42:12 | Ep: 216/ 600 | Trn loss:  0.264477 - Acc: 90.2136 | Val loss:  0.437701 - Acc: 86.3704 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 7                              \n",
      " 20:42:25 | Ep: 217/ 600 | Trn loss:  0.263684 - Acc: 90.2403 | Val loss:  0.437288 - Acc: 86.3611 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 6                              \n",
      " 20:42:38 | Ep: 218/ 600 | Trn loss:  0.262917 - Acc: 90.2583 | Val loss:  0.437128 - Acc: 86.3704 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 5                              \n",
      " 20:42:51 | Ep: 219/ 600 | Trn loss:  0.262190 - Acc: 90.2911 | Val loss:  0.436970 - Acc: 86.3843 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 4                              \n",
      " 20:43:03 | Ep: 220/ 600 | Trn loss:  0.261543 - Acc: 90.3164 | Val loss:  0.436882 - Acc: 86.3981 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 3                              \n",
      " 20:43:16 | Ep: 221/ 600 | Trn loss:  0.260927 - Acc: 90.3286 | Val loss:  0.436905 - Acc: 86.3935 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 2                              \n",
      " 20:43:29 | Ep: 222/ 600 | Trn loss:  0.260335 - Acc: 90.3492 | Val loss:  0.436990 - Acc: 86.4213 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 1                              \n",
      " 20:43:42 | Ep: 223/ 600 | Trn loss:  0.259760 - Acc: 90.3690 | Val loss:  0.437142 - Acc: 86.4306 | last_lr: 1.25000e-04  bad_ep: 0  cdwn: 0                              \n",
      " 20:43:54 | Ep: 224/ 600 | Trn loss:  0.259200 - Acc: 90.3849 | Val loss:  0.437352 - Acc: 86.4259 | last_lr: 1.25000e-04  bad_ep: 1  cdwn: 0                              \n",
      " 20:44:07 | Ep: 225/ 600 | Trn loss:  0.258652 - Acc: 90.3997 | Val loss:  0.437620 - Acc: 86.4120 | last_lr: 1.25000e-04  bad_ep: 2  cdwn: 0                              \n",
      " 20:44:20 | Ep: 226/ 600 | Trn loss:  0.258115 - Acc: 90.4156 | Val loss:  0.437928 - Acc: 86.3935 | last_lr: 1.25000e-04  bad_ep: 3  cdwn: 0                              \n",
      " 20:44:33 | Ep: 227/ 600 | Trn loss:  0.257587 - Acc: 90.4329 | Val loss:  0.438273 - Acc: 86.4074 | last_lr: 1.25000e-04  bad_ep: 4  cdwn: 0                              \n",
      " 20:44:46 | Ep: 228/ 600 | Trn loss:  0.257066 - Acc: 90.4470 | Val loss:  0.438642 - Acc: 86.3704 | last_lr: 1.25000e-04  bad_ep: 5  cdwn: 0                              \n",
      " 20:44:58 | Ep: 229/ 600 | Trn loss:  0.256552 - Acc: 90.4661 | Val loss:  0.439035 - Acc: 86.3704 | last_lr: 1.25000e-04  bad_ep: 6  cdwn: 0                              \n",
      " 20:45:11 | Ep: 230/ 600 | Trn loss:  0.256043 - Acc: 90.4870 | Val loss:  0.439455 - Acc: 86.3519 | last_lr: 1.25000e-04  bad_ep: 7  cdwn: 0                              \n",
      " 20:45:24 | Ep: 231/ 600 | Trn loss:  0.255540 - Acc: 90.5032 | Val loss:  0.439890 - Acc: 86.3796 | last_lr: 1.25000e-04  bad_ep: 8  cdwn: 0                              \n",
      " 20:45:37 | Ep: 232/ 600 | Trn loss:  0.255042 - Acc: 90.5180 | Val loss:  0.440345 - Acc: 86.3981 | last_lr: 1.25000e-04  bad_ep: 9  cdwn: 0                              \n",
      " 20:45:50 | Ep: 233/ 600 | Trn loss:  0.254548 - Acc: 90.5350 | Val loss:  0.440819 - Acc: 86.3981 | last_lr: 1.25000e-04  bad_ep: 10  cdwn: 0                             \n",
      " 20:46:03 | Ep: 234/ 600 | Trn loss:  0.254059 - Acc: 90.5519 | Val loss:  0.441306 - Acc: 86.3657 | last_lr: 1.25000e-04  bad_ep: 11  cdwn: 0                             \n",
      " 20:46:16 | Ep: 235/ 600 | Trn loss:  0.253575 - Acc: 90.5671 | Val loss:  0.441804 - Acc: 86.3241 | last_lr: 1.25000e-04  bad_ep: 12  cdwn: 0                             \n",
      " 20:46:29 | Ep: 236/ 600 | Trn loss:  0.253094 - Acc: 90.5869 | Val loss:  0.442318 - Acc: 86.3380 | last_lr: 1.25000e-04  bad_ep: 13  cdwn: 0                             \n",
      " 20:46:42 | Ep: 237/ 600 | Trn loss:  0.252617 - Acc: 90.6032 | Val loss:  0.442841 - Acc: 86.3426 | last_lr: 1.25000e-04  bad_ep: 14  cdwn: 0                             \n",
      " 20:46:55 | Ep: 238/ 600 | Trn loss:  0.252144 - Acc: 90.6169 | Val loss:  0.443373 - Acc: 86.3426 | last_lr: 1.25000e-04  bad_ep: 15  cdwn: 0                             \n",
      " 20:47:08 | Ep: 239/ 600 | Trn loss:  0.251674 - Acc: 90.6360 | Val loss:  0.443923 - Acc: 86.3519 | last_lr: 1.25000e-04  bad_ep: 16  cdwn: 0                             \n",
      " 20:47:21 | Ep: 240/ 600 | Trn loss:  0.251206 - Acc: 90.6490 | Val loss:  0.444477 - Acc: 86.3426 | last_lr: 1.25000e-04  bad_ep: 17  cdwn: 0                             \n",
      " 20:47:34 | Ep: 241/ 600 | Trn loss:  0.250741 - Acc: 90.6670 | Val loss:  0.445037 - Acc: 86.3287 | last_lr: 1.25000e-04  bad_ep: 18  cdwn: 0                             \n",
      " 20:47:47 | Ep: 242/ 600 | Trn loss:  0.250279 - Acc: 90.6847 | Val loss:  0.445608 - Acc: 86.3102 | last_lr: 1.25000e-04  bad_ep: 19  cdwn: 0                             \n",
      " 20:48:00 | Ep: 243/ 600 | Trn loss:  0.249818 - Acc: 90.6955 | Val loss:  0.446193 - Acc: 86.3056 | last_lr: 1.25000e-04  bad_ep: 20  cdwn: 0                             \n",
      " 20:48:13 | Ep: 244/ 600 | Trn loss:  0.249360 - Acc: 90.7042 | Val loss:  0.446783 - Acc: 86.2731 | last_lr: 1.25000e-04  bad_ep: 21  cdwn: 0                             \n",
      " 20:48:26 | Ep: 245/ 600 | Trn loss:  0.248904 - Acc: 90.7168 | Val loss:  0.447383 - Acc: 86.2731 | last_lr: 1.25000e-04  bad_ep: 22  cdwn: 0                             \n",
      " 20:48:39 | Ep: 246/ 600 | Trn loss:  0.248449 - Acc: 90.7345 | Val loss:  0.447989 - Acc: 86.2454 | last_lr: 1.25000e-04  bad_ep: 23  cdwn: 0                             \n",
      " 20:48:52 | Ep: 247/ 600 | Trn loss:  0.247996 - Acc: 90.7514 | Val loss:  0.448602 - Acc: 86.2454 | last_lr: 1.25000e-04  bad_ep: 24  cdwn: 0                             \n",
      " 20:49:05 | Ep: 248/ 600 | Trn loss:  0.247545 - Acc: 90.7644 | Val loss:  0.449220 - Acc: 86.2315 | last_lr: 1.25000e-04  bad_ep: 25  cdwn: 0                             \n",
      " 20:49:18 | Ep: 249/ 600 | Trn loss:  0.247095 - Acc: 90.7879 | Val loss:  0.449846 - Acc: 86.2083 | last_lr: 1.25000e-04  bad_ep: 26  cdwn: 0                             \n",
      " 20:49:31 | Ep: 250/ 600 | Trn loss:  0.246646 - Acc: 90.8081 | Val loss:  0.450483 - Acc: 86.1852 | last_lr: 1.25000e-04  bad_ep: 27  cdwn: 0                             \n",
      " 20:49:44 | Ep: 251/ 600 | Trn loss:  0.246198 - Acc: 90.8258 | Val loss:  0.451113 - Acc: 86.1759 | last_lr: 1.25000e-04  bad_ep: 28  cdwn: 0                             \n",
      " 20:49:57 | Ep: 252/ 600 | Trn loss:  0.245751 - Acc: 90.8445 | Val loss:  0.451761 - Acc: 86.1574 | last_lr: 1.25000e-04  bad_ep: 29  cdwn: 0                             \n",
      " 20:50:10 | Ep: 253/ 600 | Trn loss:  0.245306 - Acc: 90.8604 | Val loss:  0.452409 - Acc: 86.1435 | last_lr: 1.25000e-04  bad_ep: 30  cdwn: 0                             \n",
      " 20:50:23 | Ep: 254/ 600 | Trn loss:  0.244861 - Acc: 90.8791 | Val loss:  0.453062 - Acc: 86.1296 | last_lr: 1.25000e-04  bad_ep: 31  cdwn: 0                             \n",
      " 20:50:36 | Ep: 255/ 600 | Trn loss:  0.244417 - Acc: 90.8961 | Val loss:  0.453722 - Acc: 86.1019 | last_lr: 1.25000e-04  bad_ep: 32  cdwn: 0                             \n",
      " 20:50:49 | Ep: 256/ 600 | Trn loss:  0.243975 - Acc: 90.9105 | Val loss:  0.454383 - Acc: 86.0833 | last_lr: 1.25000e-04  bad_ep: 33  cdwn: 0                             \n",
      " 20:51:02 | Ep: 257/ 600 | Trn loss:  0.243532 - Acc: 90.9221 | Val loss:  0.455046 - Acc: 86.0880 | last_lr: 1.25000e-04  bad_ep: 34  cdwn: 0                             \n",
      " 20:51:14 | Ep: 258/ 600 | Trn loss:  0.243091 - Acc: 90.9361 | Val loss:  0.455711 - Acc: 86.0880 | last_lr: 1.25000e-04  bad_ep: 35  cdwn: 0                             \n",
      " 20:51:27 | Ep: 259/ 600 | Trn loss:  0.242650 - Acc: 90.9506 | Val loss:  0.456386 - Acc: 86.0602 | last_lr: 1.25000e-04  bad_ep: 36  cdwn: 0                             \n",
      " 20:51:40 | Ep: 260/ 600 | Trn loss:  0.242209 - Acc: 90.9650 | Val loss:  0.457053 - Acc: 86.0463 | last_lr: 1.25000e-04  bad_ep: 37  cdwn: 0                             \n",
      " 20:51:53 | Ep: 261/ 600 | Trn loss:  0.241769 - Acc: 90.9747 | Val loss:  0.457722 - Acc: 86.0278 | last_lr: 1.25000e-04  bad_ep: 38  cdwn: 0                             \n",
      " 20:52:05 | Ep: 262/ 600 | Trn loss:  0.241330 - Acc: 90.9910 | Val loss:  0.458397 - Acc: 86.0185 | last_lr: 1.25000e-04  bad_ep: 39  cdwn: 0                             \n",
      " 20:52:18 | Ep: 263/ 600 | Trn loss:  0.240891 - Acc: 91.0058 | Val loss:  0.459069 - Acc: 86.0000 | last_lr: 1.25000e-04  bad_ep: 40  cdwn: 0                             \n",
      " 20:52:31 | Ep: 264/ 600 | Trn loss:  0.240452 - Acc: 91.0202 | Val loss:  0.459750 - Acc: 86.0000 | last_lr: 1.25000e-04  bad_ep: 41  cdwn: 0                             \n",
      " 20:52:44 | Ep: 265/ 600 | Trn loss:  0.240014 - Acc: 91.0339 | Val loss:  0.460431 - Acc: 86.0046 | last_lr: 1.25000e-04  bad_ep: 42  cdwn: 0                             \n",
      " 20:52:57 | Ep: 266/ 600 | Trn loss:  0.239575 - Acc: 91.0491 | Val loss:  0.461111 - Acc: 86.0000 | last_lr: 1.25000e-04  bad_ep: 43  cdwn: 0                             \n",
      " 20:53:09 | Ep: 267/ 600 | Trn loss:  0.239137 - Acc: 91.0722 | Val loss:  0.461799 - Acc: 86.0185 | last_lr: 1.25000e-04  bad_ep: 44  cdwn: 0                             \n",
      " 20:53:22 | Ep: 268/ 600 | Trn loss:  0.238699 - Acc: 91.0855 | Val loss:  0.462481 - Acc: 86.0046 | last_lr: 1.25000e-04  bad_ep: 45  cdwn: 0                             \n",
      " 20:53:35 | Ep: 269/ 600 | Trn loss:  0.238261 - Acc: 91.1010 | Val loss:  0.463178 - Acc: 86.0000 | last_lr: 1.25000e-04  bad_ep: 46  cdwn: 0                             \n",
      " 20:53:48 | Ep: 270/ 600 | Trn loss:  0.237823 - Acc: 91.1140 | Val loss:  0.463868 - Acc: 85.9954 | last_lr: 1.25000e-04  bad_ep: 47  cdwn: 0                             \n",
      " 20:54:01 | Ep: 271/ 600 | Trn loss:  0.237385 - Acc: 91.1317 | Val loss:  0.464562 - Acc: 85.9907 | last_lr: 1.25000e-04  bad_ep: 48  cdwn: 0                             \n",
      " 20:54:13 | Ep: 272/ 600 | Trn loss:  0.236947 - Acc: 91.1515 | Val loss:  0.465264 - Acc: 85.9954 | last_lr: 1.25000e-04  bad_ep: 49  cdwn: 0                             \n",
      " 20:54:26 | Ep: 273/ 600 | Trn loss:  0.236509 - Acc: 91.1659 | Val loss:  0.465961 - Acc: 86.0046 | last_lr: 1.25000e-04  bad_ep: 50  cdwn: 0                             \n",
      " 20:54:39 | Ep: 274/ 600 | Trn loss:  0.236071 - Acc: 91.1793 | Val loss:  0.466663 - Acc: 86.0185 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 10                             \n",
      " 20:54:52 | Ep: 275/ 600 | Trn loss:  0.244094 - Acc: 90.8225 | Val loss:  0.456924 - Acc: 86.5926 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 9                              \n",
      " 20:55:05 | Ep: 276/ 600 | Trn loss:  0.245479 - Acc: 90.7767 | Val loss:  0.455013 - Acc: 86.6713 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 8                              \n",
      " 20:55:17 | Ep: 277/ 600 | Trn loss:  0.244991 - Acc: 90.7944 | Val loss:  0.454148 - Acc: 86.7176 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 7                              \n",
      " 20:55:30 | Ep: 278/ 600 | Trn loss:  0.244523 - Acc: 90.8160 | Val loss:  0.453722 - Acc: 86.7454 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 6                              \n",
      " 20:55:43 | Ep: 279/ 600 | Trn loss:  0.244079 - Acc: 90.8294 | Val loss:  0.453518 - Acc: 86.7361 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 5                              \n",
      " 20:55:56 | Ep: 280/ 600 | Trn loss:  0.243647 - Acc: 90.8561 | Val loss:  0.453449 - Acc: 86.7407 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 4                              \n",
      " 20:56:09 | Ep: 281/ 600 | Trn loss:  0.243224 - Acc: 90.8781 | Val loss:  0.453467 - Acc: 86.7407 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 3                              \n",
      " 20:56:21 | Ep: 282/ 600 | Trn loss:  0.242812 - Acc: 90.8961 | Val loss:  0.453543 - Acc: 86.7454 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 2                              \n",
      " 20:56:34 | Ep: 283/ 600 | Trn loss:  0.242409 - Acc: 90.9087 | Val loss:  0.453662 - Acc: 86.7361 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 1                              \n",
      " 20:56:47 | Ep: 284/ 600 | Trn loss:  0.242016 - Acc: 90.9246 | Val loss:  0.453812 - Acc: 86.7083 | last_lr: 6.25000e-05  bad_ep: 0  cdwn: 0                              \n",
      " 20:57:00 | Ep: 285/ 600 | Trn loss:  0.241630 - Acc: 90.9304 | Val loss:  0.453985 - Acc: 86.7222 | last_lr: 6.25000e-05  bad_ep: 1  cdwn: 0                              \n",
      " 20:57:13 | Ep: 286/ 600 | Trn loss:  0.241251 - Acc: 90.9477 | Val loss:  0.454175 - Acc: 86.7269 | last_lr: 6.25000e-05  bad_ep: 2  cdwn: 0                              \n",
      " 20:57:25 | Ep: 287/ 600 | Trn loss:  0.240879 - Acc: 90.9603 | Val loss:  0.454381 - Acc: 86.7315 | last_lr: 6.25000e-05  bad_ep: 3  cdwn: 0                              \n",
      " 20:57:38 | Ep: 288/ 600 | Trn loss:  0.240512 - Acc: 90.9751 | Val loss:  0.454597 - Acc: 86.7361 | last_lr: 6.25000e-05  bad_ep: 4  cdwn: 0                              \n",
      " 20:57:51 | Ep: 289/ 600 | Trn loss:  0.240151 - Acc: 90.9877 | Val loss:  0.454824 - Acc: 86.7361 | last_lr: 6.25000e-05  bad_ep: 5  cdwn: 0                              \n",
      " 20:58:04 | Ep: 290/ 600 | Trn loss:  0.239795 - Acc: 91.0036 | Val loss:  0.455061 - Acc: 86.7176 | last_lr: 6.25000e-05  bad_ep: 6  cdwn: 0                              \n",
      " 20:58:16 | Ep: 291/ 600 | Trn loss:  0.239444 - Acc: 91.0152 | Val loss:  0.455303 - Acc: 86.7176 | last_lr: 6.25000e-05  bad_ep: 7  cdwn: 0                              \n",
      " 20:58:29 | Ep: 292/ 600 | Trn loss:  0.239097 - Acc: 91.0281 | Val loss:  0.455554 - Acc: 86.7130 | last_lr: 6.25000e-05  bad_ep: 8  cdwn: 0                              \n",
      " 20:58:42 | Ep: 293/ 600 | Trn loss:  0.238755 - Acc: 91.0404 | Val loss:  0.455808 - Acc: 86.7083 | last_lr: 6.25000e-05  bad_ep: 9  cdwn: 0                              \n",
      " 20:58:55 | Ep: 294/ 600 | Trn loss:  0.238417 - Acc: 91.0552 | Val loss:  0.456065 - Acc: 86.7037 | last_lr: 6.25000e-05  bad_ep: 10  cdwn: 0                             \n",
      " 20:59:07 | Ep: 295/ 600 | Trn loss:  0.238083 - Acc: 91.0664 | Val loss:  0.456328 - Acc: 86.6944 | last_lr: 6.25000e-05  bad_ep: 11  cdwn: 0                             \n",
      " 20:59:20 | Ep: 296/ 600 | Trn loss:  0.237752 - Acc: 91.0754 | Val loss:  0.456594 - Acc: 86.7037 | last_lr: 6.25000e-05  bad_ep: 12  cdwn: 0                             \n",
      " 20:59:33 | Ep: 297/ 600 | Trn loss:  0.237425 - Acc: 91.0920 | Val loss:  0.456865 - Acc: 86.7130 | last_lr: 6.25000e-05  bad_ep: 13  cdwn: 0                             \n",
      " 20:59:46 | Ep: 298/ 600 | Trn loss:  0.237101 - Acc: 91.1014 | Val loss:  0.457135 - Acc: 86.7083 | last_lr: 6.25000e-05  bad_ep: 14  cdwn: 0                             \n",
      " 20:59:59 | Ep: 299/ 600 | Trn loss:  0.236780 - Acc: 91.1133 | Val loss:  0.457407 - Acc: 86.6944 | last_lr: 6.25000e-05  bad_ep: 15  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:00:12,710 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_300.pt - epoch: 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21:00:12 | Ep: 300/ 600 | Trn loss:  0.236462 - Acc: 91.1216 | Val loss:  0.457684 - Acc: 86.6852 | last_lr: 6.25000e-05  bad_ep: 16  cdwn: 0 \n",
      " 21:00:25 | Ep: 301/ 600 | Trn loss:  0.236146 - Acc: 91.1342 | Val loss:  0.457961 - Acc: 86.6759 | last_lr: 6.25000e-05  bad_ep: 17  cdwn: 0                             \n",
      " 21:00:38 | Ep: 302/ 600 | Trn loss:  0.235833 - Acc: 91.1421 | Val loss:  0.458240 - Acc: 86.6620 | last_lr: 6.25000e-05  bad_ep: 18  cdwn: 0                             \n",
      " 21:00:52 | Ep: 303/ 600 | Trn loss:  0.235523 - Acc: 91.1512 | Val loss:  0.458520 - Acc: 86.6528 | last_lr: 6.25000e-05  bad_ep: 19  cdwn: 0                             \n",
      " 21:01:05 | Ep: 304/ 600 | Trn loss:  0.235215 - Acc: 91.1616 | Val loss:  0.458802 - Acc: 86.6389 | last_lr: 6.25000e-05  bad_ep: 20  cdwn: 0                             \n",
      " 21:01:18 | Ep: 305/ 600 | Trn loss:  0.234908 - Acc: 91.1717 | Val loss:  0.459085 - Acc: 86.6343 | last_lr: 6.25000e-05  bad_ep: 21  cdwn: 0                             \n",
      " 21:01:31 | Ep: 306/ 600 | Trn loss:  0.234604 - Acc: 91.1807 | Val loss:  0.459369 - Acc: 86.6343 | last_lr: 6.25000e-05  bad_ep: 22  cdwn: 0                             \n",
      " 21:01:44 | Ep: 307/ 600 | Trn loss:  0.234302 - Acc: 91.1937 | Val loss:  0.459655 - Acc: 86.6250 | last_lr: 6.25000e-05  bad_ep: 23  cdwn: 0                             \n",
      " 21:01:57 | Ep: 308/ 600 | Trn loss:  0.234001 - Acc: 91.2078 | Val loss:  0.459941 - Acc: 86.6250 | last_lr: 6.25000e-05  bad_ep: 24  cdwn: 0                             \n",
      " 21:02:10 | Ep: 309/ 600 | Trn loss:  0.233702 - Acc: 91.2208 | Val loss:  0.460231 - Acc: 86.6157 | last_lr: 6.25000e-05  bad_ep: 25  cdwn: 0                             \n",
      " 21:02:23 | Ep: 310/ 600 | Trn loss:  0.233404 - Acc: 91.2294 | Val loss:  0.460519 - Acc: 86.6157 | last_lr: 6.25000e-05  bad_ep: 26  cdwn: 0                             \n",
      " 21:02:36 | Ep: 311/ 600 | Trn loss:  0.233108 - Acc: 91.2381 | Val loss:  0.460813 - Acc: 86.6111 | last_lr: 6.25000e-05  bad_ep: 27  cdwn: 0                             \n",
      " 21:02:49 | Ep: 312/ 600 | Trn loss:  0.232813 - Acc: 91.2453 | Val loss:  0.461104 - Acc: 86.6111 | last_lr: 6.25000e-05  bad_ep: 28  cdwn: 0                             \n",
      " 21:03:02 | Ep: 313/ 600 | Trn loss:  0.232519 - Acc: 91.2529 | Val loss:  0.461399 - Acc: 86.6065 | last_lr: 6.25000e-05  bad_ep: 29  cdwn: 0                             \n",
      " 21:03:15 | Ep: 314/ 600 | Trn loss:  0.232227 - Acc: 91.2637 | Val loss:  0.461695 - Acc: 86.6019 | last_lr: 6.25000e-05  bad_ep: 30  cdwn: 0                             \n",
      " 21:03:28 | Ep: 315/ 600 | Trn loss:  0.231935 - Acc: 91.2767 | Val loss:  0.461992 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 31  cdwn: 0                             \n",
      " 21:03:41 | Ep: 316/ 600 | Trn loss:  0.231645 - Acc: 91.2843 | Val loss:  0.462291 - Acc: 86.5926 | last_lr: 6.25000e-05  bad_ep: 32  cdwn: 0                             \n",
      " 21:03:54 | Ep: 317/ 600 | Trn loss:  0.231355 - Acc: 91.2926 | Val loss:  0.462591 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 33  cdwn: 0                             \n",
      " 21:04:08 | Ep: 318/ 600 | Trn loss:  0.231067 - Acc: 91.2998 | Val loss:  0.462892 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 34  cdwn: 0                             \n",
      " 21:04:21 | Ep: 319/ 600 | Trn loss:  0.230779 - Acc: 91.3099 | Val loss:  0.463194 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 35  cdwn: 0                             \n",
      " 21:04:34 | Ep: 320/ 600 | Trn loss:  0.230492 - Acc: 91.3207 | Val loss:  0.463499 - Acc: 86.5787 | last_lr: 6.25000e-05  bad_ep: 36  cdwn: 0                             \n",
      " 21:04:47 | Ep: 321/ 600 | Trn loss:  0.230206 - Acc: 91.3304 | Val loss:  0.463806 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 37  cdwn: 0                             \n",
      " 21:05:00 | Ep: 322/ 600 | Trn loss:  0.229920 - Acc: 91.3391 | Val loss:  0.464112 - Acc: 86.5880 | last_lr: 6.25000e-05  bad_ep: 38  cdwn: 0                             \n",
      " 21:05:13 | Ep: 323/ 600 | Trn loss:  0.229636 - Acc: 91.3470 | Val loss:  0.464421 - Acc: 86.5741 | last_lr: 6.25000e-05  bad_ep: 39  cdwn: 0                             \n",
      " 21:05:26 | Ep: 324/ 600 | Trn loss:  0.229351 - Acc: 91.3575 | Val loss:  0.464732 - Acc: 86.5602 | last_lr: 6.25000e-05  bad_ep: 40  cdwn: 0                             \n",
      " 21:05:39 | Ep: 325/ 600 | Trn loss:  0.229068 - Acc: 91.3727 | Val loss:  0.465043 - Acc: 86.5509 | last_lr: 6.25000e-05  bad_ep: 41  cdwn: 0                             \n",
      " 21:05:52 | Ep: 326/ 600 | Trn loss:  0.228785 - Acc: 91.3856 | Val loss:  0.465356 - Acc: 86.5417 | last_lr: 6.25000e-05  bad_ep: 42  cdwn: 0                             \n",
      " 21:06:05 | Ep: 327/ 600 | Trn loss:  0.228503 - Acc: 91.3947 | Val loss:  0.465671 - Acc: 86.5231 | last_lr: 6.25000e-05  bad_ep: 43  cdwn: 0                             \n",
      " 21:06:18 | Ep: 328/ 600 | Trn loss:  0.228221 - Acc: 91.4026 | Val loss:  0.465985 - Acc: 86.5185 | last_lr: 6.25000e-05  bad_ep: 44  cdwn: 0                             \n",
      " 21:06:31 | Ep: 329/ 600 | Trn loss:  0.227940 - Acc: 91.4102 | Val loss:  0.466304 - Acc: 86.5046 | last_lr: 6.25000e-05  bad_ep: 45  cdwn: 0                             \n",
      " 21:06:44 | Ep: 330/ 600 | Trn loss:  0.227660 - Acc: 91.4224 | Val loss:  0.466622 - Acc: 86.5046 | last_lr: 6.25000e-05  bad_ep: 46  cdwn: 0                             \n",
      " 21:06:57 | Ep: 331/ 600 | Trn loss:  0.227380 - Acc: 91.4336 | Val loss:  0.466943 - Acc: 86.5000 | last_lr: 6.25000e-05  bad_ep: 47  cdwn: 0                             \n",
      " 21:07:10 | Ep: 332/ 600 | Trn loss:  0.227100 - Acc: 91.4444 | Val loss:  0.467264 - Acc: 86.4769 | last_lr: 6.25000e-05  bad_ep: 48  cdwn: 0                             \n",
      " 21:07:23 | Ep: 333/ 600 | Trn loss:  0.226821 - Acc: 91.4556 | Val loss:  0.467588 - Acc: 86.4676 | last_lr: 6.25000e-05  bad_ep: 49  cdwn: 0                             \n",
      " 21:07:36 | Ep: 334/ 600 | Trn loss:  0.226542 - Acc: 91.4650 | Val loss:  0.467912 - Acc: 86.4537 | last_lr: 6.25000e-05  bad_ep: 50  cdwn: 0                             \n",
      " 21:07:50 | Ep: 335/ 600 | Trn loss:  0.226263 - Acc: 91.4762 | Val loss:  0.468236 - Acc: 86.4491 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 10                             \n",
      " 21:08:03 | Ep: 336/ 600 | Trn loss:  0.231702 - Acc: 91.2576 | Val loss:  0.469866 - Acc: 86.9398 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 9                              \n",
      " 21:08:16 | Ep: 337/ 600 | Trn loss:  0.231255 - Acc: 91.2709 | Val loss:  0.469745 - Acc: 86.9259 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 8                              \n",
      " 21:08:29 | Ep: 338/ 600 | Trn loss:  0.230848 - Acc: 91.2897 | Val loss:  0.469716 - Acc: 86.9028 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 7                              \n",
      " 21:08:42 | Ep: 339/ 600 | Trn loss:  0.230508 - Acc: 91.2980 | Val loss:  0.469714 - Acc: 86.9167 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 6                              \n",
      " 21:08:55 | Ep: 340/ 600 | Trn loss:  0.230200 - Acc: 91.3171 | Val loss:  0.469724 - Acc: 86.9074 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 5                              \n",
      " 21:09:08 | Ep: 341/ 600 | Trn loss:  0.229910 - Acc: 91.3294 | Val loss:  0.469753 - Acc: 86.9074 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 4                              \n",
      " 21:09:21 | Ep: 342/ 600 | Trn loss:  0.229635 - Acc: 91.3395 | Val loss:  0.469791 - Acc: 86.9074 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 3                              \n",
      " 21:09:35 | Ep: 343/ 600 | Trn loss:  0.229369 - Acc: 91.3503 | Val loss:  0.469839 - Acc: 86.9028 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 2                              \n",
      " 21:09:48 | Ep: 344/ 600 | Trn loss:  0.229113 - Acc: 91.3597 | Val loss:  0.469900 - Acc: 86.8889 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 1                              \n",
      " 21:10:01 | Ep: 345/ 600 | Trn loss:  0.228862 - Acc: 91.3723 | Val loss:  0.469972 - Acc: 86.8843 | last_lr: 3.12500e-05  bad_ep: 0  cdwn: 0                              \n",
      " 21:10:14 | Ep: 346/ 600 | Trn loss:  0.228619 - Acc: 91.3828 | Val loss:  0.470055 - Acc: 86.8889 | last_lr: 3.12500e-05  bad_ep: 1  cdwn: 0                              \n",
      " 21:10:27 | Ep: 347/ 600 | Trn loss:  0.228380 - Acc: 91.3921 | Val loss:  0.470144 - Acc: 86.8843 | last_lr: 3.12500e-05  bad_ep: 2  cdwn: 0                              \n",
      " 21:10:40 | Ep: 348/ 600 | Trn loss:  0.228146 - Acc: 91.4004 | Val loss:  0.470242 - Acc: 86.8796 | last_lr: 3.12500e-05  bad_ep: 3  cdwn: 0                              \n",
      " 21:10:54 | Ep: 349/ 600 | Trn loss:  0.227916 - Acc: 91.4076 | Val loss:  0.470349 - Acc: 86.8657 | last_lr: 3.12500e-05  bad_ep: 4  cdwn: 0                              \n",
      " 21:11:07 | Ep: 350/ 600 | Trn loss:  0.227690 - Acc: 91.4156 | Val loss:  0.470460 - Acc: 86.8704 | last_lr: 3.12500e-05  bad_ep: 5  cdwn: 0                              \n",
      " 21:11:20 | Ep: 351/ 600 | Trn loss:  0.227468 - Acc: 91.4235 | Val loss:  0.470578 - Acc: 86.8611 | last_lr: 3.12500e-05  bad_ep: 6  cdwn: 0                              \n",
      " 21:11:33 | Ep: 352/ 600 | Trn loss:  0.227248 - Acc: 91.4293 | Val loss:  0.470699 - Acc: 86.8657 | last_lr: 3.12500e-05  bad_ep: 7  cdwn: 0                              \n",
      " 21:11:46 | Ep: 353/ 600 | Trn loss:  0.227032 - Acc: 91.4380 | Val loss:  0.470832 - Acc: 86.8704 | last_lr: 3.12500e-05  bad_ep: 8  cdwn: 0                              \n",
      " 21:11:59 | Ep: 354/ 600 | Trn loss:  0.226819 - Acc: 91.4434 | Val loss:  0.470964 - Acc: 86.8611 | last_lr: 3.12500e-05  bad_ep: 9  cdwn: 0                              \n",
      " 21:12:12 | Ep: 355/ 600 | Trn loss:  0.226608 - Acc: 91.4524 | Val loss:  0.471100 - Acc: 86.8519 | last_lr: 3.12500e-05  bad_ep: 10  cdwn: 0                             \n",
      " 21:12:25 | Ep: 356/ 600 | Trn loss:  0.226400 - Acc: 91.4578 | Val loss:  0.471240 - Acc: 86.8611 | last_lr: 3.12500e-05  bad_ep: 11  cdwn: 0                             \n",
      " 21:12:38 | Ep: 357/ 600 | Trn loss:  0.226193 - Acc: 91.4672 | Val loss:  0.471382 - Acc: 86.8519 | last_lr: 3.12500e-05  bad_ep: 12  cdwn: 0                             \n",
      " 21:12:51 | Ep: 358/ 600 | Trn loss:  0.225989 - Acc: 91.4737 | Val loss:  0.471532 - Acc: 86.8565 | last_lr: 3.12500e-05  bad_ep: 13  cdwn: 0                             \n",
      " 21:13:04 | Ep: 359/ 600 | Trn loss:  0.225787 - Acc: 91.4798 | Val loss:  0.471683 - Acc: 86.8611 | last_lr: 3.12500e-05  bad_ep: 14  cdwn: 0                             \n",
      " 21:13:16 | Ep: 360/ 600 | Trn loss:  0.225587 - Acc: 91.4856 | Val loss:  0.471835 - Acc: 86.8565 | last_lr: 3.12500e-05  bad_ep: 15  cdwn: 0                             \n",
      " 21:13:29 | Ep: 361/ 600 | Trn loss:  0.225389 - Acc: 91.4939 | Val loss:  0.471990 - Acc: 86.8472 | last_lr: 3.12500e-05  bad_ep: 16  cdwn: 0                             \n",
      " 21:13:43 | Ep: 362/ 600 | Trn loss:  0.225192 - Acc: 91.4993 | Val loss:  0.472147 - Acc: 86.8565 | last_lr: 3.12500e-05  bad_ep: 17  cdwn: 0                             \n",
      " 21:13:56 | Ep: 363/ 600 | Trn loss:  0.224997 - Acc: 91.5101 | Val loss:  0.472307 - Acc: 86.8472 | last_lr: 3.12500e-05  bad_ep: 18  cdwn: 0                             \n",
      " 21:14:09 | Ep: 364/ 600 | Trn loss:  0.224803 - Acc: 91.5166 | Val loss:  0.472472 - Acc: 86.8472 | last_lr: 3.12500e-05  bad_ep: 19  cdwn: 0                             \n",
      " 21:14:22 | Ep: 365/ 600 | Trn loss:  0.224611 - Acc: 91.5242 | Val loss:  0.472634 - Acc: 86.8519 | last_lr: 3.12500e-05  bad_ep: 20  cdwn: 0                             \n",
      " 21:14:35 | Ep: 366/ 600 | Trn loss:  0.224420 - Acc: 91.5321 | Val loss:  0.472802 - Acc: 86.8472 | last_lr: 3.12500e-05  bad_ep: 21  cdwn: 0                             \n",
      " 21:14:48 | Ep: 367/ 600 | Trn loss:  0.224230 - Acc: 91.5458 | Val loss:  0.472968 - Acc: 86.8472 | last_lr: 3.12500e-05  bad_ep: 22  cdwn: 0                             \n",
      " 21:15:01 | Ep: 368/ 600 | Trn loss:  0.224042 - Acc: 91.5527 | Val loss:  0.473136 - Acc: 86.8426 | last_lr: 3.12500e-05  bad_ep: 23  cdwn: 0                             \n",
      " 21:15:14 | Ep: 369/ 600 | Trn loss:  0.223855 - Acc: 91.5631 | Val loss:  0.473308 - Acc: 86.8333 | last_lr: 3.12500e-05  bad_ep: 24  cdwn: 0                             \n",
      " 21:15:27 | Ep: 370/ 600 | Trn loss:  0.223669 - Acc: 91.5693 | Val loss:  0.473481 - Acc: 86.8333 | last_lr: 3.12500e-05  bad_ep: 25  cdwn: 0                             \n",
      " 21:15:40 | Ep: 371/ 600 | Trn loss:  0.223484 - Acc: 91.5761 | Val loss:  0.473652 - Acc: 86.8333 | last_lr: 3.12500e-05  bad_ep: 26  cdwn: 0                             \n",
      " 21:15:53 | Ep: 372/ 600 | Trn loss:  0.223300 - Acc: 91.5837 | Val loss:  0.473829 - Acc: 86.8287 | last_lr: 3.12500e-05  bad_ep: 27  cdwn: 0                             \n",
      " 21:16:06 | Ep: 373/ 600 | Trn loss:  0.223117 - Acc: 91.5924 | Val loss:  0.474004 - Acc: 86.8148 | last_lr: 3.12500e-05  bad_ep: 28  cdwn: 0                             \n",
      " 21:16:19 | Ep: 374/ 600 | Trn loss:  0.222935 - Acc: 91.5967 | Val loss:  0.474182 - Acc: 86.8148 | last_lr: 3.12500e-05  bad_ep: 29  cdwn: 0                             \n",
      " 21:16:32 | Ep: 375/ 600 | Trn loss:  0.222753 - Acc: 91.6079 | Val loss:  0.474360 - Acc: 86.8056 | last_lr: 3.12500e-05  bad_ep: 30  cdwn: 0                             \n",
      " 21:16:45 | Ep: 376/ 600 | Trn loss:  0.222573 - Acc: 91.6176 | Val loss:  0.474543 - Acc: 86.8102 | last_lr: 3.12500e-05  bad_ep: 31  cdwn: 0                             \n",
      " 21:16:58 | Ep: 377/ 600 | Trn loss:  0.222393 - Acc: 91.6255 | Val loss:  0.474724 - Acc: 86.8009 | last_lr: 3.12500e-05  bad_ep: 32  cdwn: 0                             \n",
      " 21:17:11 | Ep: 378/ 600 | Trn loss:  0.222215 - Acc: 91.6367 | Val loss:  0.474906 - Acc: 86.7963 | last_lr: 3.12500e-05  bad_ep: 33  cdwn: 0                             \n",
      " 21:17:24 | Ep: 379/ 600 | Trn loss:  0.222037 - Acc: 91.6472 | Val loss:  0.475089 - Acc: 86.7870 | last_lr: 3.12500e-05  bad_ep: 34  cdwn: 0                             \n",
      " 21:17:37 | Ep: 380/ 600 | Trn loss:  0.221859 - Acc: 91.6551 | Val loss:  0.475272 - Acc: 86.7917 | last_lr: 3.12500e-05  bad_ep: 35  cdwn: 0                             \n",
      " 21:17:50 | Ep: 381/ 600 | Trn loss:  0.221683 - Acc: 91.6634 | Val loss:  0.475459 - Acc: 86.7870 | last_lr: 3.12500e-05  bad_ep: 36  cdwn: 0                             \n",
      " 21:18:03 | Ep: 382/ 600 | Trn loss:  0.221507 - Acc: 91.6692 | Val loss:  0.475642 - Acc: 86.7870 | last_lr: 3.12500e-05  bad_ep: 37  cdwn: 0                             \n",
      " 21:18:16 | Ep: 383/ 600 | Trn loss:  0.221332 - Acc: 91.6746 | Val loss:  0.475829 - Acc: 86.7778 | last_lr: 3.12500e-05  bad_ep: 38  cdwn: 0                             \n",
      " 21:18:29 | Ep: 384/ 600 | Trn loss:  0.221157 - Acc: 91.6786 | Val loss:  0.476018 - Acc: 86.7778 | last_lr: 3.12500e-05  bad_ep: 39  cdwn: 0                             \n",
      " 21:18:42 | Ep: 385/ 600 | Trn loss:  0.220983 - Acc: 91.6865 | Val loss:  0.476206 - Acc: 86.7685 | last_lr: 3.12500e-05  bad_ep: 40  cdwn: 0                             \n",
      " 21:18:55 | Ep: 386/ 600 | Trn loss:  0.220809 - Acc: 91.6937 | Val loss:  0.476395 - Acc: 86.7685 | last_lr: 3.12500e-05  bad_ep: 41  cdwn: 0                             \n",
      " 21:19:09 | Ep: 387/ 600 | Trn loss:  0.220637 - Acc: 91.6948 | Val loss:  0.476584 - Acc: 86.7778 | last_lr: 3.12500e-05  bad_ep: 42  cdwn: 0                             \n",
      " 21:19:22 | Ep: 388/ 600 | Trn loss:  0.220464 - Acc: 91.7020 | Val loss:  0.476778 - Acc: 86.7824 | last_lr: 3.12500e-05  bad_ep: 43  cdwn: 0                             \n",
      " 21:19:35 | Ep: 389/ 600 | Trn loss:  0.220292 - Acc: 91.7092 | Val loss:  0.476968 - Acc: 86.7824 | last_lr: 3.12500e-05  bad_ep: 44  cdwn: 0                             \n",
      " 21:19:48 | Ep: 390/ 600 | Trn loss:  0.220121 - Acc: 91.7179 | Val loss:  0.477162 - Acc: 86.7778 | last_lr: 3.12500e-05  bad_ep: 45  cdwn: 0                             \n",
      " 21:20:01 | Ep: 391/ 600 | Trn loss:  0.219950 - Acc: 91.7237 | Val loss:  0.477354 - Acc: 86.7824 | last_lr: 3.12500e-05  bad_ep: 46  cdwn: 0                             \n",
      " 21:20:14 | Ep: 392/ 600 | Trn loss:  0.219780 - Acc: 91.7269 | Val loss:  0.477548 - Acc: 86.7870 | last_lr: 3.12500e-05  bad_ep: 47  cdwn: 0                             \n",
      " 21:20:27 | Ep: 393/ 600 | Trn loss:  0.219610 - Acc: 91.7327 | Val loss:  0.477742 - Acc: 86.7870 | last_lr: 3.12500e-05  bad_ep: 48  cdwn: 0                             \n",
      " 21:20:40 | Ep: 394/ 600 | Trn loss:  0.219440 - Acc: 91.7406 | Val loss:  0.477939 - Acc: 86.7824 | last_lr: 3.12500e-05  bad_ep: 49  cdwn: 0                             \n",
      " 21:20:53 | Ep: 395/ 600 | Trn loss:  0.219271 - Acc: 91.7464 | Val loss:  0.478137 - Acc: 86.7731 | last_lr: 3.12500e-05  bad_ep: 50  cdwn: 0                             \n",
      " 21:21:07 | Ep: 396/ 600 | Trn loss:  0.219103 - Acc: 91.7532 | Val loss:  0.478332 - Acc: 86.7731 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 10                             \n",
      " 21:21:20 | Ep: 397/ 600 | Trn loss:  0.221488 - Acc: 91.6443 | Val loss:  0.476622 - Acc: 86.7778 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 9                              \n",
      " 21:21:33 | Ep: 398/ 600 | Trn loss:  0.220639 - Acc: 91.6851 | Val loss:  0.476607 - Acc: 86.7639 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 8                              \n",
      " 21:21:46 | Ep: 399/ 600 | Trn loss:  0.220378 - Acc: 91.6919 | Val loss:  0.476663 - Acc: 86.7361 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 7                              \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:21:59,568 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_400.pt - epoch: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21:21:59 | Ep: 400/ 600 | Trn loss:  0.220179 - Acc: 91.7049 | Val loss:  0.476747 - Acc: 86.7315 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 6 \n",
      " 21:22:12 | Ep: 401/ 600 | Trn loss:  0.220003 - Acc: 91.7157 | Val loss:  0.476843 - Acc: 86.7407 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 5                              \n",
      " 21:22:25 | Ep: 402/ 600 | Trn loss:  0.219841 - Acc: 91.7255 | Val loss:  0.476943 - Acc: 86.7454 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 4                              \n",
      " 21:22:38 | Ep: 403/ 600 | Trn loss:  0.219688 - Acc: 91.7334 | Val loss:  0.477049 - Acc: 86.7315 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 3                              \n",
      " 21:22:51 | Ep: 404/ 600 | Trn loss:  0.219543 - Acc: 91.7403 | Val loss:  0.477155 - Acc: 86.7269 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 2                              \n",
      " 21:23:04 | Ep: 405/ 600 | Trn loss:  0.219403 - Acc: 91.7435 | Val loss:  0.477262 - Acc: 86.7222 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 1                              \n",
      " 21:23:17 | Ep: 406/ 600 | Trn loss:  0.219268 - Acc: 91.7496 | Val loss:  0.477371 - Acc: 86.7130 | last_lr: 1.56250e-05  bad_ep: 0  cdwn: 0                              \n",
      " 21:23:30 | Ep: 407/ 600 | Trn loss:  0.219136 - Acc: 91.7554 | Val loss:  0.477481 - Acc: 86.7130 | last_lr: 1.56250e-05  bad_ep: 1  cdwn: 0                              \n",
      " 21:23:43 | Ep: 408/ 600 | Trn loss:  0.219008 - Acc: 91.7583 | Val loss:  0.477590 - Acc: 86.7130 | last_lr: 1.56250e-05  bad_ep: 2  cdwn: 0                              \n",
      " 21:23:56 | Ep: 409/ 600 | Trn loss:  0.218883 - Acc: 91.7608 | Val loss:  0.477700 - Acc: 86.7037 | last_lr: 1.56250e-05  bad_ep: 3  cdwn: 0                              \n",
      " 21:24:09 | Ep: 410/ 600 | Trn loss:  0.218759 - Acc: 91.7659 | Val loss:  0.477810 - Acc: 86.7037 | last_lr: 1.56250e-05  bad_ep: 4  cdwn: 0                              \n",
      " 21:24:22 | Ep: 411/ 600 | Trn loss:  0.218638 - Acc: 91.7709 | Val loss:  0.477920 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 5  cdwn: 0                              \n",
      " 21:24:35 | Ep: 412/ 600 | Trn loss:  0.218519 - Acc: 91.7760 | Val loss:  0.478031 - Acc: 86.7037 | last_lr: 1.56250e-05  bad_ep: 6  cdwn: 0                              \n",
      " 21:24:48 | Ep: 413/ 600 | Trn loss:  0.218402 - Acc: 91.7807 | Val loss:  0.478140 - Acc: 86.6991 | last_lr: 1.56250e-05  bad_ep: 7  cdwn: 0                              \n",
      " 21:25:01 | Ep: 414/ 600 | Trn loss:  0.218287 - Acc: 91.7854 | Val loss:  0.478250 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 8  cdwn: 0                              \n",
      " 21:25:14 | Ep: 415/ 600 | Trn loss:  0.218172 - Acc: 91.7933 | Val loss:  0.478360 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 9  cdwn: 0                              \n",
      " 21:25:27 | Ep: 416/ 600 | Trn loss:  0.218059 - Acc: 91.7980 | Val loss:  0.478469 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 10  cdwn: 0                             \n",
      " 21:25:40 | Ep: 417/ 600 | Trn loss:  0.217948 - Acc: 91.8019 | Val loss:  0.478579 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 11  cdwn: 0                             \n",
      " 21:25:53 | Ep: 418/ 600 | Trn loss:  0.217837 - Acc: 91.8070 | Val loss:  0.478688 - Acc: 86.6944 | last_lr: 1.56250e-05  bad_ep: 12  cdwn: 0                             \n",
      " 21:26:06 | Ep: 419/ 600 | Trn loss:  0.217727 - Acc: 91.8135 | Val loss:  0.478798 - Acc: 86.6852 | last_lr: 1.56250e-05  bad_ep: 13  cdwn: 0                             \n",
      " 21:26:19 | Ep: 420/ 600 | Trn loss:  0.217619 - Acc: 91.8185 | Val loss:  0.478908 - Acc: 86.6759 | last_lr: 1.56250e-05  bad_ep: 14  cdwn: 0                             \n",
      " 21:26:32 | Ep: 421/ 600 | Trn loss:  0.217511 - Acc: 91.8222 | Val loss:  0.479017 - Acc: 86.6759 | last_lr: 1.56250e-05  bad_ep: 15  cdwn: 0                             \n",
      " 21:26:44 | Ep: 422/ 600 | Trn loss:  0.217404 - Acc: 91.8254 | Val loss:  0.479126 - Acc: 86.6759 | last_lr: 1.56250e-05  bad_ep: 16  cdwn: 0                             \n",
      " 21:26:57 | Ep: 423/ 600 | Trn loss:  0.217298 - Acc: 91.8279 | Val loss:  0.479237 - Acc: 86.6713 | last_lr: 1.56250e-05  bad_ep: 17  cdwn: 0                             \n",
      " 21:27:10 | Ep: 424/ 600 | Trn loss:  0.217193 - Acc: 91.8341 | Val loss:  0.479345 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 18  cdwn: 0                             \n",
      " 21:27:23 | Ep: 425/ 600 | Trn loss:  0.217088 - Acc: 91.8369 | Val loss:  0.479456 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 19  cdwn: 0                             \n",
      " 21:27:36 | Ep: 426/ 600 | Trn loss:  0.216984 - Acc: 91.8391 | Val loss:  0.479565 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 20  cdwn: 0                             \n",
      " 21:27:49 | Ep: 427/ 600 | Trn loss:  0.216881 - Acc: 91.8474 | Val loss:  0.479674 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 21  cdwn: 0                             \n",
      " 21:28:02 | Ep: 428/ 600 | Trn loss:  0.216778 - Acc: 91.8506 | Val loss:  0.479783 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 22  cdwn: 0                             \n",
      " 21:28:15 | Ep: 429/ 600 | Trn loss:  0.216676 - Acc: 91.8582 | Val loss:  0.479893 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 23  cdwn: 0                             \n",
      " 21:28:28 | Ep: 430/ 600 | Trn loss:  0.216575 - Acc: 91.8633 | Val loss:  0.480003 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 24  cdwn: 0                             \n",
      " 21:28:41 | Ep: 431/ 600 | Trn loss:  0.216473 - Acc: 91.8665 | Val loss:  0.480112 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 25  cdwn: 0                             \n",
      " 21:28:54 | Ep: 432/ 600 | Trn loss:  0.216373 - Acc: 91.8712 | Val loss:  0.480222 - Acc: 86.6574 | last_lr: 1.56250e-05  bad_ep: 26  cdwn: 0                             \n",
      " 21:29:07 | Ep: 433/ 600 | Trn loss:  0.216273 - Acc: 91.8745 | Val loss:  0.480330 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 27  cdwn: 0                             \n",
      " 21:29:20 | Ep: 434/ 600 | Trn loss:  0.216173 - Acc: 91.8791 | Val loss:  0.480440 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 28  cdwn: 0                             \n",
      " 21:29:33 | Ep: 435/ 600 | Trn loss:  0.216074 - Acc: 91.8838 | Val loss:  0.480549 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 29  cdwn: 0                             \n",
      " 21:29:46 | Ep: 436/ 600 | Trn loss:  0.215975 - Acc: 91.8878 | Val loss:  0.480660 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 30  cdwn: 0                             \n",
      " 21:29:58 | Ep: 437/ 600 | Trn loss:  0.215877 - Acc: 91.8929 | Val loss:  0.480768 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 31  cdwn: 0                             \n",
      " 21:30:12 | Ep: 438/ 600 | Trn loss:  0.215779 - Acc: 91.8968 | Val loss:  0.480879 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 32  cdwn: 0                             \n",
      " 21:30:25 | Ep: 439/ 600 | Trn loss:  0.215682 - Acc: 91.9026 | Val loss:  0.480988 - Acc: 86.6667 | last_lr: 1.56250e-05  bad_ep: 33  cdwn: 0                             \n",
      " 21:30:38 | Ep: 440/ 600 | Trn loss:  0.215584 - Acc: 91.9069 | Val loss:  0.481097 - Acc: 86.6713 | last_lr: 1.56250e-05  bad_ep: 34  cdwn: 0                             \n",
      " 21:30:51 | Ep: 441/ 600 | Trn loss:  0.215487 - Acc: 91.9102 | Val loss:  0.481207 - Acc: 86.6713 | last_lr: 1.56250e-05  bad_ep: 35  cdwn: 0                             \n",
      " 21:31:04 | Ep: 442/ 600 | Trn loss:  0.215391 - Acc: 91.9141 | Val loss:  0.481317 - Acc: 86.6759 | last_lr: 1.56250e-05  bad_ep: 36  cdwn: 0                             \n",
      " 21:31:16 | Ep: 443/ 600 | Trn loss:  0.215295 - Acc: 91.9188 | Val loss:  0.481428 - Acc: 86.6759 | last_lr: 1.56250e-05  bad_ep: 37  cdwn: 0                             \n",
      " 21:31:29 | Ep: 444/ 600 | Trn loss:  0.215199 - Acc: 91.9206 | Val loss:  0.481536 - Acc: 86.6713 | last_lr: 1.56250e-05  bad_ep: 38  cdwn: 0                             \n",
      " 21:31:42 | Ep: 445/ 600 | Trn loss:  0.215103 - Acc: 91.9264 | Val loss:  0.481647 - Acc: 86.6620 | last_lr: 1.56250e-05  bad_ep: 39  cdwn: 0                             \n",
      " 21:31:55 | Ep: 446/ 600 | Trn loss:  0.215008 - Acc: 91.9300 | Val loss:  0.481757 - Acc: 86.6528 | last_lr: 1.56250e-05  bad_ep: 40  cdwn: 0                             \n",
      " 21:32:09 | Ep: 447/ 600 | Trn loss:  0.214913 - Acc: 91.9347 | Val loss:  0.481866 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 41  cdwn: 0                             \n",
      " 21:32:22 | Ep: 448/ 600 | Trn loss:  0.214818 - Acc: 91.9361 | Val loss:  0.481978 - Acc: 86.6389 | last_lr: 1.56250e-05  bad_ep: 42  cdwn: 0                             \n",
      " 21:32:35 | Ep: 449/ 600 | Trn loss:  0.214724 - Acc: 91.9383 | Val loss:  0.482088 - Acc: 86.6343 | last_lr: 1.56250e-05  bad_ep: 43  cdwn: 0                             \n",
      " 21:32:48 | Ep: 450/ 600 | Trn loss:  0.214629 - Acc: 91.9430 | Val loss:  0.482197 - Acc: 86.6343 | last_lr: 1.56250e-05  bad_ep: 44  cdwn: 0                             \n",
      " 21:33:01 | Ep: 451/ 600 | Trn loss:  0.214535 - Acc: 91.9459 | Val loss:  0.482307 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 45  cdwn: 0                             \n",
      " 21:33:14 | Ep: 452/ 600 | Trn loss:  0.214442 - Acc: 91.9506 | Val loss:  0.482417 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 46  cdwn: 0                             \n",
      " 21:33:27 | Ep: 453/ 600 | Trn loss:  0.214348 - Acc: 91.9531 | Val loss:  0.482529 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 47  cdwn: 0                             \n",
      " 21:33:41 | Ep: 454/ 600 | Trn loss:  0.214255 - Acc: 91.9560 | Val loss:  0.482639 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 48  cdwn: 0                             \n",
      " 21:33:54 | Ep: 455/ 600 | Trn loss:  0.214162 - Acc: 91.9596 | Val loss:  0.482749 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 49  cdwn: 0                             \n",
      " 21:34:07 | Ep: 456/ 600 | Trn loss:  0.214069 - Acc: 91.9643 | Val loss:  0.482859 - Acc: 86.6435 | last_lr: 1.56250e-05  bad_ep: 50  cdwn: 0                             \n",
      " 21:34:20 | Ep: 457/ 600 | Trn loss:  0.213977 - Acc: 91.9683 | Val loss:  0.482970 - Acc: 86.6389 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 10                             \n",
      " 21:34:33 | Ep: 458/ 600 | Trn loss:  0.214821 - Acc: 91.8943 | Val loss:  0.482186 - Acc: 86.5417 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 9                              \n",
      " 21:34:46 | Ep: 459/ 600 | Trn loss:  0.214173 - Acc: 91.9300 | Val loss:  0.482256 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 8                              \n",
      " 21:35:00 | Ep: 460/ 600 | Trn loss:  0.214044 - Acc: 91.9340 | Val loss:  0.482321 - Acc: 86.5324 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 7                              \n",
      " 21:35:13 | Ep: 461/ 600 | Trn loss:  0.213957 - Acc: 91.9358 | Val loss:  0.482387 - Acc: 86.5324 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 6                              \n",
      " 21:35:26 | Ep: 462/ 600 | Trn loss:  0.213880 - Acc: 91.9376 | Val loss:  0.482454 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 5                              \n",
      " 21:35:39 | Ep: 463/ 600 | Trn loss:  0.213808 - Acc: 91.9430 | Val loss:  0.482522 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 4                              \n",
      " 21:35:52 | Ep: 464/ 600 | Trn loss:  0.213739 - Acc: 91.9466 | Val loss:  0.482591 - Acc: 86.5278 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 3                              \n",
      " 21:36:05 | Ep: 465/ 600 | Trn loss:  0.213673 - Acc: 91.9495 | Val loss:  0.482659 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 2                              \n",
      " 21:36:19 | Ep: 466/ 600 | Trn loss:  0.213608 - Acc: 91.9517 | Val loss:  0.482729 - Acc: 86.5139 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 1                              \n",
      " 21:36:32 | Ep: 467/ 600 | Trn loss:  0.213545 - Acc: 91.9531 | Val loss:  0.482797 - Acc: 86.5185 | last_lr: 7.81250e-06  bad_ep: 0  cdwn: 0                              \n",
      " 21:36:45 | Ep: 468/ 600 | Trn loss:  0.213483 - Acc: 91.9556 | Val loss:  0.482866 - Acc: 86.5093 | last_lr: 7.81250e-06  bad_ep: 1  cdwn: 0                              \n",
      " 21:36:58 | Ep: 469/ 600 | Trn loss:  0.213422 - Acc: 91.9596 | Val loss:  0.482933 - Acc: 86.5093 | last_lr: 7.81250e-06  bad_ep: 2  cdwn: 0                              \n",
      " 21:37:12 | Ep: 470/ 600 | Trn loss:  0.213362 - Acc: 91.9610 | Val loss:  0.483001 - Acc: 86.5185 | last_lr: 7.81250e-06  bad_ep: 3  cdwn: 0                              \n",
      " 21:37:25 | Ep: 471/ 600 | Trn loss:  0.213303 - Acc: 91.9654 | Val loss:  0.483068 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 4  cdwn: 0                              \n",
      " 21:37:38 | Ep: 472/ 600 | Trn loss:  0.213244 - Acc: 91.9697 | Val loss:  0.483134 - Acc: 86.5185 | last_lr: 7.81250e-06  bad_ep: 5  cdwn: 0                              \n",
      " 21:37:51 | Ep: 473/ 600 | Trn loss:  0.213186 - Acc: 91.9726 | Val loss:  0.483201 - Acc: 86.5231 | last_lr: 7.81250e-06  bad_ep: 6  cdwn: 0                              \n",
      " 21:38:05 | Ep: 474/ 600 | Trn loss:  0.213129 - Acc: 91.9747 | Val loss:  0.483266 - Acc: 86.5139 | last_lr: 7.81250e-06  bad_ep: 7  cdwn: 0                              \n",
      " 21:38:18 | Ep: 475/ 600 | Trn loss:  0.213072 - Acc: 91.9787 | Val loss:  0.483331 - Acc: 86.5093 | last_lr: 7.81250e-06  bad_ep: 8  cdwn: 0                              \n",
      " 21:38:31 | Ep: 476/ 600 | Trn loss:  0.213016 - Acc: 91.9805 | Val loss:  0.483396 - Acc: 86.5093 | last_lr: 7.81250e-06  bad_ep: 9  cdwn: 0                              \n",
      " 21:38:45 | Ep: 477/ 600 | Trn loss:  0.212960 - Acc: 91.9830 | Val loss:  0.483460 - Acc: 86.5093 | last_lr: 7.81250e-06  bad_ep: 10  cdwn: 0                             \n",
      " 21:38:58 | Ep: 478/ 600 | Trn loss:  0.212904 - Acc: 91.9852 | Val loss:  0.483525 - Acc: 86.5046 | last_lr: 7.81250e-06  bad_ep: 11  cdwn: 0                             \n",
      " 21:39:11 | Ep: 479/ 600 | Trn loss:  0.212849 - Acc: 91.9885 | Val loss:  0.483588 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 12  cdwn: 0                             \n",
      " 21:39:24 | Ep: 480/ 600 | Trn loss:  0.212795 - Acc: 91.9935 | Val loss:  0.483651 - Acc: 86.5046 | last_lr: 7.81250e-06  bad_ep: 13  cdwn: 0                             \n",
      " 21:39:38 | Ep: 481/ 600 | Trn loss:  0.212740 - Acc: 91.9975 | Val loss:  0.483714 - Acc: 86.5046 | last_lr: 7.81250e-06  bad_ep: 14  cdwn: 0                             \n",
      " 21:39:51 | Ep: 482/ 600 | Trn loss:  0.212686 - Acc: 92.0004 | Val loss:  0.483777 - Acc: 86.4954 | last_lr: 7.81250e-06  bad_ep: 15  cdwn: 0                             \n",
      " 21:40:04 | Ep: 483/ 600 | Trn loss:  0.212633 - Acc: 92.0025 | Val loss:  0.483840 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 16  cdwn: 0                             \n",
      " 21:40:17 | Ep: 484/ 600 | Trn loss:  0.212579 - Acc: 92.0061 | Val loss:  0.483902 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 17  cdwn: 0                             \n",
      " 21:40:31 | Ep: 485/ 600 | Trn loss:  0.212526 - Acc: 92.0094 | Val loss:  0.483964 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 18  cdwn: 0                             \n",
      " 21:40:44 | Ep: 486/ 600 | Trn loss:  0.212473 - Acc: 92.0137 | Val loss:  0.484026 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 19  cdwn: 0                             \n",
      " 21:40:57 | Ep: 487/ 600 | Trn loss:  0.212421 - Acc: 92.0162 | Val loss:  0.484088 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 20  cdwn: 0                             \n",
      " 21:41:10 | Ep: 488/ 600 | Trn loss:  0.212368 - Acc: 92.0195 | Val loss:  0.484149 - Acc: 86.5000 | last_lr: 7.81250e-06  bad_ep: 21  cdwn: 0                             \n",
      " 21:41:23 | Ep: 489/ 600 | Trn loss:  0.212316 - Acc: 92.0191 | Val loss:  0.484211 - Acc: 86.4954 | last_lr: 7.81250e-06  bad_ep: 22  cdwn: 0                             \n",
      " 21:41:36 | Ep: 490/ 600 | Trn loss:  0.212264 - Acc: 92.0202 | Val loss:  0.484272 - Acc: 86.4907 | last_lr: 7.81250e-06  bad_ep: 23  cdwn: 0                             \n",
      " 21:41:50 | Ep: 491/ 600 | Trn loss:  0.212212 - Acc: 92.0231 | Val loss:  0.484333 - Acc: 86.4907 | last_lr: 7.81250e-06  bad_ep: 24  cdwn: 0                             \n",
      " 21:42:03 | Ep: 492/ 600 | Trn loss:  0.212161 - Acc: 92.0242 | Val loss:  0.484394 - Acc: 86.4907 | last_lr: 7.81250e-06  bad_ep: 25  cdwn: 0                             \n",
      " 21:42:16 | Ep: 493/ 600 | Trn loss:  0.212110 - Acc: 92.0271 | Val loss:  0.484455 - Acc: 86.4954 | last_lr: 7.81250e-06  bad_ep: 26  cdwn: 0                             \n",
      " 21:42:29 | Ep: 494/ 600 | Trn loss:  0.212058 - Acc: 92.0321 | Val loss:  0.484515 - Acc: 86.4861 | last_lr: 7.81250e-06  bad_ep: 27  cdwn: 0                             \n",
      " 21:42:43 | Ep: 495/ 600 | Trn loss:  0.212007 - Acc: 92.0346 | Val loss:  0.484577 - Acc: 86.4861 | last_lr: 7.81250e-06  bad_ep: 28  cdwn: 0                             \n",
      " 21:42:56 | Ep: 496/ 600 | Trn loss:  0.211956 - Acc: 92.0400 | Val loss:  0.484637 - Acc: 86.4861 | last_lr: 7.81250e-06  bad_ep: 29  cdwn: 0                             \n",
      " 21:43:09 | Ep: 497/ 600 | Trn loss:  0.211906 - Acc: 92.0426 | Val loss:  0.484697 - Acc: 86.4954 | last_lr: 7.81250e-06  bad_ep: 30  cdwn: 0                             \n",
      " 21:43:22 | Ep: 498/ 600 | Trn loss:  0.211855 - Acc: 92.0437 | Val loss:  0.484758 - Acc: 86.4907 | last_lr: 7.81250e-06  bad_ep: 31  cdwn: 0                             \n",
      " 21:43:36 | Ep: 499/ 600 | Trn loss:  0.211805 - Acc: 92.0469 | Val loss:  0.484818 - Acc: 86.4861 | last_lr: 7.81250e-06  bad_ep: 32  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:43:49,429 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_500.pt - epoch: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21:43:49 | Ep: 500/ 600 | Trn loss:  0.211755 - Acc: 92.0501 | Val loss:  0.484878 - Acc: 86.4861 | last_lr: 7.81250e-06  bad_ep: 33  cdwn: 0 \n",
      " 21:44:02 | Ep: 501/ 600 | Trn loss:  0.211704 - Acc: 92.0512 | Val loss:  0.484939 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 34  cdwn: 0                             \n",
      " 21:44:15 | Ep: 502/ 600 | Trn loss:  0.211654 - Acc: 92.0519 | Val loss:  0.484999 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 35  cdwn: 0                             \n",
      " 21:44:29 | Ep: 503/ 600 | Trn loss:  0.211605 - Acc: 92.0548 | Val loss:  0.485059 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 36  cdwn: 0                             \n",
      " 21:44:42 | Ep: 504/ 600 | Trn loss:  0.211555 - Acc: 92.0566 | Val loss:  0.485119 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 37  cdwn: 0                             \n",
      " 21:44:55 | Ep: 505/ 600 | Trn loss:  0.211505 - Acc: 92.0581 | Val loss:  0.485179 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 38  cdwn: 0                             \n",
      " 21:45:08 | Ep: 506/ 600 | Trn loss:  0.211456 - Acc: 92.0592 | Val loss:  0.485239 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 39  cdwn: 0                             \n",
      " 21:45:22 | Ep: 507/ 600 | Trn loss:  0.211406 - Acc: 92.0610 | Val loss:  0.485299 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 40  cdwn: 0                             \n",
      " 21:45:35 | Ep: 508/ 600 | Trn loss:  0.211357 - Acc: 92.0631 | Val loss:  0.485359 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 41  cdwn: 0                             \n",
      " 21:45:48 | Ep: 509/ 600 | Trn loss:  0.211308 - Acc: 92.0671 | Val loss:  0.485419 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 42  cdwn: 0                             \n",
      " 21:46:02 | Ep: 510/ 600 | Trn loss:  0.211259 - Acc: 92.0693 | Val loss:  0.485479 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 43  cdwn: 0                             \n",
      " 21:46:15 | Ep: 511/ 600 | Trn loss:  0.211210 - Acc: 92.0707 | Val loss:  0.485539 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 44  cdwn: 0                             \n",
      " 21:46:28 | Ep: 512/ 600 | Trn loss:  0.211161 - Acc: 92.0718 | Val loss:  0.485598 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 45  cdwn: 0                             \n",
      " 21:46:41 | Ep: 513/ 600 | Trn loss:  0.211112 - Acc: 92.0747 | Val loss:  0.485659 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 46  cdwn: 0                             \n",
      " 21:46:54 | Ep: 514/ 600 | Trn loss:  0.211064 - Acc: 92.0750 | Val loss:  0.485718 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 47  cdwn: 0                             \n",
      " 21:47:07 | Ep: 515/ 600 | Trn loss:  0.211015 - Acc: 92.0754 | Val loss:  0.485778 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 48  cdwn: 0                             \n",
      " 21:47:21 | Ep: 516/ 600 | Trn loss:  0.210967 - Acc: 92.0783 | Val loss:  0.485838 - Acc: 86.4769 | last_lr: 7.81250e-06  bad_ep: 49  cdwn: 0                             \n",
      " 21:47:34 | Ep: 517/ 600 | Trn loss:  0.210918 - Acc: 92.0804 | Val loss:  0.485898 - Acc: 86.4815 | last_lr: 7.81250e-06  bad_ep: 50  cdwn: 0                             \n",
      " 21:47:47 | Ep: 518/ 600 | Trn loss:  0.210870 - Acc: 92.0830 | Val loss:  0.485958 - Acc: 86.4815 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 10                             \n",
      " 21:48:00 | Ep: 519/ 600 | Trn loss:  0.210899 - Acc: 92.0469 | Val loss:  0.485403 - Acc: 86.4444 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 9                              \n",
      " 21:48:13 | Ep: 520/ 600 | Trn loss:  0.210501 - Acc: 92.0685 | Val loss:  0.485453 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 8                              \n",
      " 21:48:26 | Ep: 521/ 600 | Trn loss:  0.210423 - Acc: 92.0700 | Val loss:  0.485489 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 7                              \n",
      " 21:48:39 | Ep: 522/ 600 | Trn loss:  0.210377 - Acc: 92.0711 | Val loss:  0.485518 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 6                              \n",
      " 21:48:52 | Ep: 523/ 600 | Trn loss:  0.210340 - Acc: 92.0772 | Val loss:  0.485544 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 5                              \n",
      " 21:49:05 | Ep: 524/ 600 | Trn loss:  0.210307 - Acc: 92.0779 | Val loss:  0.485570 - Acc: 86.4398 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 4                              \n",
      " 21:49:19 | Ep: 525/ 600 | Trn loss:  0.210275 - Acc: 92.0779 | Val loss:  0.485596 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 3                              \n",
      " 21:49:32 | Ep: 526/ 600 | Trn loss:  0.210244 - Acc: 92.0797 | Val loss:  0.485622 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 2                              \n",
      " 21:49:45 | Ep: 527/ 600 | Trn loss:  0.210214 - Acc: 92.0790 | Val loss:  0.485649 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 1                              \n",
      " 21:49:58 | Ep: 528/ 600 | Trn loss:  0.210185 - Acc: 92.0797 | Val loss:  0.485676 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 0  cdwn: 0                              \n",
      " 21:50:11 | Ep: 529/ 600 | Trn loss:  0.210156 - Acc: 92.0819 | Val loss:  0.485703 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 1  cdwn: 0                              \n",
      " 21:50:24 | Ep: 530/ 600 | Trn loss:  0.210127 - Acc: 92.0837 | Val loss:  0.485731 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 2  cdwn: 0                              \n",
      " 21:50:37 | Ep: 531/ 600 | Trn loss:  0.210098 - Acc: 92.0859 | Val loss:  0.485760 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 3  cdwn: 0                              \n",
      " 21:50:51 | Ep: 532/ 600 | Trn loss:  0.210070 - Acc: 92.0873 | Val loss:  0.485788 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 4  cdwn: 0                              \n",
      " 21:51:04 | Ep: 533/ 600 | Trn loss:  0.210042 - Acc: 92.0887 | Val loss:  0.485817 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 5  cdwn: 0                              \n",
      " 21:51:17 | Ep: 534/ 600 | Trn loss:  0.210014 - Acc: 92.0895 | Val loss:  0.485846 - Acc: 86.4352 | last_lr: 3.90625e-06  bad_ep: 6  cdwn: 0                              \n",
      " 21:51:31 | Ep: 535/ 600 | Trn loss:  0.209987 - Acc: 92.0913 | Val loss:  0.485875 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 7  cdwn: 0                              \n",
      " 21:51:44 | Ep: 536/ 600 | Trn loss:  0.209959 - Acc: 92.0913 | Val loss:  0.485905 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 8  cdwn: 0                              \n",
      " 21:51:57 | Ep: 537/ 600 | Trn loss:  0.209932 - Acc: 92.0913 | Val loss:  0.485934 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 9  cdwn: 0                              \n",
      " 21:52:10 | Ep: 538/ 600 | Trn loss:  0.209905 - Acc: 92.0920 | Val loss:  0.485964 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 10  cdwn: 0                             \n",
      " 21:52:24 | Ep: 539/ 600 | Trn loss:  0.209878 - Acc: 92.0956 | Val loss:  0.485993 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 11  cdwn: 0                             \n",
      " 21:52:37 | Ep: 540/ 600 | Trn loss:  0.209851 - Acc: 92.0952 | Val loss:  0.486023 - Acc: 86.4306 | last_lr: 3.90625e-06  bad_ep: 12  cdwn: 0                             \n",
      " 21:52:50 | Ep: 541/ 600 | Trn loss:  0.209825 - Acc: 92.0963 | Val loss:  0.486053 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 13  cdwn: 0                             \n",
      " 21:53:03 | Ep: 542/ 600 | Trn loss:  0.209798 - Acc: 92.0992 | Val loss:  0.486083 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 14  cdwn: 0                             \n",
      " 21:53:17 | Ep: 543/ 600 | Trn loss:  0.209772 - Acc: 92.0999 | Val loss:  0.486113 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 15  cdwn: 0                             \n",
      " 21:53:30 | Ep: 544/ 600 | Trn loss:  0.209745 - Acc: 92.1010 | Val loss:  0.486144 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 16  cdwn: 0                             \n",
      " 21:53:43 | Ep: 545/ 600 | Trn loss:  0.209719 - Acc: 92.1028 | Val loss:  0.486173 - Acc: 86.4213 | last_lr: 3.90625e-06  bad_ep: 17  cdwn: 0                             \n",
      " 21:53:57 | Ep: 546/ 600 | Trn loss:  0.209693 - Acc: 92.1043 | Val loss:  0.486204 - Acc: 86.4213 | last_lr: 3.90625e-06  bad_ep: 18  cdwn: 0                             \n",
      " 21:54:10 | Ep: 547/ 600 | Trn loss:  0.209667 - Acc: 92.1043 | Val loss:  0.486234 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 19  cdwn: 0                             \n",
      " 21:54:23 | Ep: 548/ 600 | Trn loss:  0.209641 - Acc: 92.1050 | Val loss:  0.486264 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 20  cdwn: 0                             \n",
      " 21:54:36 | Ep: 549/ 600 | Trn loss:  0.209615 - Acc: 92.1061 | Val loss:  0.486294 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 21  cdwn: 0                             \n",
      " 21:54:50 | Ep: 550/ 600 | Trn loss:  0.209589 - Acc: 92.1068 | Val loss:  0.486324 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 22  cdwn: 0                             \n",
      " 21:55:03 | Ep: 551/ 600 | Trn loss:  0.209563 - Acc: 92.1075 | Val loss:  0.486355 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 23  cdwn: 0                             \n",
      " 21:55:16 | Ep: 552/ 600 | Trn loss:  0.209537 - Acc: 92.1093 | Val loss:  0.486385 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 24  cdwn: 0                             \n",
      " 21:55:30 | Ep: 553/ 600 | Trn loss:  0.209512 - Acc: 92.1100 | Val loss:  0.486415 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 25  cdwn: 0                             \n",
      " 21:55:43 | Ep: 554/ 600 | Trn loss:  0.209486 - Acc: 92.1111 | Val loss:  0.486445 - Acc: 86.4259 | last_lr: 3.90625e-06  bad_ep: 26  cdwn: 0                             \n",
      " 21:55:56 | Ep: 555/ 600 | Trn loss:  0.209461 - Acc: 92.1140 | Val loss:  0.486475 - Acc: 86.4213 | last_lr: 3.90625e-06  bad_ep: 27  cdwn: 0                             \n",
      " 21:56:10 | Ep: 556/ 600 | Trn loss:  0.209435 - Acc: 92.1147 | Val loss:  0.486506 - Acc: 86.4213 | last_lr: 3.90625e-06  bad_ep: 28  cdwn: 0                             \n",
      " 21:56:23 | Ep: 557/ 600 | Trn loss:  0.209410 - Acc: 92.1162 | Val loss:  0.486536 - Acc: 86.4213 | last_lr: 3.90625e-06  bad_ep: 29  cdwn: 0                             \n",
      " 21:56:36 | Ep: 558/ 600 | Trn loss:  0.209384 - Acc: 92.1172 | Val loss:  0.486566 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 30  cdwn: 0                             \n",
      " 21:56:49 | Ep: 559/ 600 | Trn loss:  0.209359 - Acc: 92.1190 | Val loss:  0.486596 - Acc: 86.4120 | last_lr: 3.90625e-06  bad_ep: 31  cdwn: 0                             \n",
      " 21:57:03 | Ep: 560/ 600 | Trn loss:  0.209334 - Acc: 92.1198 | Val loss:  0.486627 - Acc: 86.4120 | last_lr: 3.90625e-06  bad_ep: 32  cdwn: 0                             \n",
      " 21:57:16 | Ep: 561/ 600 | Trn loss:  0.209309 - Acc: 92.1216 | Val loss:  0.486657 - Acc: 86.4120 | last_lr: 3.90625e-06  bad_ep: 33  cdwn: 0                             \n",
      " 21:57:29 | Ep: 562/ 600 | Trn loss:  0.209284 - Acc: 92.1227 | Val loss:  0.486687 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 34  cdwn: 0                             \n",
      " 21:57:42 | Ep: 563/ 600 | Trn loss:  0.209259 - Acc: 92.1248 | Val loss:  0.486718 - Acc: 86.4167 | last_lr: 3.90625e-06  bad_ep: 35  cdwn: 0                             \n",
      " 21:57:56 | Ep: 564/ 600 | Trn loss:  0.209233 - Acc: 92.1263 | Val loss:  0.486748 - Acc: 86.4120 | last_lr: 3.90625e-06  bad_ep: 36  cdwn: 0                             \n",
      " 21:58:09 | Ep: 565/ 600 | Trn loss:  0.209209 - Acc: 92.1284 | Val loss:  0.486778 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 37  cdwn: 0                             \n",
      " 21:58:22 | Ep: 566/ 600 | Trn loss:  0.209184 - Acc: 92.1306 | Val loss:  0.486808 - Acc: 86.4074 | last_lr: 3.90625e-06  bad_ep: 38  cdwn: 0                             \n",
      " 21:58:35 | Ep: 567/ 600 | Trn loss:  0.209159 - Acc: 92.1310 | Val loss:  0.486839 - Acc: 86.4074 | last_lr: 3.90625e-06  bad_ep: 39  cdwn: 0                             \n",
      " 21:58:48 | Ep: 568/ 600 | Trn loss:  0.209134 - Acc: 92.1313 | Val loss:  0.486869 - Acc: 86.4074 | last_lr: 3.90625e-06  bad_ep: 40  cdwn: 0                             \n",
      " 21:59:01 | Ep: 569/ 600 | Trn loss:  0.209109 - Acc: 92.1317 | Val loss:  0.486899 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 41  cdwn: 0                             \n",
      " 21:59:14 | Ep: 570/ 600 | Trn loss:  0.209084 - Acc: 92.1328 | Val loss:  0.486930 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 42  cdwn: 0                             \n",
      " 21:59:27 | Ep: 571/ 600 | Trn loss:  0.209060 - Acc: 92.1342 | Val loss:  0.486960 - Acc: 86.3981 | last_lr: 3.90625e-06  bad_ep: 43  cdwn: 0                             \n",
      " 21:59:41 | Ep: 572/ 600 | Trn loss:  0.209035 - Acc: 92.1353 | Val loss:  0.486990 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 44  cdwn: 0                             \n",
      " 21:59:54 | Ep: 573/ 600 | Trn loss:  0.209010 - Acc: 92.1367 | Val loss:  0.487020 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 45  cdwn: 0                             \n",
      " 22:00:07 | Ep: 574/ 600 | Trn loss:  0.208986 - Acc: 92.1364 | Val loss:  0.487050 - Acc: 86.4028 | last_lr: 3.90625e-06  bad_ep: 46  cdwn: 0                             \n",
      " 22:00:20 | Ep: 575/ 600 | Trn loss:  0.208961 - Acc: 92.1371 | Val loss:  0.487081 - Acc: 86.3889 | last_lr: 3.90625e-06  bad_ep: 47  cdwn: 0                             \n",
      " 22:00:33 | Ep: 576/ 600 | Trn loss:  0.208937 - Acc: 92.1367 | Val loss:  0.487111 - Acc: 86.3889 | last_lr: 3.90625e-06  bad_ep: 48  cdwn: 0                             \n",
      " 22:00:46 | Ep: 577/ 600 | Trn loss:  0.208912 - Acc: 92.1382 | Val loss:  0.487141 - Acc: 86.3889 | last_lr: 3.90625e-06  bad_ep: 49  cdwn: 0                             \n",
      " 22:00:59 | Ep: 578/ 600 | Trn loss:  0.208888 - Acc: 92.1392 | Val loss:  0.487171 - Acc: 86.3889 | last_lr: 3.90625e-06  bad_ep: 50  cdwn: 0                             \n",
      " 22:01:12 | Ep: 579/ 600 | Trn loss:  0.208863 - Acc: 92.1403 | Val loss:  0.487202 - Acc: 86.3889 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 10                             \n",
      " 22:01:26 | Ep: 580/ 600 | Trn loss:  0.208578 - Acc: 92.1558 | Val loss:  0.486826 - Acc: 86.3796 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 9                              \n",
      " 22:01:39 | Ep: 581/ 600 | Trn loss:  0.208409 - Acc: 92.1537 | Val loss:  0.486887 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 8                              \n",
      " 22:01:52 | Ep: 582/ 600 | Trn loss:  0.208364 - Acc: 92.1508 | Val loss:  0.486926 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 7                              \n",
      " 22:02:05 | Ep: 583/ 600 | Trn loss:  0.208340 - Acc: 92.1533 | Val loss:  0.486956 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 6                              \n",
      " 22:02:18 | Ep: 584/ 600 | Trn loss:  0.208320 - Acc: 92.1540 | Val loss:  0.486983 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 5                              \n",
      " 22:02:31 | Ep: 585/ 600 | Trn loss:  0.208304 - Acc: 92.1555 | Val loss:  0.487007 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 4                              \n",
      " 22:02:44 | Ep: 586/ 600 | Trn loss:  0.208288 - Acc: 92.1580 | Val loss:  0.487029 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 3                              \n",
      " 22:02:57 | Ep: 587/ 600 | Trn loss:  0.208273 - Acc: 92.1580 | Val loss:  0.487051 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 2                              \n",
      " 22:03:10 | Ep: 588/ 600 | Trn loss:  0.208258 - Acc: 92.1591 | Val loss:  0.487072 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 1                              \n",
      " 22:03:24 | Ep: 589/ 600 | Trn loss:  0.208244 - Acc: 92.1591 | Val loss:  0.487093 - Acc: 86.3796 | last_lr: 1.95313e-06  bad_ep: 0  cdwn: 0                              \n",
      " 22:03:37 | Ep: 590/ 600 | Trn loss:  0.208230 - Acc: 92.1598 | Val loss:  0.487113 - Acc: 86.3796 | last_lr: 1.95313e-06  bad_ep: 1  cdwn: 0                              \n",
      " 22:03:50 | Ep: 591/ 600 | Trn loss:  0.208215 - Acc: 92.1605 | Val loss:  0.487134 - Acc: 86.3796 | last_lr: 1.95313e-06  bad_ep: 2  cdwn: 0                              \n",
      " 22:04:03 | Ep: 592/ 600 | Trn loss:  0.208201 - Acc: 92.1620 | Val loss:  0.487154 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 3  cdwn: 0                              \n",
      " 22:04:16 | Ep: 593/ 600 | Trn loss:  0.208187 - Acc: 92.1623 | Val loss:  0.487174 - Acc: 86.3750 | last_lr: 1.95313e-06  bad_ep: 4  cdwn: 0                              \n",
      " 22:04:29 | Ep: 594/ 600 | Trn loss:  0.208173 - Acc: 92.1631 | Val loss:  0.487194 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 5  cdwn: 0                              \n",
      " 22:04:42 | Ep: 595/ 600 | Trn loss:  0.208159 - Acc: 92.1634 | Val loss:  0.487214 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 6  cdwn: 0                              \n",
      " 22:04:56 | Ep: 596/ 600 | Trn loss:  0.208145 - Acc: 92.1627 | Val loss:  0.487233 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 7  cdwn: 0                              \n",
      " 22:05:09 | Ep: 597/ 600 | Trn loss:  0.208132 - Acc: 92.1638 | Val loss:  0.487253 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 8  cdwn: 0                              \n",
      " 22:05:22 | Ep: 598/ 600 | Trn loss:  0.208118 - Acc: 92.1638 | Val loss:  0.487273 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 9  cdwn: 0                              \n",
      " 22:05:36 | Ep: 599/ 600 | Trn loss:  0.208104 - Acc: 92.1641 | Val loss:  0.487292 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 10  cdwn: 0                             \n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 22:05:49,379 - utils.utils_cellpainting - INFO: -  Model exported to NN_snnl_embd600_150Ltnt_512_20240906_2201_LAST_20240909_2130_ep_600.pt - epoch: 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22:05:49 | Ep: 600/ 600 | Trn loss:  0.208090 - Acc: 92.1649 | Val loss:  0.487311 - Acc: 86.3704 | last_lr: 1.95313e-06  bad_ep: 11  cdwn: 0 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = fit(model, optimizer, scheduler, data_loader, metrics, start_epoch, end_epoch, device, CKPT_FILE, CKPT_PATH )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ac673-4b85-4d5a-ba01-40945db8419f",
   "metadata": {},
   "source": [
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52421a1e-edc4-4f04-af58-390ac23260cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CKPT_FILE)\n",
    "# save_checkpoint(end_epoch, model, optimizer, scheduler, metrics = metrics,\n",
    "#                 filename = CKPT_FILE.format(ep=end_epoch),\n",
    "#                 ckpt_path = CKPT_PATH, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e978589-d202-445e-a7a8-2c8068acbe85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:35:15.434870Z",
     "start_time": "2023-06-04T11:35:15.344699Z"
    }
   },
   "outputs": [],
   "source": [
    "# start_epoch, end_epoch\n",
    "\n",
    "# for mtrc in ['loss_trn', 'loss_val']:\n",
    "#     for i in range(len(metrics[mtrc])):\n",
    "#         # print(i)\n",
    "#         metrics[mtrc][i] = metrics[mtrc][i].item()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75622ea-9d55-42a5-afbd-b7453166bce0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modify TPSA Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4e52f-46c9-4506-8b0d-239f045f04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_y_72 = np.zeros_like(train_y)\n",
    "train_y_72.shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11392e3-cbea-49a8-9a0b-2030c1a0aee1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"                  min           max           std          mean           median\")\n",
    "for x in ['TPSA', 'lnTPSA', 'log10TPSA']:\n",
    "    print(f\"{x:12s} {df_train[x].min():13.7f} {df_train[x].max():13.7f} {df_train[x].std():13.7f} {df_train[x].mean():13.7f} {df_train[x].median():13.7f}\") \n",
    "\n",
    "df_train.TPSA.count()\n",
    "df_train[df_train.TPSA >= THRESHOLD].TPSA.count()/df_train.TPSA.count()\n",
    "df_train[df_train.TPSA < THRESHOLD].TPSA.count()/df_train.TPSA.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5bab9-6b23-4078-a398-dccbea38ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = df_train.Metadata_Permiation.value_counts()\n",
    "_tmp[0], _tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59dcba1-6add-4446-aa27-a30564f42e54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for threshold in [68, 69, 70, 71, 72, 100]:\n",
    "    _tmp = (df_train['Metadata_TPSA'] >= threshold).value_counts()\n",
    "    print(f\"\\n TPSA threshold {threshold} \\n Total samples: {_tmp.sum()}\")\n",
    "    print(f\" Label 0: {_tmp[False]:>7d}      % {_tmp[False]*100/_tmp.sum():2.2f} \")\n",
    "    print(f\" Label 1: {_tmp[True]:>7d}      % {_tmp[True]*100/_tmp.sum():2.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1d01b-3946-4668-9c10-5fb3f2b3bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(4,4))\n",
    "# fig.canvas.draw()  # Need to draw the figure to define renderer\n",
    "# ax.set_title(\"AngleLabel example\")\n",
    "# # Plot two crossing lines and label each angle between them with the above\n",
    "# center = (4.5, 650)\n",
    "# p1 = [(2.5, 710), (6.0, 605)]\n",
    "# p2 = [(3.0, 275), (5.5, 900)]\n",
    "# line1, = ax.plot(*zip(*p1))\n",
    "# line2, = ax.plot(*zip(*p2))\n",
    "# point, = ax.plot(*center, marker=\"o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19bd08-45c1-4d41-9d02-a5b59d30c53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:37:34.108730Z",
     "start_time": "2023-06-28T19:37:34.072553Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "num_bins = 200\n",
    "# fig, ax = plt.subplots()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "sigma = df_train.Metadata_TPSA.std()\n",
    "mu = df_train.Metadata_TPSA.mean()\n",
    "med = df_train.Metadata_TPSA.median()\n",
    "# the histogram of the data\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "n, bins, patches = plt.hist(df_train.Metadata_TPSA, num_bins, density=False, range=[0, 500],)\n",
    "# p1 = [(med, 710), (6.0, 605)]\n",
    "# _ = plt.vlines(x=med, ymin=10, ymax=17000, colors='red', linestyles='-', lw=1.75, label='Single Short Line')\n",
    "_ = plt.axvline(x=med, ymin=0, ymax=.97, color='red', linestyle='-', lw=1.75, label='Single Short Line')\n",
    "_ = plt.xlabel('TPSA Value');\n",
    "_ = plt.ylabel('# Compounds');\n",
    "_ = plt.title(fr'TPSA distribution -  $\\mu={mu:.3f}$    $\\sigma={sigma:.3f}$')\n",
    "plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0)\n",
    "# axs[1].hist(dist2, bins=n_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c33d9-a56a-4175-9936-b16efed13334",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Stratified CV data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36185b9f-f76e-4556-a736-7a97ac07659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532d16b-50f2-486d-a2b8-22e960f6007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    use_groups = \"Group\" in type(cv).__name__\n",
    "    groups = group if use_groups else None\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=groups)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, 100],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3f078-8b33-4acc-b639-6daac6d9d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1165a3b-5756-443f-ad46-bf316c34929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1338)\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "n_splits = 4\n",
    "\n",
    "# Generate the class/group data\n",
    "# n_points = 100\n",
    "# X = rng.randn(100, 10)\n",
    "\n",
    "# percentiles_classes = [0.1, 0.3, 0.6]\n",
    "# y = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd8391-cbf3-4468-9aa2-d311c7f83bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate uneven groups\n",
    "\n",
    "# group_prior = rng.dirichlet([2] * 10)\n",
    "# group_prior.sum()\n",
    "# group_prior\n",
    "\n",
    "# groups = np.repeat(np.arange(10), rng.multinomial(100, group_prior))\n",
    "# groups.shape\n",
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be667cf-b73b-49d9-8f93-028feb33dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.repeat(0, train_X.shape[0])\n",
    "groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc3e15-7328-43d7-87b0-e662e89f8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_groups(train_y, groups, \"no groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b44ef-5b62-4008-8e90-fcd97dca2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "groups = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5f1e4-9fbf-4c51-a82a-ee2c870850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cv = KFold(n_splits)\n",
    "plot_cv_indices(cv, train_X, train_y, groups, ax, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1cd39-be31-4f80-b0b3-a064ddf5b59d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987503fe-4de3-4967-a228-9e5b7a6d30b8",
   "metadata": {},
   "source": [
    "## Read Embedded Features CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b33d4-10b8-44a2-a97b-3fb5e124812e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_TRAIN_INPUT = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = BASE_runmode ,datatype='train'))\n",
    "BASE_TEST_INPUT  = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = BASE_runmode ,datatype='test'))\n",
    "SNNL_TRAIN_INPUT = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = SNNL_runmode ,datatype='train'))\n",
    "SNNL_TEST_INPUT  = os.path.join(OUTPUT_PATH, INPUT_FILE.format(runmode = SNNL_runmode ,datatype='test'))\n",
    "BASE_TRAIN_INPUT\n",
    "BASE_TEST_INPUT \n",
    "SNNL_TRAIN_INPUT\n",
    "SNNL_TEST_INPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff17ab-dd6a-49fe-8733-8f3448537618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(SNNL_TEST_INPUT )\n",
    "df_train = pd.read_csv(SNNL_TRAIN_INPUT)\n",
    "\n",
    "# df_train = pd.read_csv(BASE_TRAIN_INPUT)\n",
    "# df_test = pd.read_csv(BASE_TEST_INPUT )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, nrows = 100 )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, usecols = ['Metadata_Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a273e-36aa-4b1b-8a49-3c911fe62659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.shape\n",
    "df_test.columns\n",
    "df_test.iloc[:5,:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21aa50d-b501-4532-9c1f-62a2c960f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(TRAIN_INPUT, nrows = 100 )\n",
    "# df_train = pd.read_csv(TRAIN_INPUT, usecols = ['Metadata_Batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e266886-b249-4370-84ef-242c34c98e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = df_test.iloc[:,10:11].to_numpy().ravel().astype(np.uint8)\n",
    "test_y.sum()\n",
    "test_y.shape, type(test_y), test_y.dtype\n",
    "test_X = df_test.iloc[:,11:].to_numpy()\n",
    "test_X.shape,type(test_X), test_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccbf57-4fa7-4842-919b-103d14e44c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape\n",
    "df_train.info()\n",
    "df_train.iloc[:5,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d392e-68eb-4474-ad37-12244f4d23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "312000+34542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710ee4c-badf-4f28-a214-f8354f6c1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_train.iloc[:,10:11].to_numpy().ravel().astype(np.uint8)\n",
    "train_y.sum()\n",
    "train_y.shape, type(train_y), train_y.dtype\n",
    "\n",
    "train_X = df_train.iloc[:,11:].to_numpy()\n",
    "train_X.shape,type(train_X) ,train_X.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c738a2-74d5-4702-a93f-36428714aedf",
   "metadata": {},
   "source": [
    "## Standardize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba790ed-fea3-4803-bf33-91b2a0d74fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab780bd-8b49-46ce-b18b-abc1e0ff181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "# print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ed6ad-1c8c-4c10-9bc5-82e6fcc9fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy = True)\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a118cd-aed2-4e64-a4da-8de20a99be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After Standard Scaler Transformation\")\n",
    "print(f\"Train_X :  Min: {train_X.min():.4f}    Max: {train_X.max():.4f}   Mean: {train_X.mean():.4f}  Std: {train_X.std():.4f}\")\n",
    "print(f\"Test_X  :  Min: {test_X.min():.4f}    Max: {test_X.max():.4f}    Mean: {test_X.mean():.4f}  Std: {test_X.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685b4df-8975-4935-8bd2-edba44873a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts([(\"Training\", train_y), (\"Test\", test_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7ad73-1936-428c-bd8e-341f594d816b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa293a17-1064-44e2-8d7c-42a5aef53159",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TQDM Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4955de-e618-45a3-83be-028e913b55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# TRANGE example\n",
    "#-----------------------------------------   \n",
    "# with trange(+1, ns.trn_iters_warmup+1 , initial = 0 , total = ns.trn_iters_warmup, position=0, file=sys.stdout,\n",
    "#             leave= False, disable = disable_tqdm, desc=f\" Warmup Epoch {ns.current_epoch}/{ns.stop_epoch_warmup}\") as t_warmup :\n",
    "#     for _ in t_warmup:\n",
    "#         ns.current_iter += 1            \n",
    "\n",
    "#         batch = next(dldrs.warmup_trn_loader)            \n",
    "#         environ.set_inputs(batch, input_size)\n",
    "\n",
    "#         environ.optimize(is_policy=False, \n",
    "#                          num_train_layers=ns.num_train_layers,\n",
    "#                          flag='update_weights', \n",
    "#                          verbose = verbose)\n",
    "    \n",
    "#         t_warmup.set_postfix({'curr_iter':ns.current_iter, \n",
    "#                             'Loss': f\"{environ.losses['total']['total'].item():.4f}\"})\n",
    "\n",
    "#-----------------------------------------\n",
    "# TQDM example\n",
    "#-----------------------------------------   \n",
    "# current_epoch = 1\n",
    "# total_epochs = 20\n",
    "# current_iter = 0 \n",
    "# train_minibatches = len(data_loader['train']) // minibatch_size\n",
    "# val_minibatches = len(data_loader['val']) // minibatch_size\n",
    "\n",
    "# # with batch_count, (batch_features, batch_labels, _, _, _, _) in tqdm(enumerate(data_loader['train']), initial=0, total = 400, position=0, file=sys.stdout,\n",
    "#             # leave= False, desc=f\" Epoch {current_epoch}/{total_epochs}\") as t_warmup :\n",
    "# t_warmup =  tqdm(enumerate(data_loader['train']), initial=0, total = train_minibatches, position=0, file=sys.stdout,\n",
    "#             leave= False, desc=f\" Epoch {current_epoch}/{total_epochs}\") \n",
    "# for batch_count, (batch_features, batch_labels, _, _, _, _) in t_warmup:\n",
    "#     # batch_count, (batch_features, batch_labels, _, _, _, _) = pp\n",
    "#     loss = random.random()\n",
    "#     t_warmup.set_postfix({'curr_iter':batch_count, 'Loss': f\"{loss:.4f}\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cp311]",
   "language": "python",
   "name": "conda-env-cp311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
